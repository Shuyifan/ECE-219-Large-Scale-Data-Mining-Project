{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "# Refer to the offcial document of scikit-learn for detailed usages:\n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_20newsgroups.html\n",
    "twenty_train = fetch_20newsgroups(subset='train', # choose which subset of the dataset to use; can be 'train', 'test', 'all'\n",
    "                                  shuffle=True,\n",
    "                                  random_state=42, # set the seed of random number generator when shuffling to make the outcome repeatable across different runs\n",
    "#                                   remove=['headers'],\n",
    "                                 )\n",
    "twenty_test = fetch_20newsgroups(subset='test', shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.utils.Bunch'>\n",
      "dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR'])\n"
     ]
    }
   ],
   "source": [
    "print(type(twenty_train))\n",
    "print(twenty_train.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['/Users/apple/scikit_learn_data/20news_home/20news-bydate-train/rec.autos/102994',\n",
       "       '/Users/apple/scikit_learn_data/20news_home/20news-bydate-train/comp.sys.mac.hardware/51861',\n",
       "       '/Users/apple/scikit_learn_data/20news_home/20news-bydate-train/comp.sys.mac.hardware/51879',\n",
       "       ...,\n",
       "       '/Users/apple/scikit_learn_data/20news_home/20news-bydate-train/comp.sys.ibm.pc.hardware/60695',\n",
       "       '/Users/apple/scikit_learn_data/20news_home/20news-bydate-train/comp.graphics/38319',\n",
       "       '/Users/apple/scikit_learn_data/20news_home/20news-bydate-train/rec.motorcycles/104440'],\n",
       "      dtype='<U93')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_train.filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 4, 4, ..., 3, 1, 8])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_train.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_train.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(twenty_train.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.unique(twenty_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "From: guykuo@carson.u.washington.edu (Guy Kuo)\n",
      "Subject: SI Clock Poll - Final Call\n",
      "Summary: Final call for SI clock reports\n",
      "Keywords: SI,acceleration,clock,upgrade\n",
      "Article-I.D.: shelley.1qvfo9INNc3s\n",
      "Organization: University of Washington\n",
      "Lines: 11\n",
      "NNTP-Posting-Host: carson.u.washington.edu\n",
      "\n",
      "A fair number of brave souls who upgraded their SI clock oscillator have\n",
      "shared their experiences for this poll. Please send a brief message detailing\n",
      "your experiences with the procedure. Top speed attained, CPU rated speed,\n",
      "add on cards and adapters, heat sinks, hour of usage per day, floppy disk\n",
      "functionality with 800 and 1.4 m floppies are especially requested.\n",
      "\n",
      "I will be summarizing in the next two days, so please add to the network\n",
      "knowledge base if you have done the clock upgrade and haven't answered this\n",
      "poll. Thanks.\n",
      "\n",
      "Guy Kuo <guykuo@u.washington.edu>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(twenty_train.target[1])\n",
    "print(twenty_train.data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rec.autos\n"
     ]
    }
   ],
   "source": [
    "# The first document belongs to the category 'comp.sys.mac.hardware'\n",
    "print(twenty_train.target_names[twenty_train.target[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11314\n",
      "11314\n"
     ]
    }
   ],
   "source": [
    "print(len(twenty_train.data))\n",
    "print(len(twenty_train.target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Question 1:\n",
    "To get started, plot a histogram of the number of training documents for each of the 20 categories to check if they are evenly distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[480, 584, 591, 590, 578, 593, 585, 594, 598, 597, 600, 595, 591, 594, 593, 599, 546, 564, 465, 377]\n"
     ]
    }
   ],
   "source": [
    "num_each_category = [0]*20\n",
    "lenth = len(twenty_train.target)\n",
    "for target in twenty_train.target:\n",
    "    num_each_category[target] += 1\n",
    "print(num_each_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "t = range(0,20)\n",
    "plt.bar(t,num_each_category,0.5)\n",
    "plt.xticks(t,t)\n",
    "plt.title(\"Distribution of documents\")\n",
    "plt.xlabel(\"Category ID\")\n",
    "plt.ylabel(\"Number of documents in the group\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: \n",
    "Use the following specs to extract features from the textual data:\n",
    "- Use the “english” stopwords of the CountVectorizer\n",
    "- Exclude terms that are numbers (e.g. “123”, “-45”, “6.7” etc.) \n",
    "- Perform lemmatization with nltk.stem.wordnet.WordNetLemmatizer and pos_tag \n",
    "- Use min_df=3 \n",
    "\n",
    "Report the shape of the TF-IDF matrices of the train and test subsets respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "import random\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "categories = ['comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware',\n",
    "            'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey']\n",
    "\n",
    "train_dataset = fetch_20newsgroups(subset = 'train', categories = categories, shuffle = True, random_state = None)\n",
    "test_dataset = fetch_20newsgroups(subset = 'test', categories = categories, shuffle = True, random_state = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7]\n",
      "['comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey']\n",
      "4732\n",
      "3150\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(train_dataset.target))\n",
    "print(train_dataset.target_names)\n",
    "print(len(train_dataset.target))\n",
    "print(len(test_dataset.target))\n",
    "print(type(train_dataset.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer(analyzer=<function stem_rmv_nums at 0x11284a400>,\n",
      "        binary=False, decode_error='strict', dtype=<class 'numpy.int64'>,\n",
      "        encoding='utf-8', input='content', lowercase=True, max_df=1.0,\n",
      "        max_features=None, min_df=3, ngram_range=(1, 1), preprocessor=None,\n",
      "        stop_words=None, strip_accents=None,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, vocabulary=None)\n",
      "--------------------\n",
      "(4732, 16319)\n",
      "--------------------\n",
      "16319\n",
      "--------------------\n",
      "['0005111312na1em', '0010580b', '002251w', '0096b0f0', '00bjgood', '00mbstultz', '00pm', '02uv', '03hz', '03k', '05apr93', '05l', '06eh', '06paul', '0_', '0___', '0a', '0b', '0b14', '0c', '0d', '0d2', '0df', '0e', '0ek', '0f', '0g', '0g8', '0h', '0hd', '0i', '0iv', '0ivbudk', '0j', '0k', '0l', '0m', '0m75u', '0m8b', '0mk', '0n', '0o', '0p', '0q', '0qax', '0qq', '0r', '0sl', '0t', '0tbxn', '0tbxom', '0tq', '0tq6', '0u', '0v', '0va', '0w', '0x', '0x100', '0y', '0z', '1000cc', '100k', '100mph', '101e', '1024x768', '1024x768x16', '1024x768x256', '1024x768x65536', '106ps', '10h', '10k', '10mb', '10min', '10pm', '10th', '10w', '10w40', '115a', '11h', '11k', '11th', '1200cc', '120km', '120mb', '120mph', '125mb', '1280x1024', '128k', '12a', '12cyl', '12k', '12mb', '12ms', '12v', '1304s', '130mph', '132mb', '13h', '13k']\n"
     ]
    }
   ],
   "source": [
    "# Lemmatization\n",
    "from nltk import pos_tag,word_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet as wn\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS, CountVectorizer\n",
    "\n",
    "wnl = WordNetLemmatizer()\n",
    "\n",
    "stop_words = ENGLISH_STOP_WORDS\n",
    "\n",
    "def penn2morphy(penntag):\n",
    "    \"\"\" Converts Penn Treebank tags to WordNet. \"\"\"\n",
    "    morphy_tag = {'NN':'n', 'JJ':'a',\n",
    "                  'VB':'v', 'RB':'r'}\n",
    "    try:\n",
    "        return morphy_tag[penntag[:2]]\n",
    "    except:\n",
    "        return 'n'\n",
    "\n",
    "def lemmatize_sent(list_word):\n",
    "    # Text input is string, returns array of lowercased strings(words).\n",
    "    return [wnl.lemmatize(word.lower(), pos=penn2morphy(tag)) \n",
    "            for word, tag in pos_tag(list_word)]\n",
    "\n",
    "# remove nums as well as stop words\n",
    "def stem_rmv_nums(doc):\n",
    "    return (word for word in lemmatize_sent(analyzer(doc)) if word not in stop_words and not word.isdigit())\n",
    "\n",
    "analyzer = CountVectorizer().build_analyzer()\n",
    "vectorizer = CountVectorizer(min_df=3, analyzer=stem_rmv_nums) # we have removed stopwords when removing nums\n",
    "\n",
    "print(vectorizer)\n",
    "print('-' * 20)\n",
    "X_train = vectorizer.fit_transform(train_dataset.data)\n",
    "print(X_train.shape)\n",
    "print('-' * 20)\n",
    "print(len(vectorizer.get_feature_names()))\n",
    "print('-' * 20)\n",
    "print(vectorizer.get_feature_names()[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3150, 16319)\n"
     ]
    }
   ],
   "source": [
    "# test data\n",
    "\n",
    "X_test = vectorizer.transform(test_dataset.data)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)\n",
      "--------------------\n",
      "(4732, 16319)\n",
      "--------------------\n",
      "[[0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]]\n",
      "--------------------\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF matrices of the train subsets\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf = TfidfTransformer()\n",
    "\n",
    "print(tfidf)\n",
    "print('-' * 20)\n",
    "\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "print(X_train_tfidf.shape)\n",
    "print('-' * 20)\n",
    "print(X_train.toarray()[20:30,20:30])\n",
    "print('-' * 20)\n",
    "print(X_train_tfidf.toarray()[20:30,20:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3150, 16319)\n",
      "--------------------\n",
      "[[0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]]\n",
      "--------------------\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF matrices of the test subsets\n",
    "\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "print(X_test_tfidf.shape)\n",
    "print('-' * 20)\n",
    "print(X_test.toarray()[20:30,20:30])\n",
    "print('-' * 20)\n",
    "print(X_test_tfidf.toarray()[20:30,20:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3:\n",
    "Reduce the dimensionality of the data using the methods above\n",
    "- Apply LSI to the TF-IDF matrix corresponding to the 8 categories with k = 50; so each document is mapped to a 50-dimensional vector.\n",
    "- Also reduce dimnsionality through NMF (k = 50) and compare with LSI: \n",
    "<br>Which one is larger, the $ \\mid\\mid X-WH\\mid\\mid_F^2 $ in NMF or the $\\mid\\mid X-U_k\\sum_kV_k^T\\mid\\mid_F^2$ in LSI? Why is the case?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4732, 50)\n",
      "[[ 0.13264864  0.0996511   0.02809409 ... -0.01471573  0.03555587\n",
      "   0.00890533]\n",
      " [ 0.12492937  0.12831517  0.0373239  ...  0.27479684 -0.15601885\n",
      "   0.04450578]\n",
      " [ 0.18184614 -0.02649614  0.00257884 ...  0.00289785  0.03281254\n",
      "   0.01577702]\n",
      " ...\n",
      " [ 0.14001711  0.113792    0.02665245 ...  0.02799442 -0.01186747\n",
      "  -0.00182857]\n",
      " [ 0.21163627  0.15900119  0.02883639 ...  0.03833902  0.00435591\n",
      "  -0.0109685 ]\n",
      " [ 0.11851532 -0.02439784 -0.04525538 ...  0.02404043  0.02482595\n",
      "   0.01249345]]\n"
     ]
    }
   ],
   "source": [
    "# LSI\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "svd = TruncatedSVD(n_components = 50, random_state = 42)\n",
    "X_train_lsi = svd.fit_transform(X_train_tfidf)\n",
    "X_test_lsi = svd.transform(X_test_tfidf)\n",
    "\n",
    "# show time\n",
    "print(X_train_lsi.shape)\n",
    "print(X_train_lsi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4732, 50)\n",
      "-------------------- NMF --------------------\n",
      "[[0.09231654 0.05966702 0.         ... 0.00453938 0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.01386315 0.         0.00745838 ... 0.00207688 0.         0.        ]\n",
      " ...\n",
      " [0.02440786 0.14556696 0.         ... 0.         0.         0.        ]\n",
      " [0.16921084 0.         0.         ... 0.         0.         0.00091498]\n",
      " [0.         0.         0.         ... 0.         0.00398401 0.00224543]]\n",
      "-------------------- NMF --------------------\n",
      "(4732, 50)\n",
      "(50, 16319)\n"
     ]
    }
   ],
   "source": [
    "# NMF\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "nmf = NMF(n_components=50, init='random', random_state=42)\n",
    "W_train = nmf.fit_transform(X_train_tfidf)\n",
    "W_test = nmf.transform(X_test_tfidf)\n",
    "\n",
    "H = nmf.components_\n",
    "\n",
    "# show time\n",
    "print(W_train.shape)\n",
    "print('-' * 20, 'NMF', '-'*20)\n",
    "print(W_train)\n",
    "print('-' * 20, 'NMF', '-'*20)\n",
    "print(W_train.shape)\n",
    "print(H.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4141.549653993933\n"
     ]
    }
   ],
   "source": [
    "# Loss of nmf\n",
    "\n",
    "\n",
    "#err_nmf = nmf.reconstruction_err_\n",
    "err_nmf = np.sum(np.array(X_train_tfidf - W_train.dot(H)) ** 2)\n",
    "\n",
    "print(err_nmf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4106.962861236307\n"
     ]
    }
   ],
   "source": [
    "# Loss of lsi\n",
    "\n",
    "SIGMA_V = svd.components_\n",
    "err_lsi = np.sum(np.array(X_train_tfidf - X_train_lsi.dot(SIGMA_V)) ** 2)\n",
    "\n",
    "print(err_lsi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss of LSI method is:  4106.962861236307\n",
      "The loss of NMF method is:  4141.549653993933\n",
      "So the loss of NMF is larger!\n"
     ]
    }
   ],
   "source": [
    "print('The loss of LSI method is: ',err_lsi)\n",
    "print('The loss of NMF method is: ',err_nmf)\n",
    "\n",
    "if err_lsi > err_nmf:\n",
    "    print('So the loss of LSI is larger!')\n",
    "elif err_lsi < err_nmf:\n",
    "    print('So the loss of NMF is larger!')\n",
    "else:\n",
    "    print('Incredible!!! They are equal!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4:\n",
    "Hard margin and soft margin linear SVMs:\n",
    "- Train two linear SVMs and compare:\n",
    "    * Train one SVM with $\\gamma = 1000$ (hard margin), another with $\\gamma = 0.0001$ (soft nargin).\n",
    "    * Plot the ROC curve, report the **confusion matrix** and calculate the **accuracy, recall, precision** and **F-1 score** of both SVM classifier. Which one performs better?\n",
    "    * What happens for the soft margin SVM? Why is the case?\n",
    "        - Does the DOC curve of the soft margin SVM look good? Does this conflict with other metrics?\n",
    "- Use cross-validation to choose $\\gamma$ (use average validation accuuracy to compare):\n",
    "<br>Using a 5-fold cross-validation, find the best value of the parameter $\\gamma$ in the range $\\lbrace10^k\\mid-3\\leq k\\leq3, k\\in\\mathbb Z\\rbrace$. Again, plot the ROC curve and report the confusion matrix and calculate the **accuracy, recall precision** and **F-1 score** of this best SVM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train SVM and Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- train_dataset --------------------\n",
      "4732\n",
      "[0 1]\n",
      "-------------------- test_dataset --------------------\n",
      "3150\n",
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "# data preparation and regroup\n",
    "\n",
    "# regroup\n",
    "def get_labels(dataset):\n",
    "    labels = []\n",
    "    new_name = ['Computer Technology','Recreational Activity']\n",
    "\n",
    "    for label in dataset.target:\n",
    "        name = dataset.target_names[label]\n",
    "        if name.startswith('comp'):\n",
    "            labels.append(0)\n",
    "        elif name.startswith('rec'):\n",
    "            labels.append(1)\n",
    "        else:\n",
    "            print('Wrong type!')\n",
    "    \n",
    "    return labels, new_name\n",
    "\n",
    "train_label, new_name = get_labels(train_dataset)\n",
    "test_label, _ = get_labels(test_dataset)\n",
    "\n",
    "# check\n",
    "print('-'*20,'train_dataset','-'*20)\n",
    "print(len(train_label))\n",
    "print(np.unique(train_label))\n",
    "print('-'*20,'test_dataset','-'*20)\n",
    "print(len(test_label))\n",
    "print(np.unique(test_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train linear SVMs\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_hard = SVC(kernel='linear', C=1000, random_state=42).fit(X_train_lsi, train_label)\n",
    "svm_soft = SVC(kernel='linear', C=0.0001, random_state=42).fit(X_train_lsi, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# define plot drawing\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def plot_roc(fpr, tpr):\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    roc_auc = metrics.auc(fpr,tpr)\n",
    "\n",
    "    ax.plot(fpr, tpr, linewidth=2,label= 'area under curve = %0.4f' % roc_auc)\n",
    "\n",
    "    ax.grid(color='0.7', linestyle='--', linewidth=1)\n",
    "\n",
    "    ax.set_xlim([-0.1, 1.1])\n",
    "    ax.set_ylim([0.0, 1.05])\n",
    "    ax.set_xlabel('False Positive Rate',fontsize=15)\n",
    "    ax.set_ylabel('True Positive Rate',fontsize=15)\n",
    "\n",
    "    ax.legend(loc=\"lower right\")\n",
    "\n",
    "    for label in ax.get_xticklabels()+ax.get_yticklabels():\n",
    "        label.set_fontsize(15)\n",
    "        \n",
    "# prepare plot for svm_hard\n",
    "\n",
    "score_hard = svm_hard.decision_function(X_test_lsi)\n",
    "#print(len(score_hard))\n",
    "fpr_hard, tpr_hard, _ = metrics.roc_curve(test_label, score_hard)\n",
    "\n",
    "# draw the ROC for svm_hard\n",
    "\n",
    "plot_roc(fpr_hard, tpr_hard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot for svm_soft\n",
    "\n",
    "score_soft = svm_soft.decision_function(X_test_lsi)\n",
    "fpr_soft, tpr_soft, _ = metrics.roc_curve(test_label, score_soft)\n",
    "\n",
    "# draw the ROC for svm_soft\n",
    "\n",
    "plot_roc(fpr_soft, tpr_soft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "line_hard = ax.plot(fpr_hard, tpr_hard, linewidth=2)\n",
    "line_soft = ax.plot(fpr_soft, tpr_soft, linewidth=2)\n",
    "\n",
    "ax.grid(color='0.7', linestyle='--', linewidth=1)\n",
    "\n",
    "ax.set_xlim([-0.1, 1.1])\n",
    "ax.set_ylim([0.0, 1.05])\n",
    "ax.set_xlabel('False Positive Rate',fontsize=15)\n",
    "ax.set_ylabel('True Positive Rate',fontsize=15)\n",
    "\n",
    "ax.legend(('Hard SVM','Soft SVM'),loc=\"lower right\")\n",
    "plt.title('ROC curve of SVM with C=1000(hard) and C=0.0001(soft)')\n",
    "\n",
    "for label in ax.get_xticklabels()+ax.get_yticklabels():\n",
    "    label.set_fontsize(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Confusion Matrix of hard SVM(C=1000) --------------------\n",
      "[[1504   56]\n",
      " [  35 1555]]\n",
      "-------------------- Other Evaluation of hard SVM(C=1000) --------------------\n",
      "Accuracy: 0.9711111111111111\n",
      "Recall: 0.9779874213836478\n",
      "Precision: 0.9652389819987586\n",
      "F-1 Score: 0.9715713839425181\n",
      "\n",
      "-------------------- Confusion Matrix of soft SVM(C=0.0001) --------------------\n",
      "[[   0 1560]\n",
      " [   0 1590]]\n",
      "-------------------- Other Evaluation of soft SVM(C=0.0001) --------------------\n",
      "Accuracy: 0.5047619047619047\n",
      "Recall: 1.0\n",
      "Precision: 0.5047619047619047\n",
      "F-1 Score: 0.6708860759493671\n",
      "\n",
      "-------------------- Notes of Index --------------------\n",
      "labels are:\n",
      "Value of 0 -> Computer Technology\n",
      "Value of 1 -> Recreational Activity\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix & other metrics\n",
    "def evaluate(classifier, clf_name, testSet, label, average=''):\n",
    "    y_pred = classifier.predict(testSet)\n",
    "    CM = metrics.confusion_matrix(label, y_pred)\n",
    "    \n",
    "    print('-'*20, 'Confusion Matrix of', clf_name, '-'*20)\n",
    "    print(CM)\n",
    "    \n",
    "    accuracy = metrics.accuracy_score(label, y_pred)\n",
    "    if average == '':\n",
    "        recall = metrics.recall_score(label, y_pred)\n",
    "        precision = metrics.precision_score(label, y_pred)\n",
    "        Fscore = metrics.f1_score(label, y_pred)\n",
    "    else:\n",
    "        recall = metrics.recall_score(label,y_pred,average=average)\n",
    "        precision = metrics.precision_score(label, y_pred,average=average)\n",
    "        Fscore = metrics.f1_score(label, y_pred,average=average)\n",
    "    \n",
    "    print('-'*20, 'Other Evaluation of', clf_name, '-'*20)\n",
    "    print('Accuracy:', accuracy)\n",
    "    print('Recall:', recall)\n",
    "    print('Precision:', precision)\n",
    "    print('F-1 Score:', Fscore)\n",
    "\n",
    "evaluate(svm_hard, 'hard SVM(C=1000)', X_test_lsi, test_label)\n",
    "print()\n",
    "evaluate(svm_soft, 'soft SVM(C=0.0001)', X_test_lsi, test_label)\n",
    "\n",
    "print()\n",
    "print('-'*20,'Notes of Index','-'*20)\n",
    "print('labels are:')\n",
    "print('Value of 0 ->',new_name[0])\n",
    "print('Value of 1 ->',new_name[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use cross-validation to choose $\\gamma$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- C = 0.001 --------------------\n",
      "[0.49295775 0.50633803 0.48098592 0.50985915 0.48309859]\n",
      "0.4946478873239437\n",
      "-------------------- C = 0.01 --------------------\n",
      "[0.49295775 0.50633803 0.48169014 0.50985915 0.48380282]\n",
      "0.4949295774647887\n",
      "-------------------- C = 0.1 --------------------\n",
      "[0.96267606 0.96056338 0.97112676 0.96690141 0.95985915]\n",
      "0.9642253521126761\n",
      "-------------------- C = 1 --------------------\n",
      "[0.97042254 0.96478873 0.97464789 0.97112676 0.96760563]\n",
      "0.969718309859155\n",
      "-------------------- C = 10 --------------------\n",
      "[0.97253521 0.96830986 0.97464789 0.97535211 0.96830986]\n",
      "0.971830985915493\n",
      "-------------------- C = 100 --------------------\n",
      "[0.97183099 0.96971831 0.97042254 0.97323944 0.96830986]\n",
      "0.9707042253521129\n",
      "-------------------- C = 1000 --------------------\n",
      "[0.97112676 0.96901408 0.97112676 0.97394366 0.96760563]\n",
      "0.9705633802816902\n",
      "-------------------- Result --------------------\n",
      "The best classifier is when C = 10\n",
      "Average Accuracy is: 0.971830985915493\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "def cross_validate(classifier, train, label):\n",
    "    avg_score = []\n",
    "\n",
    "    for k in range(-3, 4):\n",
    "        classifier.set_params(C=10**k).fit(train, label)\n",
    "        cv = ShuffleSplit(n_splits=5, test_size=0.3, random_state=42)\n",
    "        scores = cross_val_score(classifier, train, label, cv=cv, scoring='accuracy')\n",
    "    \n",
    "        print('-'*20,'C =',10**k,'-'*20)\n",
    "        print(scores)\n",
    "        print(np.average(scores))\n",
    "        avg_score.append(np.average(scores))\n",
    "\n",
    "    max_score = np.max(avg_score)\n",
    "    index = avg_score.index(max_score)\n",
    "    c_idx = [x for x in range(-3,4)][index]\n",
    "    print('-'*20,'Result','-'*20)\n",
    "    print('The best classifier is when C =', 10**c_idx)\n",
    "    print('Average Accuracy is:', max_score)\n",
    "    \n",
    "    return classifier.set_params(C=10**c_idx).fit(train,label)\n",
    "\n",
    "svm_best = cross_validate(SVC(kernel='linear'), X_train_lsi, train_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**$\\therefore$ the best $\\gamma$ for SVM is 10**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "  kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
      "  shrinking=True, tol=0.001, verbose=False)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'ROC Curve of the best SVM')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEgCAYAAACegPWEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJztnXuYVWXZ/z9fUUBUBlRGRWCQRBBkMuWgBVYKnqLMQ0qpqelrqaXZq3lI8/yimWkeyjyEab6iYemPMQ+AoeCrcTAFDyCmgKiJIowgcr5/fzxrj5vNnpk9M3vttWdxf67ruWbWc1jP/d1rZt37OcvMcBzHcZzmskXSBjiO4zitG3ckjuM4TotwR+I4juO0CHckjuM4TotwR+I4juO0CHckjuM4TotwR+I4JUTS1ZI+kvSfAvNfLunPRar7HklXF+NejpONOxKn2UiaL+kzSSsk/Sd6UW2bk+fLkp6WtFxSraTxkvrl5Oko6SZJC6N7/Tu63rGeeiXpbEmvSPpU0iJJf5E0IE69LUVSD+C/gX5mtnOe9K9JWlR6y5pPITZL6ibp4ciB1kbP7WRJ7SUtk3RgnjI3ShoX/T5f0prcvwdJ/5JkknoWU5PTdNyROC3lm2a2LbA38CXgokyCpP2Bp4BHga7AbsDLwHOSekV52gKTgP7AoUBHYH9gCTC4njp/C5wDnA1sD+wBPAJ8o6nGS9qyqWVaQA9giZktLmGd5cB9wDtAFbADcCLwgZmtAh4Evp+dWVIb4LvAn7Ki347iMnkGAB3iNdspGDPz4KFZAZgPDM+6/hXwWNb1FOB3eco9Dtwb/X4a8AGwbYF19gbWA4MbyDMZOC3r+mRgata1AWcB8wgvqN8Dv865x6PAz6LfuwIPAx9G+c9uoO4K4N4o7wLgEsIXtuHAZ8AGYAVwT065bXLSV0T1Xg48FN1zOfAqMDCrXFNsuwe4HZgQ3esZoCorvW+U9jEwFzg2K+1w4LWo3LvAefXZnKfeFcDe9dj05eieHXLqWgxsmfV3dgkwPSvPr4FfRM+yZ9L/C5t7SNwAD603ZDsSoBswG/htdN0heuF/PU+5U4D3o9/HAn9qQp0/AhY0kqcQRzKB0JrZGjiA8I1ZUXrn6AXZNXICM4FfAm2BXsBbwCH11H0vwQltB/QE3gBOjdK+BixqwO5N0iNHsip6ubYBRgMvRGlNte2e6KV9ANCO0LKbGqVtE30GpwBbElqXHxG64QDeB4ZlfT77FKIpyjMReA4YBfTIk/4GcELW9QPATbl/ZwTntmf0OSwitHDckZRB8K4tp6U8Imk54SW0GLgsit+e8KJ7P0+Z94FMf/cO9eSpj6bmr4/RZvaxmX1GaDkZMCxKOwZ43szeAwYBXczsSjNbY2ZvAXcSXoobEXXJjAIuMrPlZjYfuIHQldMSpprZ381sPaGb6ItRfMG2ZfGYmT1rZqsJ3+j3l9QdGAnMN7MxZrbOzP5FaOl8Jyq3FugnqaOZLTWzF5tg/3cIn/GlwNuSXpI0KCv9XqLuLUkdgSPYuFsrw31RvhHA64SWkVMGuCNxWsq3zWw7wjfTvnzuIJYSujx2yVNmF8K3XQhjIfny1EdT89fHO5lfLHztHcvnffDfA+6Pfq8CukaDwsskLQMuBnbKc88dga0IXVoZFgC7ttDW7BleK4H20dhOU2zLkK17BaEbq2t0ryE59zoeyEwKOJrQKlog6Zlo/KsgIsdzoZn1j2x7ifAFRFGW+4CvS+pKcOL/jhxZLvcRns3JBOfjlAnuSJyiYGbPELpOfh1dfwo8z+ffaLM5ljDADqHb4xBJ2xRY1SSgm6SBDeT5lI0HYjeZIUVogWTzAHCMpCpgCOHbOIQX79tm1ikrbGdmh+e550eEb+5VWXE9KPybc1O34m6KbRm6Z36JZthtD7wX3euZnHtta2ZnAJjZdDM7AqgkTGx4qDk2m9lHhL+RrlHdmNkCQovlBELrLV9rJJPvbYJD+2tT6nXixR2JU0xuAkZIynS9XAicFE3V3U5S52gdw/7AFVGezIyehyX1lbSFpB0kXSxpkxeimc0Dfgc8EE09bRtNIx0l6cIo20vAUZI6SNodOLUxw6NvwB8BdwFPmtmyKGkasFzSBZK2ltRG0l45XTOZe6wnvGCvifRWAT8DCl0H8gGwg6SKAvMXbFsWh0saGs2Wu4ow3vIOUAPsIelESVtFYZCkPaPP+HhJFWa2FviE0NosyGZJ10V2bSlpO+AM4E0zW5KV7U/Aj4Gv8HlrMB+nAgdGX1ScMsEdiVM0zOxDQpfDL6PrqcAhwFGEcY0FhEHcoZFDIOqrHw7MIQyAf0J4Qe4I/LOeqs4GbgVuA5YB/waOBMZH6TcCawgvuT/R8Ispm/+NbPnfLE3rCeMHexO+DWecTX0vzp8QWkRvAVOje/2xkMrNbA6hZfRW1L3UtZH8TbWNyJ7LCF1a+xJaAZjZcuBgwvjKe4TutOsIg/IQWgrzJX1CmPBwfBNs7gD8jfCs3iK02L6Vk+dhQgtlkpnVOwZmZv82sxkN6HMSIDNLxXEcx3GahbdIHMdxnBbhjsRxHMdpEe5IHMdxnBbhjsRxHMdpEaXcsC4xdtxxR+vZs2fJ6lu1ahXt27cvWX2lxvW1XtKsDVxfsZk5c+ZHZtalsXybhSPp2bMnM2aUbsbgsmXL6NSpU8nqKzWur/WSZm3g+oqNpAWN5/KuLcdxHKeFuCOJgalTpyZtQqy4vtZLmrWB60sKdySO4zhOi3BH4jiO47SIkjsSSbtL+oOkWZLWS5pcYLkKSWMkLY3Ofb5f0g4xm9ssevfunbQJseL6Wi9p1gauLylKvteWpCMIG+69AOxFOLv5awWUe5JwNvd5hJ1Hr4vKDmuwIDBw4EAr5awtx3GcNCBpppk1dGQDkEzX1ngz625m3yGcP90o0SE6BwMnmdnDZvY3wq6lQyUNj9HWZjFhwoSkTYgV19d6SbM2cH1JUXJHYmYbGs+1CYcRWh/PZt1nGmHr7MOKZVuxWL16ddImxIrra72kWRu4vqRoLQsS+xLOq8jl9SjNaYBTxkzjH3M/LOIdxY+nPlbE+5UbadaXZm2wOegbOTJpGzaltTiSzoRDcXJZCvTKV0DS6cDpAF27dqWmpqYubejQocDGc7J79+5Nnz59mDBhQp3Xr6ioYNiwYcyaNYuFCxfW5R0+fDi1tbVMnz69Lm7AgAFUVVXV1VNTU0NlZSWDBw9m2rRpLF68uC7vyJEjWbBgAbNnz66LGzRoEBUVFUycOLEurkePHlRXV3PEDU/y8ofrGvuMHMfZDMh+l2XeEVOmTKG2thaAdu3aMWLECObOncu8efPq8jbnvVcoiR5sJWkcsGNjg+2SJgCfmtm3c+L/DPQysy83VL5cB9uL31Kon6/36cKYUwaXpC7HcdJBoYPtraVFshTIt3FY5yitrJg1axbV1dX1pjfHgZSTI2hMX2snzfrSrA1cX1K0FkcyB8g3zbcv8EiJbWmUhQsX1vuwc51IOTmIQmlIXxpIs740awPXlxStxZE8DlwqaaiZTQWQNJAwPvJ4opY1kYwTaY0OxHEcJx8ldySSOgCHR5e7Ah0lHRNd/93MVkp6E3jGzE4FMLPnJT0F3Cspe0HiVDObSCvhlDHT6n53J+I4TlpIYmV7T8L6j3zsZmbzJc0HJpvZyVnlOgE3AkcS1r/UAGeb2UeN1VnqwfZ8h89kd2m19taIHx7UekmzNnB9xaZsB9vNbD6gRvL0zBO3DDglCmVNbW3tJg87LU4E8utLE2nWl2Zt4PqSwnf/jYHs9SWQvi6tXH1pI8360qwNXF9SuCMpAdmtEcdxnLThjqSEpKE14jiOk4s7khgYMGBA3e/Z3VppIVtfGkmzvjRrA9eXFO5IYqCqqqru9zR2a2XrSyNp1pdmbeD6ksIdSQxkb6qWIU3dWvn0pYk060uzNnB9SeGOJEbS2K3lOI6TizuSGEljt5bjOE4u7khioLKyMnVrR7KprKxM2oRYSbO+NGsD15cUiZ5HUiqSOI+k54XhlLY0rGR3HGfzpNAtUrxFEgPTpqW3NQIb60sjadaXZm3g+pLCHUkMZB+rm0ZcX+slzdrA9SWFOxLHcRynRbgjcRzHcVqED7bHRGawff613yhpvY7jOMXCB9sTZNTvnknahFhZsGBB0ibESpr1pVkbuL6kcEcSAy8sXAGkdyHi7NmzkzYhVtKsL83awPUlhTuSGEnj1F/HcZxc3JE4juM4LcIdidNkBg0alLQJsZJmfWnWBq4vKdyROE2moqIiaRNiJc360qwNXF9SuCNxmszEiROTNiFW0qwvzdrA9SWFOxLHcRynRTTJkUjaVtIgSUdJqojiFI9pjuM4TmugIEeiwJXAe8A/gb8AX4iSH5f0y5jsc8qQHj16JG1CrKRZX5q1getLikJbJFcBPwUuAPoB2a2QR4BvFdkup4yprq5O2oRYSbO+NGsD15cUhTqSU4CLzOz3wLyctDeB3YtqlVPWTJkyJWkTYiXN+tKsDVxfUhTqSLYH5taTtmUUnM2E2trapE2IlTTrS7M2cH1JUagjeQ04vJ60g4GXCq1QUj9JkyStlPSepCsltSmg3EBJT0n6OAoTJQ0ptF7HcRwnHgptSYwGxkpqC4wDDNhT0mHAWcBRhdxEUmdgIsExHUEYsL+B4NAuaaBc96jci8CJUfT5wARJA8ysPLfETCnt2rVL2oRYSbO+NGsD15cUBZ9HIun7wLXAzlnRHwLnm9m9Bd7jIuDnQJWZfRLF/Ry4HNg5E5en3I+A24Dtzaw2iusMfAT8OBq7qZdSn0fiZ5E4jpMGin4eSeQsugF7A8OBfYCuhTqRiMOAJ3Mcxlhga+CrDZTbClgHfJoVtyKK83UsJWbu3PqGy9JBmvWlWRu4vqQodB3JzyXtbGYbzGyWmT1tZi+Z2XpJO0WtikLoC8zJjjCzhcDKKK0+Ho7y3CCpUlIlcCOwlLCmxSkh8+blTtxLF2nWl2Zt4PqSoiljJJOB/+RJ6xal/6qA+3QGluWJXxql5cXM3pP0daAGODuKfh84xMw+zFdG0unA6QBdu3alpqamLm3o0KEATJ06tS6ud+/e9OnThwkTJrB69WogbJA2bNgwZs2axcKFC+vyDh8+nNraWqZPn14XN2DAAKqqqqJ6QiNp2rRpDB48mGnTprF48eK6vCNHjmTBggUbHVIzaNAgKioqNtpLp0ePHlRXVzNlypS62Rrt2rVjxIgRzJ07d6M/qvg1BSorK+u0pUlT7nOqqalJnaYMadOU+5xqampSpynznDL6SqWpYMys0QBsAAbVk/ZNYEmB91kL/DRP/CLgfxootwth/cqjwKFRGB+V69FYvfvuu6+VkqoLaqzqgpqS1llKxo8fn7QJsZJmfWnWZub6ig0wwwp4t9fbIpF0PHB8xt8AN0nKncTcnjBWMrlAv7UUyLcPcucorT7OJ4yTHGNmayP7niY4l/P4vJXilIDMN5u0kmZ9adYGri8pGhoj2QCsj4JyrjNhKWE21ekF1jeHnLGQaGpvB3LGTnLoC7yacSIAZrYGeJXP9/xyHMdxEqBeR2JmD5jZN83sm8CDwEmZ66xwtJn9wswW13efHB4HDpG0XVbcccBnwDMNlFsA7BWtYwFAUjtgL2B+gXU7RSK7jzWNpFlfmrWB60uKgmZtmdl3zeytItR3O7Aa+Kuk4dGA+OXAbyxrSrCkNyXdnVXuLqAr8DdJ35A0krBZ5C7AHUWwy3Ecx2kmBe+RJWlX4LvAHoSxkY0ws+83dg8zWyrpIOBWwmD5MsI03svz2NUmq9xMSYcClwH3RdGzgRFm9nKhGhzHcZziU5AjkfRFYAphJXkVYTyjM2GV+/uErqeCMLPXgAMbydMzT9wkYFKh9Tjx0bt376RNiJU060uzNnB9SVHoyvZfE1oQexAG3k80s66EFe7rgUvjMc8pR/r06ZO0CbGSZn1p1gauLykKdSRfInQpbYiu2wOY2dOEQ6+uL75pTrkyYcKEpE2IlTTrS7M2cH1JUagj2QJYZWYbCBs1ds9KexsoTzfpxEJmBWxaSbO+NGsD15cUhTqS14Fe0e//BM6R1F3STsC5+BRcx3GczZZCZ23dDWROnf8F8CSfO49VwLHFNcspZyoq8m1OkB7SrC/N2sD1JUXB55FsVEjqBAwjbP/+nJm9W2zDiomfR+I4jtN0in4eSTZmtszMxpvZQ2b2brStu7OZ0KRdQVshadaXZm3g+pKiWY4kg6Q9JP0BHyPZrMjeLjuNpFlfmrWB60uKBh2JpKMkPSJppqRxkgZF8X0kPUw4e/04wup0x3EcZzOkXkcSndE+jrAx4juEWVuTJZ0GvERYnX454fz1X8RvquM4jlOONDRr66fAA4RV7BsgHLkL/AGYDow0s4/iN9EpN4YPH560CbGSZn1p1gauLyka6traHRiTcSIRdxK2SLnSncjmS+ZIz7SSZn1p1gauLykaciTbAp/kxGWu853d7gCnjJmWtAmxk30OdRpJs740awPXlxSNLUgcKGnbrOstCMfuDorWktQR7bu12fOPuR8C8PU+XRK2xHEcpzQ05khurSf+9znXRtb5IQ6MOWVw0iY4juOUhIYcyZ4ls8JpVQwYMCBpE2IlzfrSrA1cX1LU60jMbG4pDXFaD1VVVUmbECtp1pdmbeD6kqJFK9udzZOampqkTYiVNOtLszZwfUnhjsRxHMdpEe5IHMdxnBbhjsRpMpWV6d7sOc360qwNXF9SuCNxmszgweme2pxmfWnWBq4vKQp2JJK2l3SFpMckzZK0ZxR/hqRGDz5x0sO0aelevZ9mfWnWBq4vKQpyJJL2Ad4ETgGWAf0JpyNC2BX4/Fisc8qSxYsXJ21CrKRZX5q1getLikJbJDcBzxM2cjyJsHFjhueB/Ypsl+M4jtNKaGyLlAwDgSPNbI2k3K1QPgJ2Kq5ZjuM4Tmuh0BbJcmD7etJ2Az4sjjlOa2DkyJFJmxAradaXZm3g+pKiUEdSA1wuqXtWnEU7AP8MeKToljlly4IFC5I2IVbSrC/N2sD1JUWhjuQCYC0wB5gQxf0WyOzHdWmhFUrqJ2mSpJWS3pN0ZZ7usvrKHiVpuqTPJC2R9ISkbQqt2ykOs2fPTtqEWEmzvjRrA9eXFAU5kug0xIHAzwmztqYCHwNXA/uZ2bJC7iOpMzCRsO38EcCVwH8DVxRQ9jTgf4HHgcOA04B5FD7O4ziO48RAwS9hM1sF3BaF5vIjwrTho8zsE2CCpI6EbrNfRXGbIGlH4EbgJ2Z2Z1bS31pgi+M4jlMECl1H8pSkU3JPRWwGhwFP5jiMsQTn8tUGyh0b/fxTC+t3isCgQYOSNiFW0qwvzdrA9SVFoWMkqwmnIv5H0nhJ38s5grdQ+hLGWeows4XAyiitPoYQxmNOlbRI0lpJ/5T05WbY4LSQioqKpE2IlTTrS7M2cH1JUegYyTcJa0XOIHSH3QN8IGmcpO9Ial9gfZ0JYyy5LI3S6mNnoA9wCWHg/5vAp8ATknwNS4mZOHFi0ibESpr1pVkbuL6kaMoYSS0wBhgjaQfgaEKX0/3AZ0CcrlLAtsB3zOwJAEn/BywAfkyeWWOSTgdOB+jatetGB8IMHToUgKlTp9bF9e7dmz59+jBhwgRWr14NBO8/bNgwZs2axcKFC+vyDh8+nNraWqZPn14XN2DAgI1OL6upqaGyspLBgwczbdq0jbY2GDlyJAsWLNhoBsagQYOoqKjY6A+lR48eVFdXM2XKFGprawFo164dI0aMYO7cucybN68kmrI/u8zuo2nTlPucampqUqcpQ9o05T6nmpqa1GnKPKeMvlJpKhgza1YA9gWuB/4DrC+wzGLgsjzxnwLnN1DuQWAD0D4nfiLwcGP17rvvvlYqqi6osaoLakpWXxKMHz8+aRNiJc360qzNzPUVG2CGFfBub9LUWUnVwHGElkgv4N/AnYQB80KYQ85YSLTIsQM5Yyc5vE5olSgnXgQH45SQHj16JG1CrKRZX5q1getLikJnbV0h6XXgX8D3gL8Cg8xsDzO71MxeLbC+x4FDJG2XFXccoWvsmQbKZdpyX8+yqYLQKnq5wLqdIlFdXZ20CbGSZn1p1gauLykKnbV1GvAk8BUz283MLjCzF5tR3+2EGWB/lTQ8Gse4HPiNZU0JlvSmpLsz12Y2A3gUuFvSSZK+Afw/wmr7lqxrcZrBlClTkjYhVtKsL83awPUlRaFdW92i/rIWYWZLJR0E3AqMJ8zgupHgTHLtyt025QTCmMxvCF1hzwEHmtnSltrlNI3MoF5aSbO+NGsD15cU9ToSSVuY2YbPL5U7PrERWXkbxMxeAw5sJE/PPHErCNOPzyikHsdxHKc0NNS1tVZS5oDgdYRupIaCs5nQrl27pE2IlTTrS7M2cH1J0VDX1pnAW1m/t7hry0kHI0aMSNqEWEmzvjRrA9eXFPU6EjP7Q9bvt5fGHKc1MHfuXPr06ZO0GbGRZn1p1gauLykKnf77mqQB9aT1k/Racc1yypns1bJpJM360qwNXF9SFDr9ty9hh958bAv0Lo45juM4TmujoVlbHQhOIkNnSZU52doT9tx6NwbbHMdxnFZAQ4Pt5wOXEQbZDfh7PfkEXFRku5wyJrP5W1pJs740awPXlxQNOZKHgFcIjuIh4GLC0bbZrAHmmFl5dtw5juM4sVPvGImZvW5mD5vZOMLJhr+LrrPDeHcimx/Z21CnkTTrS7M2cH1JUdAWKWb2ZNyGOI7jOK2ThgbbFwLfNLOXJb1DIwsSzaw89zd2HMdxYqWhFsn9wEdZv/vKdgcIp6qlmTTrS7M2cH1J0dDK9ouyfr+wNOY4rYFyXFlbTNKsL83awPUlRaELEjdBUi9Jh0rqUkyDnPJnwoQJSZsQK2nWl2Zt4PqSotAtUm6RdGvW9ZGEo3H/DryRtUuwsxmwevXqpE2IlTTrS7M2cH1JUWiL5JvA81nX/wM8TDi3/RngmiLb5TiO47QSCnUkOwELASR9AegDjDaz+cDvgH1isc4pSyoqKpI2IVbSrC/N2sD1JUWhjmQpkBkLGQ4sNrNZ0bUBWxXbMKd8GTZsWNImxEqa9aVZG7i+pCjUkTwFXC7pVODnwListP7A/CLb5ZQxs2bNajxTKybN+tKsDVxfUhTqSH5G2HfrQuBF4NKstFHAxCLb5ZQxCxcuTNqEWEmzvjRrA9eXFIVukfIx8L160vYrqkWO4zhOq6IgR5JB0o7AEGB74GPgn2b2UcOlHMdxnDRTkCORtAXwa+AsNh5YXyPpNuA8M/MtVDYThg8fnrQJsZJmfWnWBq4vKQodI7kU+DFwNeHY3c7Rz2ui+Etisc4pS2pra5M2IVbSrC/N2sD1JUWhjuQHwC/N7Coze8PMaqOfVxFOUTwtPhOdcmP69OlJmxAradaXZm3g+pKiKQsSZ9aTNjNKdxzHcTZDCnUkbwLH1JN2TJTuOI7jbIYUOmtrNHCfpF0JixE/ACqB7xCO4T0xHvOccmTAgAFJmxAradaXZm3g+pKi0HUk90v6BLgSuBsQYWuUl4Fvm9n4+Ex0yo2qqqqkTYiVNOtLszZwfUlR8HkkZjbezL4EbA30BLY2s32a6kQk9ZM0SdJKSe9JulJSmyaU30LSDEkmaWRT6naKQ01NTdImxEqa9aVZG7i+pGiwRSKpLTCC4Dj+A0w2syVEOwE3FUmdCdupvAYcAXwBuIHg0AqdQnwa0K059TuO4zjFp15HIqmKsFlj9iHBSyUdY2b/aGZ9PyK0aI4ys0+ACZI6EjaE/FUUVy+RI7qGsOfXXc20wXEcxykiDXVt/QpoR2iRbA/sSzgV8Y4W1HcY8GSOwxhLcC5fLaD8VcBzwKQW2OC0kMrKyqRNiJU060uzNnB9SdGQI/kK8Aszm2Rmy8zsX8CpQC9JOzezvr4EZ1SHmS0EVkZp9SKpmrAw8rxm1u0UicGD032ycpr1pVkbuL6kaGiMpCubrg+ZR5ixtQthzKSpdAaW5YlfGqU1xC3ArWb2pqSejVUk6XTgdICuXbtuNEg1dOhQAKZOnVoX17t3b/r06cOECRPqzkWuqKhg2LBhzJo1a6Ptm4cPH05tbe1Gq0wHDBiw0YyKmpoaKisrGTx4MNOmTWPx4sV1aSNHjmTBggXMnj27Lm7QoEFUVFQwceLnO/L36NGD6upqpkyZUrc1Qrt27RgxYgRz585l3rx5JdGU/dllfyNKk6Y0Pqd8miorK9lpp51SpSmNz6k+TW+99RZLliwpmaaCMbO8AdgADMqJaxPFf6m+cg0FYC3w0zzxi4D/aaDcKILj6hhd9yRMPx5ZSL377ruvlYqqC2qs6oKaktWXBOPHj0/ahFhJs740azNzfcUGmGEFvGMbW0cyXtKaPPF/l7Q2xyH1KMBvLQXyHTrcOUrbBElbAdcD1wFbSOoEdIySt5G0nZktL6Bux3EcJwYaciTXxVDfHHLGQiR1BzqQM3aSxTaE6b6/iUI2Y4F/A7sX10zHcRynUGQlPEZE0kXA+UBVphUh6TzCivmdLc/0X0lbAkNzoncGHgAuBp42s382VO/AgQNtxowZRVDQOD0vfAyA+dd+oyT1OY7jxIWkmWY2sLF8Ba9sLxK3A6uBv0oaHg2IXw78JtuJSHpT0t0AZrbOzCZnB+CFKOvsxpyIU3wWLFiQtAmxkmZ9adYGri8pSupIzGwpcBBh0H48cAVwI+FMk2y2jPI4ZUj2TJI0kmZ9adYGri8pmnRmezEws9eAAxvJ07OR9PmEaciO4zhOwpS6a8txHMdJGe5InCYzaNCgpE2IlTTrS7M2cH1J0aSuLUlfAPYBugN/NrPF0fTdJWa2Mg4DnfKjoiLfUqD0kGZ9adYGri8pCmqRSNpa0r2EtR4PEBYIZrZyv4kw88rZTMjediKNpFlfmrWB60uKQru2biDsAvwtwsr07IHuxwi7+jqO4zibIYV2bX0H+G8zezzPaYZvA+V5/qPjOI4TO4W2SLYBPmggbUNxzHFaAz16FLKtWuslzfrSrA1cX1IU6khmAt+rJ+0owFeXb0ZUV1cnbUKspFlfmrWB60uKQh3JL4HvSqoBTiBs4T5c0p0EB3N5POY55ciUKVPPBiy4AAAdpElEQVSSNiFW0qwvzdrA9SVFQY7EwhnthwKVwB8Jg+3XEqYCH25mz8dmoVN2ZA7QSStp1pdmbeD6kqLgdSRm9jQwWFIFsAOwNNo7y3Ecx9mMafJeW2ZWC5SnW3RKQrt27ZI2IVbSrC/N2sD1JUVB55FEixEbxMy+XxSLYsDPI3Ecx2k6xT6PpHeeMBj4LmGhop9QuBkxd+7cpE2IlTTrS7M2cH1JUehg+/55Ql/CsbnvE044dDYT5s2bl7QJsZJmfWnWBq4vKVq0+6+Z/RsYDfy6OOY4juM4rY1ibCO/Gt8ixXEcZ7OloFlbknrliW4L7ElokbxYTKOc8mbo0KFJmxAradaXZm3g+pKi0Om/bxJWs+ciYDZwetEschzHcVoVhXZtHQYcnhMOBHqb2RfNrDynEjixMHXq1KRNiJU060uzNnB9SdFoi0RSO2Av4Ckzmx2/SY7jOE5rotEWiZmtJkzv3T5+cxzHcZzWRlO2kf9inIY4rYfevXsnbUKspFlfmrWB60uKQgfbzwHGSloJ/J1wyNVGg+9m5odbbSb06dMnaRNiJc360qwNXF9SNKVF0hv4A/AOsAZYmxOczYQJEyYkbUKspFlfmrWB60uKQlskZ5J/+q+zGbJ69eqkTYiVNOtLszZwfUlRryORdADwopmtMLPbS2iT4ziO04poqGvrH0C/UhnitB4qKiqSNiFW0qwvzdrA9SVFQ45EcVQoqZ+kSZJWSnpP0pWS2jRSZpCkMZLejMrNlXSZpPZx2Og0zLBhw5I2IVbSrC/N2sD1JUUxNm0sGEmdgYmE8ZYjCOtT/hu4opGixwFfAK4jrKq/DfgZcH9sxjr1MmvWrKRNiJU060uzNnB9SdHYYPvhkvoWciMza/QUReBHwNbAUWb2CTBBUkfgckm/iuLyca2ZfZR1PVnSKuAPkqrMbEEhNjrFYeHChVRXVydtRmykWV+atYHrS4rGHMkvC7yPAYU4ksOAJ3McxlhCS+OrwPi8N9/YiWT4V/SzK+COxHEcJyEa69r6OrBdAaFjgfX1BeZkR5jZQmBllNYU9gc2AP9uYjnHcRyniDTWIvnMzD4tYn2dgWV54pdGaQUhaWfgEuA+M1tcT57Tiba379q1KzU1NXVpmT39s3fS7N27N3369GHChAl1c7UrKioYNmwYs2bNYuHChXV5hw8fTm1tLdOnT6+LGzBgAFVVn5/vVVNTQ2VlJYMHD2batGksXvy5mSNHjmTBggXMnv35HpiDBg2ioqKCiRMn1sX16NGD6upqpkyZQm1tLQDt2rVjxIgRzJ07d6NjN+PUlP3ZVVZWMnz48NRpyn1ONTU1qdOUKZ82TbnPqaamJnWaMs9p2LBhG5WPW1OhyCz/OkNJG4D9zGxawXdrrDJpLXC+md2UE78IuNfMLi7gHm0JA/bdgH3NbGljZQYOHGgzZsxoptVNo+eFjwEw/9pvlKS+JPjggw/YaaedkjYjNtKsL83awPUVG0kzzWxgY/lKOmuL0PLINxG6c5TWIJJEGIvpDxxeiBNxik/2t6w0kmZ9adYGri8p6u3aMrM4nMwccsZCJHUHOpAzdlIPNxGmDY8ws0LyO47jODFT6hbJ48AhkrbLijsO+Ax4pqGCki4CfgycYGbleUyY4zjOZkipHcntwGrgr5KGRwPilwO/yZ4SHK1gvzvr+nvA/xC6td6VtF9W6FJaCc6AAQOSNiFW0qwvzdrA9SVFobv/FgUzWyrpIOBWwpqRZcCNBGeSa1f2tikHRz9PjkI2pwD3FNdSpyGyZ6elkTTrS7M2cH1JUeoWCWb2mpkdaGZbm9kuZnapma3PydPTzE7Ouj7ZzFRPuKfUGjZ3sqcfppE060uzNnB9SVFyR+I4juOkC3ckjuM4TotwR+I0mcrKyqRNiJU060uzNnB9SeGOxGkygwcPTtqEWEmzvjRrA9eXFO5InCYzbVrRds0pS9KsL83awPUlhTsSp8lkby6XRtKsL83awPUlhTsSx3Ecp0W4I3Ecx3FaRL3byKcJ30becRyn6ZTrNvJOCliwIN0nG6dZX5q1getLCnckTpPJPrUtjaRZX5q1getLipJu2ug4mxNr165l0aJFrFq1KmlT6ujatSuvv/560mbEhutrHu3bt6dbt25stdVWzSrvjsRxYmLRokVst9129OzZk3C4Z/IsW7aMTp06JW1GbLi+pmNmLFmyhEWLFrHbbrs16x7eteU0mUGDBiVtQqwUS9+qVavYYYcdysaJAGyzzTZJmxArrq/pSGKHHXZoUcvZHYnTZCoqKpI2IVaKqa+cnAhAmzZtGs/UinF9zaOlf6fuSJwmM3HixKRNiJU06/vkk08az9SKcX3J4I7EcZxEmT9/PnvttVfSZpSM0aNHs/vuu9OnTx+efPLJvHmefvpp9tlnH/baay9OOukk1q1bB4QxkiOPPJLq6moGDx7MK6+8Uldm2bJlHHPMMfTt25c999yT559/HoBLL72U6upq9t57bw4++GDee++9omtyR+I4mznr169vPFMZkXmpFgMzY8OGDUW7X2O89tprjB07lldffZUnnniCM888c5PPf8OGDZx00kmMHTuWV155haqqKv70pz8BcMMNN7D33nsza9Ys7r33Xs4555y6cueccw6HHnooc+bM4eWXX2bPPfcE4Pzzz2fWrFm89NJLjBw5kiuvvLLounzWltNkevTokbQJsRKHvsyOB8WmsR0Uvv3tb/POO++watUqzjnnHE444QQAtt12W374wx8yceJEbrvtNrbeemt+9rOfsWLFCnbccUfuuecedtllF+68807uuOMO1qxZw+677859991Hhw4dNqrj8ssvZ9ttt+W8884DYK+99qo7Evawww5j6NCh/N///R+77rorjz76KFtvvTUzZ87kBz/4AQAHH3xw3b3Wr1/PhRdeyOTJk1m9ejVnnXUWP/zhD5k8eTKXXnopnTt3Zs6cObzxxhsb2fDEE09w8cUXs3btWiorK5k0aVKDdh1yyCEMGTKEmTNncuyxx7JixQquv/56AO655x5mzJjBrbfeyp///Gduvvlm1qxZw5AhQ/jd737XonGKRx99lFGjRtGuXTt22203dt99d6ZNm8b+++9fl2fJkiW0bduWPfbYA4ARI0YwevRoTj31VObNm8exxx4LQN++fZk/fz4ffPAB7du359lnn+Wee+4BoG3btrRt2xaAjh071t37008/jWXczlskTpOprq5O2oRYSZO+P/7xj8ycOZMZM2Zw880389lnnwHhhTJkyBBefvllhgwZwk9+8hPGjRtX94L/xS9+AcBRRx3F9OnT677h3n333U2qf968eZx11lm8+uqrdOrUiYcffhiAU045hVtuuYWXX355o/x33303FRUVTJ8+nenTp3PnnXfy9ttvA/Diiy/y29/+dhMn8uGHH/Jf//VfPPzww8yePZu//OUvBdl15pln8uqrr3LmmWfyt7/9rS7twQcfZNSoUbz++us8+OCDPPfcc7z00ku0adOG+++/f5N7nXvuuey9996bhGuvvXaTvO+++y7du3evu+7WrRvvvvvuRnl23HFH1q1bR2Zbp3HjxvHOO+8AsM8++/DXv/4VCFvKL1iwgEWLFvH222/TpUsXTjnlFL70pS9x2mmn8emnn9bd8xe/+AXdu3fn/vvv9xaJUx5MmTKFYcOGJW1GbMShL6m9126++ea6l+Q777zDSy+9xEEHHUSbNm04+uijAZg7dy6vvPIKI0aMAEKrYJdddgHglVde4ZJLLmHZsmWsWLGCQw45pEn177bbbuy9994A7LvvvsyfP59ly5axbNkyDjjgAABOPPFEHn/8cQCeeuopZs2axbhx4wCora1l3rx5tG3blsGDB+dd5/DCCy9wwAEHsNtuu7F8+XK23377Ru2qqqpiv/32A6BLly706tWLF154gd69ezNnzhy+8pWvcNtttzFz5sy66eCfffZZ3hMKb7zxxiZ9Jo0hibFjx3LuueeyevVqDj744LpW0FlnncUll1zC3nvvzYABA/jSl75EmzZtWLduHS+++CK33HILQ4YM4ZxzzuHaa6/lqquuAuCaa67hmmuuYfTo0dx6661cccUVRbXZHYnTZGpra5M2IVbSom/y5MlMnDiR559/ng4dOvC1r32trkXSvn37upeTmdG/f/+6wdlsTj75ZB555BG++MUvcs899zB58uRN8my55ZYbjTNkr0do165d3e9t2rSpq78+zIxbbrllE4c1efLkgtZQZI83NGRX7r1GjRrFQw89RN++fTnyyCORhJlx0kknMXr06AbrPPfcc/nHP/6xSfyoUaO48MILN4rbdddd61oXEBat7rrrrpuU3X///ZkyZQoQnGumFbbNNtswZswYIHxWu+22G7169WLlypV069aNIUOGAHDMMcfkbREdf/zxHH744UV3JN615Tgppba2ls6dO9OhQwfmzJnDCy+8kDdfnz59+PDDD+scydq1a3n11VcBWL58Obvssgtr167N260D0LNnT1588UUgdD9luqLqo1OnTnTq1ImpU6cCbHTfQw45hN///vesXbsWgDfeeGOjLpp87Lfffjz77LN19X788cdNtuvII4/k0Ucf5YEHHmDUqFEAHHTQQYwbN67uMKmPP/4476aJN954Iy+99NImIdeJAHzrW99i7NixrF69mrfffpt58+blPT43U+fq1au57rrr+NGPfgSEZ7pmzRoA7rrrLg444AA6duzIzjvvTPfu3Zk7dy4AkyZNol+/fkDoxsvw6KOP0rdv33o/h+biLRKnyWR/y0wjadF36KGHcvvtt7PnnnvSp08f9ttvv7wDrW3btmXcuHGcffbZ1NbWsm7dOn7605/Sv39/rrrqKoYMGUKXLl0YMmQIy5cv36T80Ucfzb333kv//v0ZMmRI3SBxQ4wZM4Yf/OAHSNposP20005j/vz57LPPPpgZXbp04ZFHHmnwXl26dOGOO+7gqKOOYt26dey8885MmDChSXZ17tyZPffck9dee63uxd6vXz+uvvpqDj74YDZs2MBWW23FbbfdRlVVVaP66qN///4ce+yx9OvXjy233JLbbrutrmV4+OGHc9ddd9G1a1euv/56ampq2LBhA2eccQYHHnggEJzCiBEjkET//v03GrO65ZZbOP7441mzZg29evWqa7lceOGFzJ07ly222IKqqipuv/32ZttfH34eSZHx80icDK+//nrdFEzHKXfy/b36eSRObGSaz2klzfrKaSfiOHB9yeCOxGky2X2uaSTN+sr1RVQsXF8yuCNxnBjZHLqOndZPS/9O3ZE4Tky0b9+eJUuWuDNxyprMeSTt27dv9j1KPmtLUj/gFmB/YBlwF3CFmTW44Y+kCuAm4NsEB1gDnG1mS+K12Mll6NChSZsQK8XS161bNxYtWsSHH35YlPsVgw0bNvD+++8nbUZsuL7mkTkhsbmU1JFI6gxMBF4DjgC+ANxAcAyXNFL8IWAP4DRgA3Ad8AiQ3iXWTqtmq622avaJc3HhJwi2bspVX6m7tn4EbA0cZWYTzOx24ArgZ5I61ldI0v7AwcBJZvawmf0NOAEYKml4KQx3PiezkCytpFlfmrWB60uKUjuSw4AnzSz7dJaxBOfy1UbKfWBmz2YizGwa8HaU5jiO4yREqR1JX2BOdoSZLQRWRmkFl4t4vZFyjuM4TsyUerC9M2GAPZelUVpzyvXKV0DS6cDp0eUKSaVcZbajruOjEtZXanYE19dKSbM2cH3FpqD9YFK715aZ3QHckUTdkmYUsq1Aa8X1tV7SrA1cX1KUumtrKVCRJ75zlFbsco7jOE7MlNqRzCFnTENSd6AD+cdA6i0XUd/YieM4jlMiSu1IHgcOkbRdVtxxwGfAM42U21lS3UoxSQMJ4yOPx2FoC0mkS62EuL7WS5q1getLhJJuIx8tSHwNeIWwoLAX8BvgJjO7JCvfm8AzZnZqVtyTQG/gPD5fkLjYzHxBouM4ToKUtEViZkuBg4A2wHjCYsQbgctysm4Z5cnmOEKr5Y/AvcBM4Mg47XUcx3EaZ7M42MpxHMeJD9/9twlI6idpkqSVkt6TdKWk3JZTvnIVksZIWiqpVtL9knYohc1NoTn6JA2KtL0ZlZsr6TJJzd9KNCaa+/yyym8haYYkkzQyTlubQ0v0STpK0nRJn0laIukJSdvEbXOhtOB/b6CkpyR9HIWJkoaUwuamIGl3SX+QNEvSekmTCyxXFu+W1K4jKTZp33CyBfqOi/JeB8wDqoGrop9Hx2hyk2jh88twGtD8LVJjpCX6JJ0G3Ar8CjifMK3+QMrk/dBcbdGM0InAi8CJUfT5wARJA8xsQZx2N5H+wOHAC8BWTShXHu8WM/NQQAAuIqxZ6ZgV93PC9i4dGyi3P2DAAVlxg6O44UnrKoK+HfPEnR7pq0paV0v1ZeXtDHwInBppG5m0pmI9P2A58F9Ja4hB24+A9UBFznNcD5yRtK4cW7fI+n0cMLmAMmXzbvGurcJJ+4aTzdJnZvm2a/hX9LNr8cxrMc19fhmuAp4DJsVgWzForr5jo59/isuwItBcbVsB64BPs+JWRHEqtpEtwcw2NKNY2bxb3JEUTto3nGyuvnzsT2hm/7s4phWFZuuTVA38gDD1vFxprr4hwFzgVEmLJK2V9E9JX47P1CbTXG0PR3lukFQpqZIwS3Qp8JeYbC0lZfNucUdSOHFsONlQuVJTFDsl7Uzot77PzBYXybZi0BJ9twC3mtmbRbeqeDRX385AH8IzuwD4JuEb/BOSdiq2kc2kWdrM7D3g64Sxug+icBRwiJmVz7GVzads3i3uSJyiIaktYfBvBXBuwuYUBUmjCC/aq5O2JSYEbAucamb3m9kThOOs1wM/TtSyFiJpF0LLYyahq+ew6PfHJPVI0ra04Y6kcNK+4WSL7JQkwkLR/sDhFhaflhNN1idpK+B6wkyYLSR1AjIneW6Ts9VP0rTk79OAyZmIaCxiJtCviPa1hOZqO58wTnKMmT0ROcmjCU6ynLspC6Vs3i3uSAon7RtONldfhpsIUzOPMLNy0pWhOfq2IUz3/Q3hH3Mp8HKUNpbPJxWUA819fq8TWiW5g88ijHOVA83V1hd41czWZiLMbA3wKmEKcWunbN4t7kgKJ+0bTjZXH5IuInSDnGBm5XmodPP0rSD0sWeH70ZpFwPHx2Nqs2ju86uJfn49EyGpAtiXz51m0jRX2wJgr6jLFQBJ7YC9gPkx2FlqyufdkvT86dYSCM3F94EJwHDCWokVwNU5+d4E7s6JexJ4izDQ923CLJkpSWsqhj7ge4SukTHAfjmhS9K6ivH8ctJ7Up7rSFry9/lIVPYk4BuEl/OHQOekdbXwb3NfYC3wWKRrJOEFuxb4YtK6cmzvABwThecJrabMdYcGnl1ZvFsS/wBbUyD0GT9N+Cb0PmFtQZucPPOBe3LiOkUv2mXAJ8D/kmchX9KhOfqAe6IXa75wctKaivH8ctLL0pG08O9zW+D3wJKo7ERgQNJ6iqTtIOBZ4OMoPAN8LWk9Dfxd5Qs9G9BXFu8W37TRcRzHaRE+RuI4juO0CHckjuM4TotwR+I4juO0CHckjuM4TotwR+I4juO0CHckjuM4TotwR+KUBEmXR0fU5oaJTbzPVElj47Izq56rc+x8V9JfJPWKoZ7/ZF33jT6rjjn5TovsiP0I4+jY12ztyyW9JOkHzbzfKEnfL7adTvlQFkdpOpsNtcCheeLKlY8JK6Ih7M10NTBR0l5mtrJIddwO/DXrui9wGXAXYYFZhkeBV4DVRaq3EM4lHP3akbDq/W5JK82sqY58FGHR471Fts8pE9yROKVknZm9kLQRTWBtlr0vSHoX+AdwCPC3YlRgZouARQXk+5CwbUkpmZPRH7UcBwLfJ2xY6Th1eNeWUzZIOl/SDEmfSPpA0qOSGtylVVIPSeMkfSjpM0lvSro8J89XJT0raaWkJZL+IGnbZpg4M/rZM+veoyS9Imm1pIWSrpTUJiu9s6Q/Snpf0ipJCyTdnpVe17UlaTifO6h3om6lN6O0uq4tBd6RNDrP5/E3SZOzrneQdKekxVH9UyUNaqpwC0fBvgJ0z6nvFEnPSfo4CpMk7ZOV/mfCrtAHZXWVXZKVfpSkmZFt70u6VpJ/wW1l+ANzSkqel8R6+3yfnm7AzcBCwjkLZwDPSeptZsvrueWfgTbAaYSuoF5A76z6DiBs9vcwMBqoBK6N7j+qieb3jH5mXvyHAw8Q9jo6D9gbuBLYns8Phfot4Zv8OYQT+roDdbu15jCNcErhdcC3CC2QVbmZzMwkPQR8B7goS2tHwuFNP42u2xP2p9oG+O/ofmcRuud6W9NPsOxBOA88myrCfmtvAW2BE4ApkvqZ2QJCN113wvnqZ0dl3ons+x5wH2Gfr4sIzy3jHC9som1OkiS9WZmHzSMAl5N/Q7rh9eRvQ9gR9VPge1nxU4GxWdergMMaqPd5YEJO3MGEszb6NlDuaoLD2DIKfQib/9UCO0V5ZuS598XAOmCX6HoOcEZj9WRdfzv6XLrl5Dstim8fXQ+Krgdm5TmRsLPtjtH1D6PPp1dWnraEzf9GN2DT7tG9D4+0b09wRKuArzRQboso/5vAxVnxjwAT8+RdBNyZE3864Zz1sth52ENhwbu2nFJSS3gBZod/ZhIlfVnSRElLCC/jTwnOZI8G7vkScJ2kkxQOO6oj6r4aAjwkactMIDiEDYRtxhtiJ8KLeS3BIXQHvmNmHyicnrg34SjXbB4kOMH9suy7QNIZknpTJMxsOqEVcFxW9HHA02b2UXQ9HJgOLMzSvoGgf2AB1TxG0L4E+DXwMzN7LjuDpP6SHpH0AeHkwbWEiQkNPTOAPYFd2fTZPE1ovZTL6YxOAbgjcUrJOjObkROWA0jajXC2wnrCt9KvEBzNx0BDU16PIbysf0t4Yb4oKXNI0w6Ek/7u4HOHsJawFXkbcvr787AksmEgsKuZ7WZmT0VpldE9Psgpk7nePvp5BjCe0CJ7Q9Ibkr7TSL2F8iBwbDRm0pnQ0soeCN+R0I22NiecSOPaIXRFDSKc4/FP4EZJe2USFQ7AegroSpjhNSzK/woNP7OMbUTls22bF8UXYp9TJvgYiVMuHAa0A75tZp8BKJxs16mhQhZmPX0/GuAeTBij+H9R6yRzbvUlBCeVy7uN2LTOzGbUk7aY4PQqc+J3in5+HNm3FPiJpLOBasIYyAOSZpnZ3Ebqb4wHCWML+xG+4Rsbzyb7mDB99yd5ym4y9pKHeRn9kl4gvORHA9+M0r9CcCJfNbM3M4UUzrZvjI+jnz8AZudJf6uAezhlgjsSp1zYmvBiXpcVN4oCW81mth54XtKVhK6bHmY2S9J0YA8zu6aYxprZWkn/Igx435mVdCxBxws5+Q14WdIFhON6+xBOs8tlTfSz0YWHZvaypDmELq09gSfNbFlWlkmEA6DmZ3V3NQszWyLpeuAaSf3N7FXCM4OstS3R5IZuOcXXsKme1whjUD3NbExLbHOSxx2JUy5MAn4FjJE0BhhA6C75pL4CknYgdBvdB7xBeLGdB7zH5y/p84EJkiDM3FpBmGn0DeACM/t3C2y+DHhM0l2EsZIvErqwbjez9yMbnwceIhydKkK33XLC2EU+5kQ/z4hmZn1qZq80YMODwJmE42hPzkkbQxhwnyzpBsK3/B0JLZh3zOzmgpUGbgN+TviMTwH+jzAwfpekXxNmdV1G+PxzNR0u6QhCK/BdM3tf0nmE592J0GJcS5h1dyRwhJmVcvGl0xKSHu33sHkEwgv2o0bynEx42X1GeEkNJMzsuTYrT92sLYLjuIvgNFYSprf+P6B/zn33J7yoPiEM4L8G3AB0bMCWjWZTNZDvu4QxgTWRrRsdAQv8htB1s4LQ1fY0WTOf8tVDeFkvJLTO3oziNpq1lZW3bxS/Etg2j32dgFsi2zI2jgP2a0BTZtbWoXnSriS0QHaNrg+PPs9VwMuEnQtyZ9ZVEmZuLY3ue0lW2jei/J9Gz+dfUR1bJP0366Hw4EftOo7jOC3CZ205juM4LcIdieM4jtMi3JE4juM4LcIdieM4jtMi3JE4juM4LcIdieM4jtMi3JE4juM4LcIdieM4jtMi/j/1Z/pD0P66eAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ROC curve of the best\n",
    "\n",
    "print(svm_best)\n",
    "\n",
    "score = svm_best.decision_function(X_test_lsi)\n",
    "fpr, tpr, _ = metrics.roc_curve(test_label, score)\n",
    "\n",
    "plot_roc(fpr, tpr)\n",
    "plt.title('ROC Curve of the best SVM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Confusion Matrix of best SVM(C=10) --------------------\n",
      "[[1512   48]\n",
      " [  30 1560]]\n",
      "-------------------- Other Evaluation of best SVM(C=10) --------------------\n",
      "Accuracy: 0.9752380952380952\n",
      "Recall: 0.9811320754716981\n",
      "Precision: 0.9701492537313433\n",
      "F-1 Score: 0.975609756097561\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix of the best SVM and other metrics\n",
    "evaluate(svm_best, 'best SVM(C=10)', X_test_lsi, test_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5:\n",
    "Logistic classifier:\n",
    "- Train a logistic classifier without regularization (you may need to come up with some way to approximate this if you use sklearn.linear_model.LogisticRegression); plot the ROC curve and report the confusion matrix and calculate the **accuracy, recall precision** and **F-1 score** of this classifier.\n",
    "- Regularization:\n",
    "    * Using 5-fold cross-validation on the dimension-reduced-by-svd training data, find the best regularization strength in the range $\\lbrace10^k\\mid -3 \\leq k \\leq 3, k \\in \\mathbb Z\\rbrace$ for logistic regression with L1 regularization and logistic regression L2 regularization, respectively.\n",
    "    * Compare the performance (accuracy, precision, recall and F-1 score) of 3 logistic classifiers: w/o regularization, w/L1 regularization and w/L2 regularization (with the best parameters you found from the part above), using test data.\n",
    "    * How does the regularization parameter affect the test error? How are the learnt coefficients affected? Why might one be interested in each type of regularization?\n",
    "    * Both logistic regression and linear SVM are trying to classify data points using a linear decision boundary, then what's the difference between their ways to find this boundary?\n",
    "    <br>Why their performance differ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a logistic classifier without regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr_nonReg = LogisticRegression(C=float(10**6), solver='liblinear', random_state=42).fit(X_train_lsi, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'ROC Curve of Logistic Regression without Regularization')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot ROC curve\n",
    "score_nonReg = lr_nonReg.decision_function(X_test_lsi)\n",
    "fpr_nonReg, tpr_nonReg, _ = metrics.roc_curve(test_label, score_nonReg)\n",
    "\n",
    "plot_roc(fpr_nonReg, tpr_nonReg)\n",
    "plt.title('ROC Curve of Logistic Regression without Regularization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Confusion Matrix of Logistic Regression without Regularization --------------------\n",
      "[[1507   53]\n",
      " [  32 1558]]\n",
      "-------------------- Other Evaluation of Logistic Regression without Regularization --------------------\n",
      "Accuracy: 0.973015873015873\n",
      "Recall: 0.979874213836478\n",
      "Precision: 0.9671011793916822\n",
      "F-1 Score: 0.9734457981880662\n",
      "\n",
      "-------------------- Notes of Index --------------------\n",
      "labels are:\n",
      "Value of 0 -> Computer Technology\n",
      "Value of 1 -> Recreational Activity\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix and other metrics of Logistic Regression without regularization \n",
    "evaluate(lr_nonReg, 'Logistic Regression without Regularization', X_test_lsi, test_label)\n",
    "\n",
    "print()\n",
    "print('-'*20,'Notes of Index','-'*20)\n",
    "print('labels are:')\n",
    "print('Value of 0 ->',new_name[0])\n",
    "print('Value of 1 ->',new_name[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression with Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using 5-fold cross-validation to optimize the regularization strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- C = 0.001 --------------------\n",
      "[0.50704225 0.49366197 0.48098592 0.49014085 0.51690141]\n",
      "0.4977464788732394\n",
      "-------------------- C = 0.01 --------------------\n",
      "[0.50704225 0.49366197 0.48098592 0.49014085 0.51690141]\n",
      "0.4977464788732394\n",
      "-------------------- C = 0.1 --------------------\n",
      "[0.95915493 0.9528169  0.96126761 0.95633803 0.95422535]\n",
      "0.9567605633802817\n",
      "-------------------- C = 1 --------------------\n",
      "[0.96619718 0.96197183 0.96901408 0.96760563 0.96338028]\n",
      "0.9656338028169014\n",
      "-------------------- C = 10 --------------------\n",
      "[0.97464789 0.97394366 0.97535211 0.97464789 0.97183099]\n",
      "0.9740845070422536\n",
      "-------------------- C = 100 --------------------\n",
      "[0.97253521 0.97183099 0.97394366 0.97394366 0.97253521]\n",
      "0.9729577464788732\n",
      "-------------------- C = 1000 --------------------\n",
      "[0.97253521 0.97183099 0.97394366 0.97323944 0.97253521]\n",
      "0.9728169014084507\n",
      "-------------------- Result --------------------\n",
      "The best classifier is when C = 10\n",
      "Average Accuracy is: 0.9740845070422536\n"
     ]
    }
   ],
   "source": [
    "# L1 regularization\n",
    "lr_L1 = cross_validate(LogisticRegression(penalty='l1', solver='liblinear', random_state=42),\n",
    "                        X_train_lsi, train_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $\\therefore$ The best inverse of regularization strength for L1 is 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- C = 0.001 --------------------\n",
      "[0.50492958 0.69788732 0.93873239 0.83028169 0.48380282]\n",
      "0.6911267605633803\n",
      "-------------------- C = 0.01 --------------------\n",
      "[0.87957746 0.93521127 0.97112676 0.95422535 0.80140845]\n",
      "0.9083098591549295\n",
      "-------------------- C = 0.1 --------------------\n",
      "[0.96478873 0.96126761 0.97183099 0.96901408 0.95140845]\n",
      "0.9636619718309859\n",
      "-------------------- C = 1 --------------------\n",
      "[0.96971831 0.96478873 0.97464789 0.97042254 0.96478873]\n",
      "0.9688732394366196\n",
      "-------------------- C = 10 --------------------\n",
      "[0.97323944 0.96830986 0.97676056 0.97323944 0.96901408]\n",
      "0.9721126760563379\n",
      "-------------------- C = 100 --------------------\n",
      "[0.97535211 0.97183099 0.97535211 0.97183099 0.97394366]\n",
      "0.973661971830986\n",
      "-------------------- C = 1000 --------------------\n",
      "[0.97253521 0.97183099 0.97394366 0.97323944 0.97323944]\n",
      "0.9729577464788732\n",
      "-------------------- Result --------------------\n",
      "The best classifier is when C = 100\n",
      "Average Accuracy is: 0.973661971830986\n"
     ]
    }
   ],
   "source": [
    "# L2 regularization\n",
    "lr_L2 = cross_validate(LogisticRegression(penalty='l2', solver='liblinear', random_state=42),\n",
    "                        X_train_lsi, train_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $\\therefore$ The best inverse of regularization strength for L2 is 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare 3 classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Logistic Regression with w/o regularization --------------------\n",
      "Accuracy: 0.973015873015873\n",
      "Recall: 0.979874213836478\n",
      "Precision: 0.9671011793916822\n",
      "F-1 Score: 0.9734457981880662\n",
      "-------------------- Logistic Regression with w/L1 regularization --------------------\n",
      "Accuracy: 0.9720634920634921\n",
      "Recall: 0.979874213836478\n",
      "Precision: 0.9653035935563816\n",
      "F-1 Score: 0.9725343320848939\n",
      "-------------------- Logistic Regression with w/L2 regularization --------------------\n",
      "Accuracy: 0.9733333333333334\n",
      "Recall: 0.9811320754716981\n",
      "Precision: 0.966542750929368\n",
      "F-1 Score: 0.9737827715355806\n"
     ]
    }
   ],
   "source": [
    "# For test data, compare their performance\n",
    "\n",
    "y_pred_nonReg = lr_nonReg.predict(X_test_lsi)\n",
    "y_pred_L1 = lr_L1.predict(X_test_lsi)\n",
    "y_pred_L2 = lr_L2.predict(X_test_lsi)\n",
    "\n",
    "accuracy_nonReg = metrics.accuracy_score(test_label, y_pred_nonReg)\n",
    "accuracy_L1 = metrics.accuracy_score(test_label, y_pred_L1)\n",
    "accuracy_L2 = metrics.accuracy_score(test_label, y_pred_L2)\n",
    "\n",
    "recall_nonReg = metrics.recall_score(test_label, y_pred_nonReg)\n",
    "recall_L1 = metrics.recall_score(test_label, y_pred_L1)\n",
    "recall_L2 = metrics.recall_score(test_label, y_pred_L2)\n",
    "\n",
    "precision_nonReg = metrics.precision_score(test_label, y_pred_nonReg)\n",
    "precision_L1 = metrics.precision_score(test_label, y_pred_L1)\n",
    "precision_L2 = metrics.precision_score(test_label, y_pred_L2)\n",
    "\n",
    "Fscore_nonReg = metrics.f1_score(test_label, y_pred_nonReg)\n",
    "Fscore_L1 = metrics.f1_score(test_label, y_pred_L1)\n",
    "Fscore_L2 = metrics.f1_score(test_label, y_pred_L2)\n",
    "\n",
    "# show time\n",
    "\n",
    "print('-'*20, 'Logistic Regression with w/o regularization','-'*20)\n",
    "print('Accuracy:',accuracy_nonReg)\n",
    "print('Recall:',recall_nonReg)\n",
    "print('Precision:',precision_nonReg)\n",
    "print('F-1 Score:',Fscore_nonReg)\n",
    "\n",
    "print('-'*20, 'Logistic Regression with w/L1 regularization','-'*20)\n",
    "print('Accuracy:',accuracy_L1)\n",
    "print('Recall:',recall_L1)\n",
    "print('Precision:',precision_L1)\n",
    "print('F-1 Score:',Fscore_L1)\n",
    "\n",
    "print('-'*20, 'Logistic Regression with w/L2 regularization','-'*20)\n",
    "print('Accuracy:',accuracy_L2)\n",
    "print('Recall:',recall_L2)\n",
    "print('Precision:',precision_L2)\n",
    "print('F-1 Score:',Fscore_L2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Confusion Matrix of w/o regularization --------------------\n",
      "[[1507   53]\n",
      " [  32 1558]]\n",
      "-------------------- Confusion Matrix of w/L1 regularization --------------------\n",
      "[[1504   56]\n",
      " [  32 1558]]\n",
      "-------------------- Confusion Matrix of w/L2 regularization --------------------\n",
      "[[1506   54]\n",
      " [  30 1560]]\n",
      "-------------------- Notes of Index --------------------\n",
      "labels are:\n",
      "Value of 0 -> Computer Technology\n",
      "Value of 1 -> Recreational Activity\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix \n",
    "\n",
    "CM_nonReg = metrics.confusion_matrix(test_label, y_pred_nonReg)\n",
    "CM_L1 = metrics.confusion_matrix(test_label, y_pred_L1)\n",
    "CM_L2 = metrics.confusion_matrix(test_label, y_pred_L2)\n",
    "\n",
    "# show time\n",
    "print('-'*20, 'Confusion Matrix of w/o regularization','-'*20)\n",
    "print(CM_nonReg)\n",
    "print('-'*20, 'Confusion Matrix of w/L1 regularization','-'*20)\n",
    "print(CM_L1)\n",
    "print('-'*20, 'Confusion Matrix of w/L2 regularization','-'*20)\n",
    "print(CM_L2)\n",
    "print('-'*20, 'Notes of Index','-'*20)\n",
    "print('labels are:')\n",
    "print('Value of 0 ->',new_name[0])\n",
    "print('Value of 1 ->',new_name[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Coefficients of w/o regularization --------------------\n",
      "[[ -4.82227468 124.04432871 -25.16035881  91.53510578  14.6348396\n",
      "  -17.44440009  -3.434508     1.51007109  24.0498891   18.3969862\n",
      "   33.45209612  -4.58073603 -12.29631953  11.73037924 -16.70782175\n",
      "   -2.57166256 -10.72619183  13.46550213  16.53555859   3.34556521\n",
      "   -0.89393895  -1.28185099  -4.37428383   5.91357888  10.01942029\n",
      "   -3.52488137  16.88711953  -6.90756099 -12.79918896  21.17840376\n",
      "    1.47271195 -10.74987683  11.59541362  -4.45628672  -7.27049459\n",
      "    1.64818731  10.14868016 -11.84525038   3.75176382   8.47487332\n",
      "    6.4412368   15.76628075 -11.60271396   3.92011692   2.62737915\n",
      "   -5.56168779 -11.21385135   4.0024145    7.98094118  -5.18590256]]\n",
      "-------------------- Coefficients of w/L1 regularization --------------------\n",
      "[[ -2.04715848 106.2594828  -18.1330126   73.90277308  11.4063873\n",
      "  -11.25435226  -1.64745972   0.          18.07938578  15.31649281\n",
      "   27.28744345  -4.02875985  -9.33645304   6.87199647 -13.4188939\n",
      "    0.          -7.07889185   7.90094613  12.63623293   2.41058466\n",
      "    0.           0.          -3.84509294   2.8681963    6.34291341\n",
      "   -1.18460636  13.85088223  -4.46930875  -9.29987336  17.03016534\n",
      "    0.          -5.69055324   7.45445359  -1.2289182   -3.15664312\n",
      "    0.7260542    6.80966594  -8.70932238   1.72307869   7.2052753\n",
      "    5.19214443  11.93539065  -7.87358252   0.64107627   0.\n",
      "   -4.30909045  -8.05268962   1.63897863   4.4200187   -1.92986537]]\n",
      "-------------------- Coefficients of w/L2 regularization --------------------\n",
      "[[ -1.80574391  84.4162102  -15.19463256  58.80136108   8.56720101\n",
      "   -8.58725551  -2.35819941  -0.1795704   14.97082934  13.60928514\n",
      "   22.74658521  -4.84533522  -7.96722821   6.47179954  -9.88313175\n",
      "   -1.93067748  -6.44336423   9.35303303   9.70361268   2.97531115\n",
      "   -0.56287474  -1.20049871  -3.94668122   2.02709011   8.4714677\n",
      "   -2.94014203   9.68399684  -4.27898045  -7.33054535  13.92009648\n",
      "    0.61335404  -5.44999424   5.44989476  -1.14252567  -3.75014237\n",
      "    1.25088043   4.97317518  -6.0489856    1.00255284   6.14734352\n",
      "    4.30216972   8.23015096  -7.34139904   0.71762537   0.75663648\n",
      "   -4.15753854  -6.60890191   1.9478189    4.29269555  -1.71441291]]\n"
     ]
    }
   ],
   "source": [
    "# Learnt coefficients\n",
    "print('-'*20, 'Coefficients of w/o regularization','-'*20)\n",
    "print(lr_nonReg.coef_)\n",
    "print('-'*20, 'Coefficients of w/L1 regularization','-'*20)\n",
    "print(lr_L1.coef_)\n",
    "print('-'*20, 'Coefficients of w/L2 regularization','-'*20)\n",
    "print(lr_L2.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6:\n",
    "Naive  Bayes classifier: Train a GaussianNB classifier; plot the ROC curve and report the confusion matrix and calculate the **accuracy, recall, precision** and **F-1 score** of this classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "bayes = GaussianNB().fit(X_train_lsi, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'ROC Curve of GaussianNB')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ROC curve for GaussianNB\n",
    "score_bayes = bayes.predict_proba(X_test_lsi)[:,1]\n",
    "fpr_bayes, tpr_bayes, _ = metrics.roc_curve(test_label, score_bayes)\n",
    "\n",
    "plot_roc(fpr_bayes, tpr_bayes)\n",
    "plt.title('ROC Curve of GaussianNB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Confusion Matrix of GaussianNB --------------------\n",
      "[[1316  244]\n",
      " [  50 1540]]\n",
      "-------------------- Other Evaluation of GaussianNB --------------------\n",
      "Accuracy: 0.9066666666666666\n",
      "Recall: 0.9685534591194969\n",
      "Precision: 0.8632286995515696\n",
      "F-1 Score: 0.9128630705394191\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "evaluate(bayes, 'GaussianNB', X_test_lsi, test_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 7:\n",
    "Grid search of parameters:\n",
    "- Construct a Pipeline that performs feature extraction,, dimensionality reduction and classification;\n",
    "- Do grid search with 5-fold cross-validation to compare the following (use test accuracy as the score to compare);\n",
    "- What is the best combination?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:0.9736507936507937\n"
     ]
    }
   ],
   "source": [
    "# prepare for pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(min_df=3, analyzer=stem_rmv_nums)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('reduce_dim', TruncatedSVD(n_components=50, random_state=42)),\n",
    "    ('clf', SVC(kernel='linear', C=100, random_state=42))\n",
    "])\n",
    "\n",
    "pipeline.fit(train_dataset.data, train_label)\n",
    "predict = pipeline.predict(test_dataset.data)\n",
    "print(\"accuracy:{}\".format(metrics.accuracy_score(test_label, predict)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Grid Search\n",
    "Compare Table:\n",
    "\n",
    "| Procedure | Options |\n",
    "| ------- | ----- | \n",
    "| Loading Data | remove \"headers\" and \"footers\" vs not | \n",
    "| Feature Extraction | min_df = 3 vs 5 <br> use lemmatization vs not |\n",
    "| Dimensionality Reduction | LSI vs NMF |\n",
    "| Classifier | SVM with the best $\\gamma$ <br> vs <br> Logistic Regression: L1 regularization <br> vs L2 regularization, <br> with the best regularization strength previously found <br> vs <br> GaussianNB |\n",
    "| Other options | Use default |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=3,\n",
      "        ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
      "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None), \n",
      "[ 'From: rschmitt@shearson.com (Robert Schmitt)\\n'\n",
      "  'Subject: Re: Please Recommend 3D Graphics Library F\\n'\n",
      "  'Reply-To: rschmitt@shearson.com\\n'\n",
      "  'Organization: Lehman Brothers, Inc.\\n'\n",
      "  'Lines: 9\\n'\n",
      "  '\\n'\n",
      "  'What hardware do plan to run on?  Workstation or PC?  Cost level?\\n'\n",
      "  'Run-time licensing needs?\\n'\n",
      "  '\\n'\n",
      "  'Bob\\n'\n",
      "  '------------------------------------------------------------------\\n'\n",
      "  'Robert A. Schmitt | Applied Derivatives Technology | Lehman Brothers\\n'\n",
      "  'rschmitt@shearson.com\\n'\n",
      "  '\\n'\n",
      "  '\\n',\n",
      "  'From: mori@volga.mfd.cs.fujitsu.co.jp (Tsuyoshi Mori)\\n'\n",
      "  'Subject: I want use DeskJet on System7\\n'\n",
      "  'Organization: FUJITSU.Ltd., Kawasaki, Japan.\\n'\n",
      "  'Lines: 15\\n'\n",
      "  'Di..., \n",
      "[ 0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "..., \n",
      "None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/pipeline.py:230: UserWarning: Persisting input arguments took 3.48s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________fit_transform_one - 3.4s, 0.1min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True), <3785x17574 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 329115 stored elements in Compressed Sparse Row format>, \n",
      "[ 0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "..., \n",
      "None)\n",
      "________________________________________________fit_transform_one - 0.1s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), \n",
      "<3785x17574 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 329115 stored elements in Compressed Sparse Row format>, \n",
      "[ 0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "..., \n",
      "None)\n",
      "________________________________________________fit_transform_one - 0.7s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=3,\n",
      "        ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
      "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None), \n",
      "[ 'From: sac@asdi.saic.com (Steve A. Conroy x6172)\\n'\n",
      "  'Subject: Re: Darrrrrrrrryl\\n'\n",
      "  'Organization: SAIC\\n'\n",
      "  'Lines: 33\\n'\n",
      "  '\\n'\n",
      "  'In article <mssC5KCru.5Ip@netcom.com>, mss@netcom.com (Mark Singer) '\n",
      "  'writes:\\n'\n",
      "  '|> \\n'\n",
      "  '|> \\n'\n",
      "  '|> The media is beating the incident at Dodger Stadium on Wednesday to\\n'\n",
      "  \"|> death, but I haven't seen anything in rsb yet.\\n\"\n",
      "  '|> \\n'\n",
      "  '|> Gerald Perry of the Cardinals pinch hit in the eighth inning with two\\n'\n",
      "  '|> on and his club down by a run.  He stroked a line drive into the\\n'\n",
      "  '|> right field corner.  The ball cleared the three-foot high fence and\\n'\n",
      "  '|> went into the crowd.  Darryl, racing over from right center, got to\\n'\n",
      "  '|> th..., \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "..., \n",
      "None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/pipeline.py:230: UserWarning: Persisting input arguments took 3.09s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________fit_transform_one - 3.0s, 0.1min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True), <3785x17232 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 324344 stored elements in Compressed Sparse Row format>, \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "..., \n",
      "None)\n",
      "________________________________________________fit_transform_one - 0.1s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), \n",
      "<3785x17232 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 324344 stored elements in Compressed Sparse Row format>, \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "..., \n",
      "None)\n",
      "________________________________________________fit_transform_one - 0.7s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=3,\n",
      "        ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
      "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None), \n",
      "[ 'From: sac@asdi.saic.com (Steve A. Conroy x6172)\\n'\n",
      "  'Subject: Re: Darrrrrrrrryl\\n'\n",
      "  'Organization: SAIC\\n'\n",
      "  'Lines: 33\\n'\n",
      "  '\\n'\n",
      "  'In article <mssC5KCru.5Ip@netcom.com>, mss@netcom.com (Mark Singer) '\n",
      "  'writes:\\n'\n",
      "  '|> \\n'\n",
      "  '|> \\n'\n",
      "  '|> The media is beating the incident at Dodger Stadium on Wednesday to\\n'\n",
      "  \"|> death, but I haven't seen anything in rsb yet.\\n\"\n",
      "  '|> \\n'\n",
      "  '|> Gerald Perry of the Cardinals pinch hit in the eighth inning with two\\n'\n",
      "  '|> on and his club down by a run.  He stroked a line drive into the\\n'\n",
      "  '|> right field corner.  The ball cleared the three-foot high fence and\\n'\n",
      "  '|> went into the crowd.  Darryl, racing over from right center, got to\\n'\n",
      "  '|> th..., \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "..., \n",
      "None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/pipeline.py:230: UserWarning: Persisting input arguments took 4.25s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________fit_transform_one - 3.4s, 0.1min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True), <3785x17671 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 328511 stored elements in Compressed Sparse Row format>, \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "..., \n",
      "None)\n",
      "________________________________________________fit_transform_one - 0.1s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), \n",
      "<3785x17671 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 328511 stored elements in Compressed Sparse Row format>, \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "..., \n",
      "None)\n",
      "________________________________________________fit_transform_one - 1.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=3,\n",
      "        ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
      "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None), \n",
      "[ 'From: sac@asdi.saic.com (Steve A. Conroy x6172)\\n'\n",
      "  'Subject: Re: Darrrrrrrrryl\\n'\n",
      "  'Organization: SAIC\\n'\n",
      "  'Lines: 33\\n'\n",
      "  '\\n'\n",
      "  'In article <mssC5KCru.5Ip@netcom.com>, mss@netcom.com (Mark Singer) '\n",
      "  'writes:\\n'\n",
      "  '|> \\n'\n",
      "  '|> \\n'\n",
      "  '|> The media is beating the incident at Dodger Stadium on Wednesday to\\n'\n",
      "  \"|> death, but I haven't seen anything in rsb yet.\\n\"\n",
      "  '|> \\n'\n",
      "  '|> Gerald Perry of the Cardinals pinch hit in the eighth inning with two\\n'\n",
      "  '|> on and his club down by a run.  He stroked a line drive into the\\n'\n",
      "  '|> right field corner.  The ball cleared the three-foot high fence and\\n'\n",
      "  '|> went into the crowd.  Darryl, racing over from right center, got to\\n'\n",
      "  '|> th..., \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "..., \n",
      "None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/pipeline.py:230: UserWarning: Persisting input arguments took 2.65s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________fit_transform_one - 2.9s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True), <3786x17321 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 327753 stored elements in Compressed Sparse Row format>, \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "..., \n",
      "None)\n",
      "________________________________________________fit_transform_one - 0.1s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), \n",
      "<3786x17321 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 327753 stored elements in Compressed Sparse Row format>, \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "..., \n",
      "None)\n",
      "________________________________________________fit_transform_one - 0.7s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=3,\n",
      "        ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
      "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None), \n",
      "[ 'From: sac@asdi.saic.com (Steve A. Conroy x6172)\\n'\n",
      "  'Subject: Re: Darrrrrrrrryl\\n'\n",
      "  'Organization: SAIC\\n'\n",
      "  'Lines: 33\\n'\n",
      "  '\\n'\n",
      "  'In article <mssC5KCru.5Ip@netcom.com>, mss@netcom.com (Mark Singer) '\n",
      "  'writes:\\n'\n",
      "  '|> \\n'\n",
      "  '|> \\n'\n",
      "  '|> The media is beating the incident at Dodger Stadium on Wednesday to\\n'\n",
      "  \"|> death, but I haven't seen anything in rsb yet.\\n\"\n",
      "  '|> \\n'\n",
      "  '|> Gerald Perry of the Cardinals pinch hit in the eighth inning with two\\n'\n",
      "  '|> on and his club down by a run.  He stroked a line drive into the\\n'\n",
      "  '|> right field corner.  The ball cleared the three-foot high fence and\\n'\n",
      "  '|> went into the crowd.  Darryl, racing over from right center, got to\\n'\n",
      "  '|> th..., \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "..., \n",
      "None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/pipeline.py:230: UserWarning: Persisting input arguments took 2.91s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________fit_transform_one - 2.6s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True), <3787x17420 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 328453 stored elements in Compressed Sparse Row format>, \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "..., \n",
      "None)\n",
      "________________________________________________fit_transform_one - 0.1s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), \n",
      "<3787x17420 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 328453 stored elements in Compressed Sparse Row format>, \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "..., \n",
      "None)\n",
      "________________________________________________fit_transform_one - 0.6s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(CountVectorizer(analyzer=<function stem_rmv_nums at 0x12655c7b8>,\n",
      "        binary=False, decode_error='strict', dtype=<class 'numpy.int64'>,\n",
      "        encoding='utf-8', input='content', lowercase=True, max_df=1.0,\n",
      "        max_features=None, min_df=3, ngram_range=(1, 1), preprocessor=None,\n",
      "        stop_words=None, strip_accents=None,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, vocabulary=None), \n",
      "[ 'From: rschmitt@shearson.com (Robert Schmitt)\\n'\n",
      "  'Subject: Re: Please Recommend 3D Graphics Library F\\n'\n",
      "  'Reply-To: rschmitt@shearson.com\\n'\n",
      "  'Organization: Lehman Brothers, Inc.\\n'\n",
      "  'Lines: 9\\n'\n",
      "  '\\n'\n",
      "  'What hardware do plan to run on?  Workstation or PC?  Cost level?\\n'\n",
      "  'Run-time licensing needs?\\n'\n",
      "  '\\n'\n",
      "  'Bob\\n'\n",
      "  '------------------------------------------------------------------\\n'\n",
      "  'Robert A. Schmitt | Applied Derivatives Technology | Lehman Brothers\\n'\n",
      "  'rschmitt@shearson.com\\n'\n",
      "  '\\n'\n",
      "  '\\n',\n",
      "  'From: mori@volga.mfd.cs.fujitsu.co.jp (Tsuyoshi Mori)\\n'\n",
      "  'Subject: I want use DeskJet on System7\\n'\n",
      "  'Organization: FUJITSU.Ltd., Kawasaki, Japan.\\n'\n",
      "  'Lines: 15\\n'\n",
      "  'Di..., \n",
      "[ 0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "..., \n",
      "None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/pipeline.py:230: UserWarning: Persisting input arguments took 3.43s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______________________________________________fit_transform_one - 72.3s, 1.2min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True), <3785x14193 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 293436 stored elements in Compressed Sparse Row format>, \n",
      "[ 0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "..., \n",
      "None)\n",
      "________________________________________________fit_transform_one - 0.1s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), \n",
      "<3785x14193 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 293436 stored elements in Compressed Sparse Row format>, \n",
      "[ 0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "..., \n",
      "None)\n",
      "________________________________________________fit_transform_one - 1.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(CountVectorizer(analyzer=<function stem_rmv_nums at 0x12655c7b8>,\n",
      "        binary=False, decode_error='strict', dtype=<class 'numpy.int64'>,\n",
      "        encoding='utf-8', input='content', lowercase=True, max_df=1.0,\n",
      "        max_features=None, min_df=3, ngram_range=(1, 1), preprocessor=None,\n",
      "        stop_words=None, strip_accents=None,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, vocabulary=None), \n",
      "[ 'From: sac@asdi.saic.com (Steve A. Conroy x6172)\\n'\n",
      "  'Subject: Re: Darrrrrrrrryl\\n'\n",
      "  'Organization: SAIC\\n'\n",
      "  'Lines: 33\\n'\n",
      "  '\\n'\n",
      "  'In article <mssC5KCru.5Ip@netcom.com>, mss@netcom.com (Mark Singer) '\n",
      "  'writes:\\n'\n",
      "  '|> \\n'\n",
      "  '|> \\n'\n",
      "  '|> The media is beating the incident at Dodger Stadium on Wednesday to\\n'\n",
      "  \"|> death, but I haven't seen anything in rsb yet.\\n\"\n",
      "  '|> \\n'\n",
      "  '|> Gerald Perry of the Cardinals pinch hit in the eighth inning with two\\n'\n",
      "  '|> on and his club down by a run.  He stroked a line drive into the\\n'\n",
      "  '|> right field corner.  The ball cleared the three-foot high fence and\\n'\n",
      "  '|> went into the crowd.  Darryl, racing over from right center, got to\\n'\n",
      "  '|> th..., \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "..., \n",
      "None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/pipeline.py:230: UserWarning: Persisting input arguments took 1.97s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______________________________________________fit_transform_one - 57.5s, 1.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True), <3785x13776 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 288757 stored elements in Compressed Sparse Row format>, \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "..., \n",
      "None)\n",
      "________________________________________________fit_transform_one - 0.1s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), \n",
      "<3785x13776 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 288757 stored elements in Compressed Sparse Row format>, \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "..., \n",
      "None)\n",
      "________________________________________________fit_transform_one - 0.5s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(CountVectorizer(analyzer=<function stem_rmv_nums at 0x12655c7b8>,\n",
      "        binary=False, decode_error='strict', dtype=<class 'numpy.int64'>,\n",
      "        encoding='utf-8', input='content', lowercase=True, max_df=1.0,\n",
      "        max_features=None, min_df=3, ngram_range=(1, 1), preprocessor=None,\n",
      "        stop_words=None, strip_accents=None,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, vocabulary=None), \n",
      "[ 'From: sac@asdi.saic.com (Steve A. Conroy x6172)\\n'\n",
      "  'Subject: Re: Darrrrrrrrryl\\n'\n",
      "  'Organization: SAIC\\n'\n",
      "  'Lines: 33\\n'\n",
      "  '\\n'\n",
      "  'In article <mssC5KCru.5Ip@netcom.com>, mss@netcom.com (Mark Singer) '\n",
      "  'writes:\\n'\n",
      "  '|> \\n'\n",
      "  '|> \\n'\n",
      "  '|> The media is beating the incident at Dodger Stadium on Wednesday to\\n'\n",
      "  \"|> death, but I haven't seen anything in rsb yet.\\n\"\n",
      "  '|> \\n'\n",
      "  '|> Gerald Perry of the Cardinals pinch hit in the eighth inning with two\\n'\n",
      "  '|> on and his club down by a run.  He stroked a line drive into the\\n'\n",
      "  '|> right field corner.  The ball cleared the three-foot high fence and\\n'\n",
      "  '|> went into the crowd.  Darryl, racing over from right center, got to\\n'\n",
      "  '|> th..., \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "..., \n",
      "None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/pipeline.py:230: UserWarning: Persisting input arguments took 2.02s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______________________________________________fit_transform_one - 58.3s, 1.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True), <3785x14278 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 292930 stored elements in Compressed Sparse Row format>, \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "..., \n",
      "None)\n",
      "________________________________________________fit_transform_one - 0.1s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), \n",
      "<3785x14278 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 292930 stored elements in Compressed Sparse Row format>, \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "..., \n",
      "None)\n",
      "________________________________________________fit_transform_one - 0.5s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(CountVectorizer(analyzer=<function stem_rmv_nums at 0x12655c7b8>,\n",
      "        binary=False, decode_error='strict', dtype=<class 'numpy.int64'>,\n",
      "        encoding='utf-8', input='content', lowercase=True, max_df=1.0,\n",
      "        max_features=None, min_df=3, ngram_range=(1, 1), preprocessor=None,\n",
      "        stop_words=None, strip_accents=None,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, vocabulary=None), \n",
      "[ 'From: sac@asdi.saic.com (Steve A. Conroy x6172)\\n'\n",
      "  'Subject: Re: Darrrrrrrrryl\\n'\n",
      "  'Organization: SAIC\\n'\n",
      "  'Lines: 33\\n'\n",
      "  '\\n'\n",
      "  'In article <mssC5KCru.5Ip@netcom.com>, mss@netcom.com (Mark Singer) '\n",
      "  'writes:\\n'\n",
      "  '|> \\n'\n",
      "  '|> \\n'\n",
      "  '|> The media is beating the incident at Dodger Stadium on Wednesday to\\n'\n",
      "  \"|> death, but I haven't seen anything in rsb yet.\\n\"\n",
      "  '|> \\n'\n",
      "  '|> Gerald Perry of the Cardinals pinch hit in the eighth inning with two\\n'\n",
      "  '|> on and his club down by a run.  He stroked a line drive into the\\n'\n",
      "  '|> right field corner.  The ball cleared the three-foot high fence and\\n'\n",
      "  '|> went into the crowd.  Darryl, racing over from right center, got to\\n'\n",
      "  '|> th..., \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "..., \n",
      "None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/pipeline.py:230: UserWarning: Persisting input arguments took 2.00s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______________________________________________fit_transform_one - 58.4s, 1.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True), <3786x13866 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 292100 stored elements in Compressed Sparse Row format>, \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "..., \n",
      "None)\n",
      "________________________________________________fit_transform_one - 0.1s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), \n",
      "<3786x13866 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 292100 stored elements in Compressed Sparse Row format>, \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "..., \n",
      "None)\n",
      "________________________________________________fit_transform_one - 0.5s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(CountVectorizer(analyzer=<function stem_rmv_nums at 0x12655c7b8>,\n",
      "        binary=False, decode_error='strict', dtype=<class 'numpy.int64'>,\n",
      "        encoding='utf-8', input='content', lowercase=True, max_df=1.0,\n",
      "        max_features=None, min_df=3, ngram_range=(1, 1), preprocessor=None,\n",
      "        stop_words=None, strip_accents=None,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, vocabulary=None), \n",
      "[ 'From: sac@asdi.saic.com (Steve A. Conroy x6172)\\n'\n",
      "  'Subject: Re: Darrrrrrrrryl\\n'\n",
      "  'Organization: SAIC\\n'\n",
      "  'Lines: 33\\n'\n",
      "  '\\n'\n",
      "  'In article <mssC5KCru.5Ip@netcom.com>, mss@netcom.com (Mark Singer) '\n",
      "  'writes:\\n'\n",
      "  '|> \\n'\n",
      "  '|> \\n'\n",
      "  '|> The media is beating the incident at Dodger Stadium on Wednesday to\\n'\n",
      "  \"|> death, but I haven't seen anything in rsb yet.\\n\"\n",
      "  '|> \\n'\n",
      "  '|> Gerald Perry of the Cardinals pinch hit in the eighth inning with two\\n'\n",
      "  '|> on and his club down by a run.  He stroked a line drive into the\\n'\n",
      "  '|> right field corner.  The ball cleared the three-foot high fence and\\n'\n",
      "  '|> went into the crowd.  Darryl, racing over from right center, got to\\n'\n",
      "  '|> th..., \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "..., \n",
      "None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/pipeline.py:230: UserWarning: Persisting input arguments took 2.00s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______________________________________________fit_transform_one - 56.9s, 0.9min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True), <3787x13987 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 293061 stored elements in Compressed Sparse Row format>, \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "..., \n",
      "None)\n",
      "________________________________________________fit_transform_one - 0.1s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), \n",
      "<3787x13987 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 293061 stored elements in Compressed Sparse Row format>, \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "..., \n",
      "None)\n",
      "________________________________________________fit_transform_one - 0.5s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=5,\n",
      "        ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
      "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None), \n",
      "[ 'From: rschmitt@shearson.com (Robert Schmitt)\\n'\n",
      "  'Subject: Re: Please Recommend 3D Graphics Library F\\n'\n",
      "  'Reply-To: rschmitt@shearson.com\\n'\n",
      "  'Organization: Lehman Brothers, Inc.\\n'\n",
      "  'Lines: 9\\n'\n",
      "  '\\n'\n",
      "  'What hardware do plan to run on?  Workstation or PC?  Cost level?\\n'\n",
      "  'Run-time licensing needs?\\n'\n",
      "  '\\n'\n",
      "  'Bob\\n'\n",
      "  '------------------------------------------------------------------\\n'\n",
      "  'Robert A. Schmitt | Applied Derivatives Technology | Lehman Brothers\\n'\n",
      "  'rschmitt@shearson.com\\n'\n",
      "  '\\n'\n",
      "  '\\n',\n",
      "  'From: mori@volga.mfd.cs.fujitsu.co.jp (Tsuyoshi Mori)\\n'\n",
      "  'Subject: I want use DeskJet on System7\\n'\n",
      "  'Organization: FUJITSU.Ltd., Kawasaki, Japan.\\n'\n",
      "  'Lines: 15\\n'\n",
      "  'Di..., \n",
      "[ 0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "..., \n",
      "None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/pipeline.py:230: UserWarning: Persisting input arguments took 1.75s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________fit_transform_one - 2.3s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True), <3785x11007 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 306922 stored elements in Compressed Sparse Row format>, \n",
      "[ 0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "..., \n",
      "None)\n",
      "________________________________________________fit_transform_one - 0.1s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), \n",
      "<3785x11007 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 306922 stored elements in Compressed Sparse Row format>, \n",
      "[ 0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "..., \n",
      "None)\n",
      "________________________________________________fit_transform_one - 0.5s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=5,\n",
      "        ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
      "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None), \n",
      "[ 'From: sac@asdi.saic.com (Steve A. Conroy x6172)\\n'\n",
      "  'Subject: Re: Darrrrrrrrryl\\n'\n",
      "  'Organization: SAIC\\n'\n",
      "  'Lines: 33\\n'\n",
      "  '\\n'\n",
      "  'In article <mssC5KCru.5Ip@netcom.com>, mss@netcom.com (Mark Singer) '\n",
      "  'writes:\\n'\n",
      "  '|> \\n'\n",
      "  '|> \\n'\n",
      "  '|> The media is beating the incident at Dodger Stadium on Wednesday to\\n'\n",
      "  \"|> death, but I haven't seen anything in rsb yet.\\n\"\n",
      "  '|> \\n'\n",
      "  '|> Gerald Perry of the Cardinals pinch hit in the eighth inning with two\\n'\n",
      "  '|> on and his club down by a run.  He stroked a line drive into the\\n'\n",
      "  '|> right field corner.  The ball cleared the three-foot high fence and\\n'\n",
      "  '|> went into the crowd.  Darryl, racing over from right center, got to\\n'\n",
      "  '|> th..., \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "..., \n",
      "None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/pipeline.py:230: UserWarning: Persisting input arguments took 1.68s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________fit_transform_one - 2.2s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True), <3785x10930 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 303063 stored elements in Compressed Sparse Row format>, \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "..., \n",
      "None)\n",
      "________________________________________________fit_transform_one - 0.1s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), \n",
      "<3785x10930 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 303063 stored elements in Compressed Sparse Row format>, \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "..., \n",
      "None)\n",
      "________________________________________________fit_transform_one - 0.5s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=5,\n",
      "        ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
      "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None), \n",
      "[ 'From: sac@asdi.saic.com (Steve A. Conroy x6172)\\n'\n",
      "  'Subject: Re: Darrrrrrrrryl\\n'\n",
      "  'Organization: SAIC\\n'\n",
      "  'Lines: 33\\n'\n",
      "  '\\n'\n",
      "  'In article <mssC5KCru.5Ip@netcom.com>, mss@netcom.com (Mark Singer) '\n",
      "  'writes:\\n'\n",
      "  '|> \\n'\n",
      "  '|> \\n'\n",
      "  '|> The media is beating the incident at Dodger Stadium on Wednesday to\\n'\n",
      "  \"|> death, but I haven't seen anything in rsb yet.\\n\"\n",
      "  '|> \\n'\n",
      "  '|> Gerald Perry of the Cardinals pinch hit in the eighth inning with two\\n'\n",
      "  '|> on and his club down by a run.  He stroked a line drive into the\\n'\n",
      "  '|> right field corner.  The ball cleared the three-foot high fence and\\n'\n",
      "  '|> went into the crowd.  Darryl, racing over from right center, got to\\n'\n",
      "  '|> th..., \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "..., \n",
      "None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/pipeline.py:230: UserWarning: Persisting input arguments took 1.61s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________fit_transform_one - 2.2s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True), <3785x11017 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 306084 stored elements in Compressed Sparse Row format>, \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "..., \n",
      "None)\n",
      "________________________________________________fit_transform_one - 0.1s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), \n",
      "<3785x11017 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 306084 stored elements in Compressed Sparse Row format>, \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "..., \n",
      "None)\n",
      "________________________________________________fit_transform_one - 0.5s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=5,\n",
      "        ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
      "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None), \n",
      "[ 'From: sac@asdi.saic.com (Steve A. Conroy x6172)\\n'\n",
      "  'Subject: Re: Darrrrrrrrryl\\n'\n",
      "  'Organization: SAIC\\n'\n",
      "  'Lines: 33\\n'\n",
      "  '\\n'\n",
      "  'In article <mssC5KCru.5Ip@netcom.com>, mss@netcom.com (Mark Singer) '\n",
      "  'writes:\\n'\n",
      "  '|> \\n'\n",
      "  '|> \\n'\n",
      "  '|> The media is beating the incident at Dodger Stadium on Wednesday to\\n'\n",
      "  \"|> death, but I haven't seen anything in rsb yet.\\n\"\n",
      "  '|> \\n'\n",
      "  '|> Gerald Perry of the Cardinals pinch hit in the eighth inning with two\\n'\n",
      "  '|> on and his club down by a run.  He stroked a line drive into the\\n'\n",
      "  '|> right field corner.  The ball cleared the three-foot high fence and\\n'\n",
      "  '|> went into the crowd.  Darryl, racing over from right center, got to\\n'\n",
      "  '|> th..., \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "..., \n",
      "None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/pipeline.py:230: UserWarning: Persisting input arguments took 1.77s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________fit_transform_one - 2.2s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True), <3786x11109 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 306687 stored elements in Compressed Sparse Row format>, \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "..., \n",
      "None)\n",
      "________________________________________________fit_transform_one - 0.1s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), \n",
      "<3786x11109 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 306687 stored elements in Compressed Sparse Row format>, \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "..., \n",
      "None)\n",
      "________________________________________________fit_transform_one - 0.5s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=5,\n",
      "        ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
      "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None), \n",
      "[ 'From: sac@asdi.saic.com (Steve A. Conroy x6172)\\n'\n",
      "  'Subject: Re: Darrrrrrrrryl\\n'\n",
      "  'Organization: SAIC\\n'\n",
      "  'Lines: 33\\n'\n",
      "  '\\n'\n",
      "  'In article <mssC5KCru.5Ip@netcom.com>, mss@netcom.com (Mark Singer) '\n",
      "  'writes:\\n'\n",
      "  '|> \\n'\n",
      "  '|> \\n'\n",
      "  '|> The media is beating the incident at Dodger Stadium on Wednesday to\\n'\n",
      "  \"|> death, but I haven't seen anything in rsb yet.\\n\"\n",
      "  '|> \\n'\n",
      "  '|> Gerald Perry of the Cardinals pinch hit in the eighth inning with two\\n'\n",
      "  '|> on and his club down by a run.  He stroked a line drive into the\\n'\n",
      "  '|> right field corner.  The ball cleared the three-foot high fence and\\n'\n",
      "  '|> went into the crowd.  Darryl, racing over from right center, got to\\n'\n",
      "  '|> th..., \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "..., \n",
      "None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/pipeline.py:230: UserWarning: Persisting input arguments took 1.79s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________fit_transform_one - 3.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True), <3787x11048 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 306977 stored elements in Compressed Sparse Row format>, \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "..., \n",
      "None)\n",
      "________________________________________________fit_transform_one - 0.1s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), \n",
      "<3787x11048 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 306977 stored elements in Compressed Sparse Row format>, \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "..., \n",
      "None)\n",
      "________________________________________________fit_transform_one - 0.5s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(CountVectorizer(analyzer=<function stem_rmv_nums at 0x12655c7b8>,\n",
      "        binary=False, decode_error='strict', dtype=<class 'numpy.int64'>,\n",
      "        encoding='utf-8', input='content', lowercase=True, max_df=1.0,\n",
      "        max_features=None, min_df=5, ngram_range=(1, 1), preprocessor=None,\n",
      "        stop_words=None, strip_accents=None,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, vocabulary=None), \n",
      "[ 'From: rschmitt@shearson.com (Robert Schmitt)\\n'\n",
      "  'Subject: Re: Please Recommend 3D Graphics Library F\\n'\n",
      "  'Reply-To: rschmitt@shearson.com\\n'\n",
      "  'Organization: Lehman Brothers, Inc.\\n'\n",
      "  'Lines: 9\\n'\n",
      "  '\\n'\n",
      "  'What hardware do plan to run on?  Workstation or PC?  Cost level?\\n'\n",
      "  'Run-time licensing needs?\\n'\n",
      "  '\\n'\n",
      "  'Bob\\n'\n",
      "  '------------------------------------------------------------------\\n'\n",
      "  'Robert A. Schmitt | Applied Derivatives Technology | Lehman Brothers\\n'\n",
      "  'rschmitt@shearson.com\\n'\n",
      "  '\\n'\n",
      "  '\\n',\n",
      "  'From: mori@volga.mfd.cs.fujitsu.co.jp (Tsuyoshi Mori)\\n'\n",
      "  'Subject: I want use DeskJet on System7\\n'\n",
      "  'Organization: FUJITSU.Ltd., Kawasaki, Japan.\\n'\n",
      "  'Lines: 15\\n'\n",
      "  'Di..., \n",
      "[ 0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "..., \n",
      "None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/pipeline.py:230: UserWarning: Persisting input arguments took 1.34s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______________________________________________fit_transform_one - 58.8s, 1.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True), <3785x8879 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 275512 stored elements in Compressed Sparse Row format>, \n",
      "[ 0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "..., \n",
      "None)\n",
      "________________________________________________fit_transform_one - 0.1s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), \n",
      "<3785x8879 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 275512 stored elements in Compressed Sparse Row format>, \n",
      "[ 0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "..., \n",
      "None)\n",
      "________________________________________________fit_transform_one - 0.4s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(CountVectorizer(analyzer=<function stem_rmv_nums at 0x12655c7b8>,\n",
      "        binary=False, decode_error='strict', dtype=<class 'numpy.int64'>,\n",
      "        encoding='utf-8', input='content', lowercase=True, max_df=1.0,\n",
      "        max_features=None, min_df=5, ngram_range=(1, 1), preprocessor=None,\n",
      "        stop_words=None, strip_accents=None,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, vocabulary=None), \n",
      "[ 'From: sac@asdi.saic.com (Steve A. Conroy x6172)\\n'\n",
      "  'Subject: Re: Darrrrrrrrryl\\n'\n",
      "  'Organization: SAIC\\n'\n",
      "  'Lines: 33\\n'\n",
      "  '\\n'\n",
      "  'In article <mssC5KCru.5Ip@netcom.com>, mss@netcom.com (Mark Singer) '\n",
      "  'writes:\\n'\n",
      "  '|> \\n'\n",
      "  '|> \\n'\n",
      "  '|> The media is beating the incident at Dodger Stadium on Wednesday to\\n'\n",
      "  \"|> death, but I haven't seen anything in rsb yet.\\n\"\n",
      "  '|> \\n'\n",
      "  '|> Gerald Perry of the Cardinals pinch hit in the eighth inning with two\\n'\n",
      "  '|> on and his club down by a run.  He stroked a line drive into the\\n'\n",
      "  '|> right field corner.  The ball cleared the three-foot high fence and\\n'\n",
      "  '|> went into the crowd.  Darryl, racing over from right center, got to\\n'\n",
      "  '|> th..., \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "..., \n",
      "None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/pipeline.py:230: UserWarning: Persisting input arguments took 1.41s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______________________________________________fit_transform_one - 58.1s, 1.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True), <3785x8776 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 271865 stored elements in Compressed Sparse Row format>, \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "..., \n",
      "None)\n",
      "________________________________________________fit_transform_one - 0.1s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), \n",
      "<3785x8776 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 271865 stored elements in Compressed Sparse Row format>, \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "..., \n",
      "None)\n",
      "________________________________________________fit_transform_one - 0.3s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(CountVectorizer(analyzer=<function stem_rmv_nums at 0x12655c7b8>,\n",
      "        binary=False, decode_error='strict', dtype=<class 'numpy.int64'>,\n",
      "        encoding='utf-8', input='content', lowercase=True, max_df=1.0,\n",
      "        max_features=None, min_df=5, ngram_range=(1, 1), preprocessor=None,\n",
      "        stop_words=None, strip_accents=None,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, vocabulary=None), \n",
      "[ 'From: sac@asdi.saic.com (Steve A. Conroy x6172)\\n'\n",
      "  'Subject: Re: Darrrrrrrrryl\\n'\n",
      "  'Organization: SAIC\\n'\n",
      "  'Lines: 33\\n'\n",
      "  '\\n'\n",
      "  'In article <mssC5KCru.5Ip@netcom.com>, mss@netcom.com (Mark Singer) '\n",
      "  'writes:\\n'\n",
      "  '|> \\n'\n",
      "  '|> \\n'\n",
      "  '|> The media is beating the incident at Dodger Stadium on Wednesday to\\n'\n",
      "  \"|> death, but I haven't seen anything in rsb yet.\\n\"\n",
      "  '|> \\n'\n",
      "  '|> Gerald Perry of the Cardinals pinch hit in the eighth inning with two\\n'\n",
      "  '|> on and his club down by a run.  He stroked a line drive into the\\n'\n",
      "  '|> right field corner.  The ball cleared the three-foot high fence and\\n'\n",
      "  '|> went into the crowd.  Darryl, racing over from right center, got to\\n'\n",
      "  '|> th..., \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "..., \n",
      "None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/pipeline.py:230: UserWarning: Persisting input arguments took 1.51s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______________________________________________fit_transform_one - 59.4s, 1.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True), <3785x8863 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 274695 stored elements in Compressed Sparse Row format>, \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "..., \n",
      "None)\n",
      "________________________________________________fit_transform_one - 0.1s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), \n",
      "<3785x8863 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 274695 stored elements in Compressed Sparse Row format>, \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "..., \n",
      "None)\n",
      "________________________________________________fit_transform_one - 0.4s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(CountVectorizer(analyzer=<function stem_rmv_nums at 0x12655c7b8>,\n",
      "        binary=False, decode_error='strict', dtype=<class 'numpy.int64'>,\n",
      "        encoding='utf-8', input='content', lowercase=True, max_df=1.0,\n",
      "        max_features=None, min_df=5, ngram_range=(1, 1), preprocessor=None,\n",
      "        stop_words=None, strip_accents=None,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, vocabulary=None), \n",
      "[ 'From: sac@asdi.saic.com (Steve A. Conroy x6172)\\n'\n",
      "  'Subject: Re: Darrrrrrrrryl\\n'\n",
      "  'Organization: SAIC\\n'\n",
      "  'Lines: 33\\n'\n",
      "  '\\n'\n",
      "  'In article <mssC5KCru.5Ip@netcom.com>, mss@netcom.com (Mark Singer) '\n",
      "  'writes:\\n'\n",
      "  '|> \\n'\n",
      "  '|> \\n'\n",
      "  '|> The media is beating the incident at Dodger Stadium on Wednesday to\\n'\n",
      "  \"|> death, but I haven't seen anything in rsb yet.\\n\"\n",
      "  '|> \\n'\n",
      "  '|> Gerald Perry of the Cardinals pinch hit in the eighth inning with two\\n'\n",
      "  '|> on and his club down by a run.  He stroked a line drive into the\\n'\n",
      "  '|> right field corner.  The ball cleared the three-foot high fence and\\n'\n",
      "  '|> went into the crowd.  Darryl, racing over from right center, got to\\n'\n",
      "  '|> th..., \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "..., \n",
      "None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/pipeline.py:230: UserWarning: Persisting input arguments took 1.40s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______________________________________________fit_transform_one - 59.6s, 1.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True), <3786x8955 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 275436 stored elements in Compressed Sparse Row format>, \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "..., \n",
      "None)\n",
      "________________________________________________fit_transform_one - 0.1s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), \n",
      "<3786x8955 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 275436 stored elements in Compressed Sparse Row format>, \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "..., \n",
      "None)\n",
      "________________________________________________fit_transform_one - 0.5s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(CountVectorizer(analyzer=<function stem_rmv_nums at 0x12655c7b8>,\n",
      "        binary=False, decode_error='strict', dtype=<class 'numpy.int64'>,\n",
      "        encoding='utf-8', input='content', lowercase=True, max_df=1.0,\n",
      "        max_features=None, min_df=5, ngram_range=(1, 1), preprocessor=None,\n",
      "        stop_words=None, strip_accents=None,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, vocabulary=None), \n",
      "[ 'From: sac@asdi.saic.com (Steve A. Conroy x6172)\\n'\n",
      "  'Subject: Re: Darrrrrrrrryl\\n'\n",
      "  'Organization: SAIC\\n'\n",
      "  'Lines: 33\\n'\n",
      "  '\\n'\n",
      "  'In article <mssC5KCru.5Ip@netcom.com>, mss@netcom.com (Mark Singer) '\n",
      "  'writes:\\n'\n",
      "  '|> \\n'\n",
      "  '|> \\n'\n",
      "  '|> The media is beating the incident at Dodger Stadium on Wednesday to\\n'\n",
      "  \"|> death, but I haven't seen anything in rsb yet.\\n\"\n",
      "  '|> \\n'\n",
      "  '|> Gerald Perry of the Cardinals pinch hit in the eighth inning with two\\n'\n",
      "  '|> on and his club down by a run.  He stroked a line drive into the\\n'\n",
      "  '|> right field corner.  The ball cleared the three-foot high fence and\\n'\n",
      "  '|> went into the crowd.  Darryl, racing over from right center, got to\\n'\n",
      "  '|> th..., \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "..., \n",
      "None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/pipeline.py:230: UserWarning: Persisting input arguments took 1.50s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______________________________________________fit_transform_one - 61.1s, 1.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True), <3787x8905 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 275885 stored elements in Compressed Sparse Row format>, \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "..., \n",
      "None)\n",
      "________________________________________________fit_transform_one - 0.1s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), \n",
      "<3787x8905 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 275885 stored elements in Compressed Sparse Row format>, \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "..., \n",
      "None)\n",
      "________________________________________________fit_transform_one - 0.4s, 0.0min\n",
      "[Memory]0.1s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/43a6e70b15cc9b424b05489316fa930d\n",
      "___________________________________fit_transform_one cache loaded - 0.5s, 0.0min\n",
      "[Memory]0.6s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/6738a4f7a60cf3addf3174c1c7d196e3\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), \n",
      "<3785x17574 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 329115 stored elements in Compressed Sparse Row format>, \n",
      "[ 0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "..., \n",
      "None)\n",
      "_______________________________________________fit_transform_one - 24.3s, 0.4min\n",
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/b52687d9fd84261f0cbb0d8ca912642a\n",
      "___________________________________fit_transform_one cache loaded - 0.4s, 0.0min\n",
      "[Memory]0.5s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/f4f405b0cf43c8cfee0ceb2b51874992\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), \n",
      "<3785x17232 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 324344 stored elements in Compressed Sparse Row format>, \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "..., \n",
      "None)\n",
      "_______________________________________________fit_transform_one - 23.4s, 0.4min\n",
      "[Memory]0.1s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/daf033aa3514611020c25ccbeaaa8da9\n",
      "___________________________________fit_transform_one cache loaded - 0.5s, 0.0min\n",
      "[Memory]0.5s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/9714ccef2b49a3c176f13a79dc49455c\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), \n",
      "<3785x17671 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 328511 stored elements in Compressed Sparse Row format>, \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "..., \n",
      "None)\n",
      "_______________________________________________fit_transform_one - 23.4s, 0.4min\n",
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/a2ff74ffa2d6f71f41e4ee2831ca4fa8\n",
      "___________________________________fit_transform_one cache loaded - 0.4s, 0.0min\n",
      "[Memory]0.5s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/4b35b965a17862ece7cac259e9a5c1bf\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), \n",
      "<3786x17321 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 327753 stored elements in Compressed Sparse Row format>, \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "..., \n",
      "None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______________________________________________fit_transform_one - 10.7s, 0.2min\n",
      "[Memory]0.1s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/3d4677ec42067bc6e1adbd41a0b286e9\n",
      "___________________________________fit_transform_one cache loaded - 0.4s, 0.0min\n",
      "[Memory]0.5s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/4d98c639017c8262d49930e011c29307\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), \n",
      "<3787x17420 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 328453 stored elements in Compressed Sparse Row format>, \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "..., \n",
      "None)\n",
      "_______________________________________________fit_transform_one - 19.5s, 0.3min\n",
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/0482c4d64fa45188abf2a238a6243aa4\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/c76bec7cac51604944bdc6c68488c092\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), \n",
      "<3785x14193 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 293436 stored elements in Compressed Sparse Row format>, \n",
      "[ 0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "..., \n",
      "None)\n",
      "_______________________________________________fit_transform_one - 17.1s, 0.3min\n",
      "[Memory]0.1s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/111d8f1a7a88a782090fbe1ff500e18f\n",
      "___________________________________fit_transform_one cache loaded - 0.4s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/3375a5000b5bc9b4a9c9330cf67af690\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), \n",
      "<3785x13776 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 288757 stored elements in Compressed Sparse Row format>, \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "..., \n",
      "None)\n",
      "_______________________________________________fit_transform_one - 19.0s, 0.3min\n",
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/225ba5546c8de6efc85d097dd878e926\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/332b067f1be94b1d6da79319de71b4c1\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), \n",
      "<3785x14278 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 292930 stored elements in Compressed Sparse Row format>, \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "..., \n",
      "None)\n",
      "_______________________________________________fit_transform_one - 20.2s, 0.3min\n",
      "[Memory]0.1s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/0a11989720b3800e8e13c3d35068a0ae\n",
      "___________________________________fit_transform_one cache loaded - 0.4s, 0.0min\n",
      "[Memory]0.5s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/2633f6df6145949646804d8b5609103f\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), \n",
      "<3786x13866 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 292100 stored elements in Compressed Sparse Row format>, \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "..., \n",
      "None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______________________________________________fit_transform_one - 14.6s, 0.2min\n",
      "[Memory]0.1s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/6852a990bd707c236e3887afd39eb25d\n",
      "___________________________________fit_transform_one cache loaded - 0.4s, 0.0min\n",
      "[Memory]0.5s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/2b0094f42b7a9be6d3c26b5d01e16d45\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), \n",
      "<3787x13987 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 293061 stored elements in Compressed Sparse Row format>, \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "..., \n",
      "None)\n",
      "_______________________________________________fit_transform_one - 20.8s, 0.3min\n",
      "[Memory]0.1s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/a37a5965428df82e3af5f29912956ad8\n",
      "___________________________________fit_transform_one cache loaded - 0.4s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/0fa844dc035dcc36a51d836ac278cde9\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), \n",
      "<3785x11007 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 306922 stored elements in Compressed Sparse Row format>, \n",
      "[ 0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "..., \n",
      "None)\n",
      "_______________________________________________fit_transform_one - 18.1s, 0.3min\n",
      "[Memory]0.1s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/1cc022731abc3fd426b3debb0fe32152\n",
      "___________________________________fit_transform_one cache loaded - 0.4s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/e42954c5be8d6675b299c764a7b14e8f\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), \n",
      "<3785x10930 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 303063 stored elements in Compressed Sparse Row format>, \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "..., \n",
      "None)\n",
      "_______________________________________________fit_transform_one - 18.9s, 0.3min\n",
      "[Memory]0.1s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/6cad3cf637d4b8a8565841c0ebf70090\n",
      "___________________________________fit_transform_one cache loaded - 0.4s, 0.0min\n",
      "[Memory]0.5s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/05f572f5554cc2f5dded0862626b4893\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), \n",
      "<3785x11017 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 306084 stored elements in Compressed Sparse Row format>, \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "..., \n",
      "None)\n",
      "_______________________________________________fit_transform_one - 20.5s, 0.3min\n",
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/719903506d1e231c9b42b916b113f726\n",
      "___________________________________fit_transform_one cache loaded - 0.4s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/c911afcac8230a4a0b7cc35f9e800d75\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), \n",
      "<3786x11109 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 306687 stored elements in Compressed Sparse Row format>, \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "..., \n",
      "None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______________________________________________fit_transform_one - 19.5s, 0.3min\n",
      "[Memory]0.1s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/f51f67a12e05f28ee1a2b223c840b657\n",
      "___________________________________fit_transform_one cache loaded - 0.4s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/b5eefb4b7f0e1dc6b2f81b17cc568cd6\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), \n",
      "<3787x11048 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 306977 stored elements in Compressed Sparse Row format>, \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "..., \n",
      "None)\n",
      "_______________________________________________fit_transform_one - 11.2s, 0.2min\n",
      "[Memory]0.1s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/78e41de6f9c25d7c944d51c4f2d3a6a2\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/be99645267b96e4b57f580fb49530fe9\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), \n",
      "<3785x8879 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 275512 stored elements in Compressed Sparse Row format>, \n",
      "[ 0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "..., \n",
      "None)\n",
      "_______________________________________________fit_transform_one - 19.7s, 0.3min\n",
      "[Memory]0.1s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/6b11bb98e03497289adbf581e02b75dd\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/ccc3cd0e401d9cbe7f94efaba15cc805\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), \n",
      "<3785x8776 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 271865 stored elements in Compressed Sparse Row format>, \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "..., \n",
      "None)\n",
      "________________________________________________fit_transform_one - 6.4s, 0.1min\n",
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/c126cb77a66cd1ba0aa0a2dc26cd87e5\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/ed30e9ad6db96077e3cfe85cbfe63c48\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), \n",
      "<3785x8863 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 274695 stored elements in Compressed Sparse Row format>, \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "..., \n",
      "None)\n",
      "_______________________________________________fit_transform_one - 13.1s, 0.2min\n",
      "[Memory]0.1s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/e13a0cabdde97cff9f382e270eeadbe9\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/1cc3b8b7c6ed48ffc37f02a2d15017d4\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), \n",
      "<3786x8955 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 275436 stored elements in Compressed Sparse Row format>, \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "..., \n",
      "None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______________________________________________fit_transform_one - 10.8s, 0.2min\n",
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/398b6b94daa65494b1af0c3ec4aa24a1\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/34bda755e91f0eada5fb2b4513030717\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), \n",
      "<3787x8905 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 275885 stored elements in Compressed Sparse Row format>, \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "..., \n",
      "None)\n",
      "_______________________________________________fit_transform_one - 10.2s, 0.2min\n",
      "[Memory]0.1s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/43a6e70b15cc9b424b05489316fa930d\n",
      "___________________________________fit_transform_one cache loaded - 0.7s, 0.0min\n",
      "[Memory]0.9s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/6738a4f7a60cf3addf3174c1c7d196e3\n",
      "___________________________________fit_transform_one cache loaded - 0.1s, 0.0min\n",
      "[Memory]1.1s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/7d825b9d49eaacbb85992a6541346802\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.1s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/b52687d9fd84261f0cbb0d8ca912642a\n",
      "___________________________________fit_transform_one cache loaded - 0.5s, 0.0min\n",
      "[Memory]0.6s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/f4f405b0cf43c8cfee0ceb2b51874992\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.6s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/2f7603d54e76984416d0f4512dcc51d2\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.1s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/daf033aa3514611020c25ccbeaaa8da9\n",
      "___________________________________fit_transform_one cache loaded - 0.4s, 0.0min\n",
      "[Memory]0.5s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/9714ccef2b49a3c176f13a79dc49455c\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.5s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/097fad3254676674ec670de9ab081be2\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.1s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/a2ff74ffa2d6f71f41e4ee2831ca4fa8\n",
      "___________________________________fit_transform_one cache loaded - 0.5s, 0.0min\n",
      "[Memory]0.5s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/4b35b965a17862ece7cac259e9a5c1bf\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.6s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/c5240ff554fe2ab8b1c77044427bc524\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.1s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/3d4677ec42067bc6e1adbd41a0b286e9\n",
      "___________________________________fit_transform_one cache loaded - 0.5s, 0.0min\n",
      "[Memory]0.6s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/4d98c639017c8262d49930e011c29307\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.6s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/5d995680aa9c6abadf5bee0856c2c1e7\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.1s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/0482c4d64fa45188abf2a238a6243aa4\n",
      "___________________________________fit_transform_one cache loaded - 0.4s, 0.0min\n",
      "[Memory]0.5s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/c76bec7cac51604944bdc6c68488c092\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.5s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/987ca23be0288364357ce7a4463f316f\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/111d8f1a7a88a782090fbe1ff500e18f\n",
      "___________________________________fit_transform_one cache loaded - 0.4s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/3375a5000b5bc9b4a9c9330cf67af690\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.5s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/16590d6062b21d495d227ec1eea528e9\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.1s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/225ba5546c8de6efc85d097dd878e926\n",
      "___________________________________fit_transform_one cache loaded - 0.4s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/332b067f1be94b1d6da79319de71b4c1\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.5s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/f8ad0b2f4aa84d98ba4da12a086601fd\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/0a11989720b3800e8e13c3d35068a0ae\n",
      "___________________________________fit_transform_one cache loaded - 0.4s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/2633f6df6145949646804d8b5609103f\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/74b139cd3bf5e1b429487878ffc77f8a\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/6852a990bd707c236e3887afd39eb25d\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/2b0094f42b7a9be6d3c26b5d01e16d45\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/703830af15c9fc1634b1648d488643fa\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/a37a5965428df82e3af5f29912956ad8\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/0fa844dc035dcc36a51d836ac278cde9\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/fc870172232185dc3184bbfc06f743f6\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.1s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/1cc022731abc3fd426b3debb0fe32152\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/e42954c5be8d6675b299c764a7b14e8f\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/79e2978649cfc0d5d81f9d1716a64da9\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.1s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/6cad3cf637d4b8a8565841c0ebf70090\n",
      "___________________________________fit_transform_one cache loaded - 0.4s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/05f572f5554cc2f5dded0862626b4893\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.5s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/135c738702ef66b2bbee90a1d705dc17\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.1s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/719903506d1e231c9b42b916b113f726\n",
      "___________________________________fit_transform_one cache loaded - 0.4s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/c911afcac8230a4a0b7cc35f9e800d75\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.5s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/6dcf83a8b2a534417639149930915eb4\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/f51f67a12e05f28ee1a2b223c840b657\n",
      "___________________________________fit_transform_one cache loaded - 0.4s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/b5eefb4b7f0e1dc6b2f81b17cc568cd6\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.5s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/7baa5410173219f912ea597317343afb\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/78e41de6f9c25d7c944d51c4f2d3a6a2\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/be99645267b96e4b57f580fb49530fe9\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/abbc3ac1c71b2c7018e1a70ef5f4b134\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.1s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/6b11bb98e03497289adbf581e02b75dd\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/ccc3cd0e401d9cbe7f94efaba15cc805\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/30b5c777c7b62aa362ef99b70bada294\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.1s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/c126cb77a66cd1ba0aa0a2dc26cd87e5\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/ed30e9ad6db96077e3cfe85cbfe63c48\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/7a73108a1bcc1bcff75120d0bfbb6d00\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/e13a0cabdde97cff9f382e270eeadbe9\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/1cc3b8b7c6ed48ffc37f02a2d15017d4\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/6abe3b4743b684c0f8b41ef6748618f4\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.1s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/398b6b94daa65494b1af0c3ec4aa24a1\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/34bda755e91f0eada5fb2b4513030717\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/e753714d36141c4d38ad6846abb105e4\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.1s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/43a6e70b15cc9b424b05489316fa930d\n",
      "___________________________________fit_transform_one cache loaded - 0.4s, 0.0min\n",
      "[Memory]0.5s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/6738a4f7a60cf3addf3174c1c7d196e3\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.5s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/e7d9470a733e4074942e51a5b9decfca\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/b52687d9fd84261f0cbb0d8ca912642a\n",
      "___________________________________fit_transform_one cache loaded - 0.4s, 0.0min\n",
      "[Memory]0.5s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/f4f405b0cf43c8cfee0ceb2b51874992\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.5s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/dee5ffe6f882be35954ec93ffac10cd6\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.1s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/daf033aa3514611020c25ccbeaaa8da9\n",
      "___________________________________fit_transform_one cache loaded - 0.4s, 0.0min\n",
      "[Memory]0.5s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/9714ccef2b49a3c176f13a79dc49455c\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.5s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/58cd3ef6911d37a4ffbafd133642fc51\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/a2ff74ffa2d6f71f41e4ee2831ca4fa8\n",
      "___________________________________fit_transform_one cache loaded - 0.4s, 0.0min\n",
      "[Memory]0.5s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/4b35b965a17862ece7cac259e9a5c1bf\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.5s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/675e6d77b110262d0691404b4c39db93\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.1s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/3d4677ec42067bc6e1adbd41a0b286e9\n",
      "___________________________________fit_transform_one cache loaded - 0.4s, 0.0min\n",
      "[Memory]0.5s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/4d98c639017c8262d49930e011c29307\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.5s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/8e2d435ce11e45bb4894298b3ea0fd6b\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.1s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/0482c4d64fa45188abf2a238a6243aa4\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/c76bec7cac51604944bdc6c68488c092\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/827b5d2042e1e9dcd857792e74219fe9\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/111d8f1a7a88a782090fbe1ff500e18f\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/3375a5000b5bc9b4a9c9330cf67af690\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/88542b44bf6cbcb678f39d23f49db98e\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.1s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/225ba5546c8de6efc85d097dd878e926\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/332b067f1be94b1d6da79319de71b4c1\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/fc1b32984b30b48ffe52927e9dfcdbff\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/0a11989720b3800e8e13c3d35068a0ae\n",
      "___________________________________fit_transform_one cache loaded - 0.4s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/2633f6df6145949646804d8b5609103f\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/130877cbdf15827c51ccc493979819fe\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.1s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/6852a990bd707c236e3887afd39eb25d\n",
      "___________________________________fit_transform_one cache loaded - 0.4s, 0.0min\n",
      "[Memory]0.5s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/2b0094f42b7a9be6d3c26b5d01e16d45\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.5s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/dee4ed6d13279b7c4b04364f07926caf\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/a37a5965428df82e3af5f29912956ad8\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/0fa844dc035dcc36a51d836ac278cde9\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/76322d282539732f202e148ded5b64b3\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/1cc022731abc3fd426b3debb0fe32152\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/e42954c5be8d6675b299c764a7b14e8f\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/4ff65243e16400fb46891ed6001aec7d\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/6cad3cf637d4b8a8565841c0ebf70090\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/05f572f5554cc2f5dded0862626b4893\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/b3b7ec6e8e751ed0e797a8aaac603359\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/719903506d1e231c9b42b916b113f726\n",
      "___________________________________fit_transform_one cache loaded - 0.4s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/c911afcac8230a4a0b7cc35f9e800d75\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/4f13554041177803c49f2df2b8a7b57d\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/f51f67a12e05f28ee1a2b223c840b657\n",
      "___________________________________fit_transform_one cache loaded - 0.4s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/b5eefb4b7f0e1dc6b2f81b17cc568cd6\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/20ce79ea31f39134e5713292fe2fe9e2\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.1s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/78e41de6f9c25d7c944d51c4f2d3a6a2\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/be99645267b96e4b57f580fb49530fe9\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/700f667e24867f7ad2bc85ded72febd3\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/6b11bb98e03497289adbf581e02b75dd\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/ccc3cd0e401d9cbe7f94efaba15cc805\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/6a29b9d4be63b1171b4d4ca01aa1206d\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.1s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/c126cb77a66cd1ba0aa0a2dc26cd87e5\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/ed30e9ad6db96077e3cfe85cbfe63c48\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/4f83ed2965b5cb6c2e67ed0762d65dbf\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.1s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/e13a0cabdde97cff9f382e270eeadbe9\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/1cc3b8b7c6ed48ffc37f02a2d15017d4\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.5s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/66b1b5eeef3449b9d0ae728c32f4c778\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.1s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/398b6b94daa65494b1af0c3ec4aa24a1\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/34bda755e91f0eada5fb2b4513030717\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/6b34adcfff690cea0faccbb9204e1771\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.1s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/43a6e70b15cc9b424b05489316fa930d\n",
      "___________________________________fit_transform_one cache loaded - 0.4s, 0.0min\n",
      "[Memory]0.5s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/6738a4f7a60cf3addf3174c1c7d196e3\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.5s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/7d825b9d49eaacbb85992a6541346802\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/b52687d9fd84261f0cbb0d8ca912642a\n",
      "___________________________________fit_transform_one cache loaded - 0.4s, 0.0min\n",
      "[Memory]0.5s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/f4f405b0cf43c8cfee0ceb2b51874992\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.5s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/2f7603d54e76984416d0f4512dcc51d2\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/daf033aa3514611020c25ccbeaaa8da9\n",
      "___________________________________fit_transform_one cache loaded - 0.5s, 0.0min\n",
      "[Memory]0.6s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/9714ccef2b49a3c176f13a79dc49455c\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.6s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/097fad3254676674ec670de9ab081be2\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.1s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/a2ff74ffa2d6f71f41e4ee2831ca4fa8\n",
      "___________________________________fit_transform_one cache loaded - 0.5s, 0.0min\n",
      "[Memory]0.6s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/4b35b965a17862ece7cac259e9a5c1bf\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.6s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/c5240ff554fe2ab8b1c77044427bc524\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/3d4677ec42067bc6e1adbd41a0b286e9\n",
      "___________________________________fit_transform_one cache loaded - 0.4s, 0.0min\n",
      "[Memory]0.5s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/4d98c639017c8262d49930e011c29307\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.5s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/5d995680aa9c6abadf5bee0856c2c1e7\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/0482c4d64fa45188abf2a238a6243aa4\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/c76bec7cac51604944bdc6c68488c092\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/987ca23be0288364357ce7a4463f316f\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/111d8f1a7a88a782090fbe1ff500e18f\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/3375a5000b5bc9b4a9c9330cf67af690\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/16590d6062b21d495d227ec1eea528e9\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.1s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/225ba5546c8de6efc85d097dd878e926\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/332b067f1be94b1d6da79319de71b4c1\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/f8ad0b2f4aa84d98ba4da12a086601fd\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/0a11989720b3800e8e13c3d35068a0ae\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/2633f6df6145949646804d8b5609103f\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/74b139cd3bf5e1b429487878ffc77f8a\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.1s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/6852a990bd707c236e3887afd39eb25d\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/2b0094f42b7a9be6d3c26b5d01e16d45\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/703830af15c9fc1634b1648d488643fa\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/a37a5965428df82e3af5f29912956ad8\n",
      "___________________________________fit_transform_one cache loaded - 0.4s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/0fa844dc035dcc36a51d836ac278cde9\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.5s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/fc870172232185dc3184bbfc06f743f6\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/1cc022731abc3fd426b3debb0fe32152\n",
      "___________________________________fit_transform_one cache loaded - 0.4s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/e42954c5be8d6675b299c764a7b14e8f\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.5s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/79e2978649cfc0d5d81f9d1716a64da9\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/6cad3cf637d4b8a8565841c0ebf70090\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/05f572f5554cc2f5dded0862626b4893\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/135c738702ef66b2bbee90a1d705dc17\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.1s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/719903506d1e231c9b42b916b113f726\n",
      "___________________________________fit_transform_one cache loaded - 0.4s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/c911afcac8230a4a0b7cc35f9e800d75\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.5s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/6dcf83a8b2a534417639149930915eb4\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/f51f67a12e05f28ee1a2b223c840b657\n",
      "___________________________________fit_transform_one cache loaded - 0.4s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/b5eefb4b7f0e1dc6b2f81b17cc568cd6\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.5s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/7baa5410173219f912ea597317343afb\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/78e41de6f9c25d7c944d51c4f2d3a6a2\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/be99645267b96e4b57f580fb49530fe9\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/abbc3ac1c71b2c7018e1a70ef5f4b134\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/6b11bb98e03497289adbf581e02b75dd\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/ccc3cd0e401d9cbe7f94efaba15cc805\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/30b5c777c7b62aa362ef99b70bada294\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.1s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/c126cb77a66cd1ba0aa0a2dc26cd87e5\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/ed30e9ad6db96077e3cfe85cbfe63c48\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/7a73108a1bcc1bcff75120d0bfbb6d00\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/e13a0cabdde97cff9f382e270eeadbe9\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/1cc3b8b7c6ed48ffc37f02a2d15017d4\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/6abe3b4743b684c0f8b41ef6748618f4\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/398b6b94daa65494b1af0c3ec4aa24a1\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/34bda755e91f0eada5fb2b4513030717\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/e753714d36141c4d38ad6846abb105e4\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/43a6e70b15cc9b424b05489316fa930d\n",
      "___________________________________fit_transform_one cache loaded - 0.4s, 0.0min\n",
      "[Memory]0.5s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/6738a4f7a60cf3addf3174c1c7d196e3\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.5s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/e7d9470a733e4074942e51a5b9decfca\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/b52687d9fd84261f0cbb0d8ca912642a\n",
      "___________________________________fit_transform_one cache loaded - 0.4s, 0.0min\n",
      "[Memory]0.5s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/f4f405b0cf43c8cfee0ceb2b51874992\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.5s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/dee5ffe6f882be35954ec93ffac10cd6\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/daf033aa3514611020c25ccbeaaa8da9\n",
      "___________________________________fit_transform_one cache loaded - 0.4s, 0.0min\n",
      "[Memory]0.5s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/9714ccef2b49a3c176f13a79dc49455c\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.5s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/58cd3ef6911d37a4ffbafd133642fc51\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/a2ff74ffa2d6f71f41e4ee2831ca4fa8\n",
      "___________________________________fit_transform_one cache loaded - 0.4s, 0.0min\n",
      "[Memory]0.5s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/4b35b965a17862ece7cac259e9a5c1bf\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.5s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/675e6d77b110262d0691404b4c39db93\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/3d4677ec42067bc6e1adbd41a0b286e9\n",
      "___________________________________fit_transform_one cache loaded - 0.4s, 0.0min\n",
      "[Memory]0.5s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/4d98c639017c8262d49930e011c29307\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.5s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/8e2d435ce11e45bb4894298b3ea0fd6b\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/0482c4d64fa45188abf2a238a6243aa4\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/c76bec7cac51604944bdc6c68488c092\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/827b5d2042e1e9dcd857792e74219fe9\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/111d8f1a7a88a782090fbe1ff500e18f\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/3375a5000b5bc9b4a9c9330cf67af690\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/88542b44bf6cbcb678f39d23f49db98e\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/225ba5546c8de6efc85d097dd878e926\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/332b067f1be94b1d6da79319de71b4c1\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/fc1b32984b30b48ffe52927e9dfcdbff\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/0a11989720b3800e8e13c3d35068a0ae\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/2633f6df6145949646804d8b5609103f\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/130877cbdf15827c51ccc493979819fe\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/6852a990bd707c236e3887afd39eb25d\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/2b0094f42b7a9be6d3c26b5d01e16d45\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/dee4ed6d13279b7c4b04364f07926caf\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/a37a5965428df82e3af5f29912956ad8\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/0fa844dc035dcc36a51d836ac278cde9\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/76322d282539732f202e148ded5b64b3\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/1cc022731abc3fd426b3debb0fe32152\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/e42954c5be8d6675b299c764a7b14e8f\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/4ff65243e16400fb46891ed6001aec7d\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/6cad3cf637d4b8a8565841c0ebf70090\n",
      "___________________________________fit_transform_one cache loaded - 0.7s, 0.0min\n",
      "[Memory]0.7s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/05f572f5554cc2f5dded0862626b4893\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.8s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/b3b7ec6e8e751ed0e797a8aaac603359\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/719903506d1e231c9b42b916b113f726\n",
      "___________________________________fit_transform_one cache loaded - 0.4s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/c911afcac8230a4a0b7cc35f9e800d75\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/4f13554041177803c49f2df2b8a7b57d\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/f51f67a12e05f28ee1a2b223c840b657\n",
      "___________________________________fit_transform_one cache loaded - 0.4s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/b5eefb4b7f0e1dc6b2f81b17cc568cd6\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/20ce79ea31f39134e5713292fe2fe9e2\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/78e41de6f9c25d7c944d51c4f2d3a6a2\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/be99645267b96e4b57f580fb49530fe9\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/700f667e24867f7ad2bc85ded72febd3\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/6b11bb98e03497289adbf581e02b75dd\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/ccc3cd0e401d9cbe7f94efaba15cc805\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/6a29b9d4be63b1171b4d4ca01aa1206d\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/c126cb77a66cd1ba0aa0a2dc26cd87e5\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/ed30e9ad6db96077e3cfe85cbfe63c48\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/4f83ed2965b5cb6c2e67ed0762d65dbf\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/e13a0cabdde97cff9f382e270eeadbe9\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/1cc3b8b7c6ed48ffc37f02a2d15017d4\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/66b1b5eeef3449b9d0ae728c32f4c778\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/398b6b94daa65494b1af0c3ec4aa24a1\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/34bda755e91f0eada5fb2b4513030717\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/6b34adcfff690cea0faccbb9204e1771\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/43a6e70b15cc9b424b05489316fa930d\n",
      "___________________________________fit_transform_one cache loaded - 0.4s, 0.0min\n",
      "[Memory]0.5s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/6738a4f7a60cf3addf3174c1c7d196e3\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.5s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/7d825b9d49eaacbb85992a6541346802\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/b52687d9fd84261f0cbb0d8ca912642a\n",
      "___________________________________fit_transform_one cache loaded - 0.4s, 0.0min\n",
      "[Memory]0.5s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/f4f405b0cf43c8cfee0ceb2b51874992\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.5s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/2f7603d54e76984416d0f4512dcc51d2\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/daf033aa3514611020c25ccbeaaa8da9\n",
      "___________________________________fit_transform_one cache loaded - 0.4s, 0.0min\n",
      "[Memory]0.5s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/9714ccef2b49a3c176f13a79dc49455c\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.5s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/097fad3254676674ec670de9ab081be2\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.1s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/a2ff74ffa2d6f71f41e4ee2831ca4fa8\n",
      "___________________________________fit_transform_one cache loaded - 0.4s, 0.0min\n",
      "[Memory]0.5s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/4b35b965a17862ece7cac259e9a5c1bf\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.5s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/c5240ff554fe2ab8b1c77044427bc524\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.1s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/3d4677ec42067bc6e1adbd41a0b286e9\n",
      "___________________________________fit_transform_one cache loaded - 0.5s, 0.0min\n",
      "[Memory]0.5s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/4d98c639017c8262d49930e011c29307\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.6s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/5d995680aa9c6abadf5bee0856c2c1e7\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/0482c4d64fa45188abf2a238a6243aa4\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/c76bec7cac51604944bdc6c68488c092\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/987ca23be0288364357ce7a4463f316f\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.1s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/111d8f1a7a88a782090fbe1ff500e18f\n",
      "___________________________________fit_transform_one cache loaded - 0.4s, 0.0min\n",
      "[Memory]0.5s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/3375a5000b5bc9b4a9c9330cf67af690\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.5s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/16590d6062b21d495d227ec1eea528e9\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/225ba5546c8de6efc85d097dd878e926\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/332b067f1be94b1d6da79319de71b4c1\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/f8ad0b2f4aa84d98ba4da12a086601fd\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.1s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/0a11989720b3800e8e13c3d35068a0ae\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/2633f6df6145949646804d8b5609103f\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/74b139cd3bf5e1b429487878ffc77f8a\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/6852a990bd707c236e3887afd39eb25d\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/2b0094f42b7a9be6d3c26b5d01e16d45\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/703830af15c9fc1634b1648d488643fa\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.1s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/a37a5965428df82e3af5f29912956ad8\n",
      "___________________________________fit_transform_one cache loaded - 0.5s, 0.0min\n",
      "[Memory]0.6s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/0fa844dc035dcc36a51d836ac278cde9\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.6s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/fc870172232185dc3184bbfc06f743f6\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.1s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/1cc022731abc3fd426b3debb0fe32152\n",
      "___________________________________fit_transform_one cache loaded - 0.4s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/e42954c5be8d6675b299c764a7b14e8f\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.5s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/79e2978649cfc0d5d81f9d1716a64da9\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.1s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/6cad3cf637d4b8a8565841c0ebf70090\n",
      "___________________________________fit_transform_one cache loaded - 0.7s, 0.0min\n",
      "[Memory]0.8s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/05f572f5554cc2f5dded0862626b4893\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.9s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/135c738702ef66b2bbee90a1d705dc17\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.1s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/719903506d1e231c9b42b916b113f726\n",
      "___________________________________fit_transform_one cache loaded - 0.5s, 0.0min\n",
      "[Memory]0.6s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/c911afcac8230a4a0b7cc35f9e800d75\n",
      "___________________________________fit_transform_one cache loaded - 0.1s, 0.0min\n",
      "[Memory]0.7s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/6dcf83a8b2a534417639149930915eb4\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.1s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/f51f67a12e05f28ee1a2b223c840b657\n",
      "___________________________________fit_transform_one cache loaded - 0.5s, 0.0min\n",
      "[Memory]0.6s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/b5eefb4b7f0e1dc6b2f81b17cc568cd6\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.6s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/7baa5410173219f912ea597317343afb\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.1s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/78e41de6f9c25d7c944d51c4f2d3a6a2\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/be99645267b96e4b57f580fb49530fe9\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/abbc3ac1c71b2c7018e1a70ef5f4b134\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.1s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/6b11bb98e03497289adbf581e02b75dd\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/ccc3cd0e401d9cbe7f94efaba15cc805\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/30b5c777c7b62aa362ef99b70bada294\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/c126cb77a66cd1ba0aa0a2dc26cd87e5\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/ed30e9ad6db96077e3cfe85cbfe63c48\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/7a73108a1bcc1bcff75120d0bfbb6d00\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/e13a0cabdde97cff9f382e270eeadbe9\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/1cc3b8b7c6ed48ffc37f02a2d15017d4\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/6abe3b4743b684c0f8b41ef6748618f4\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/398b6b94daa65494b1af0c3ec4aa24a1\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/34bda755e91f0eada5fb2b4513030717\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/e753714d36141c4d38ad6846abb105e4\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/43a6e70b15cc9b424b05489316fa930d\n",
      "___________________________________fit_transform_one cache loaded - 0.4s, 0.0min\n",
      "[Memory]0.5s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/6738a4f7a60cf3addf3174c1c7d196e3\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.5s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/e7d9470a733e4074942e51a5b9decfca\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/b52687d9fd84261f0cbb0d8ca912642a\n",
      "___________________________________fit_transform_one cache loaded - 0.4s, 0.0min\n",
      "[Memory]0.5s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/f4f405b0cf43c8cfee0ceb2b51874992\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.5s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/dee5ffe6f882be35954ec93ffac10cd6\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/daf033aa3514611020c25ccbeaaa8da9\n",
      "___________________________________fit_transform_one cache loaded - 0.4s, 0.0min\n",
      "[Memory]0.5s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/9714ccef2b49a3c176f13a79dc49455c\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.5s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/58cd3ef6911d37a4ffbafd133642fc51\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/a2ff74ffa2d6f71f41e4ee2831ca4fa8\n",
      "___________________________________fit_transform_one cache loaded - 0.4s, 0.0min\n",
      "[Memory]0.5s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/4b35b965a17862ece7cac259e9a5c1bf\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.5s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/675e6d77b110262d0691404b4c39db93\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/3d4677ec42067bc6e1adbd41a0b286e9\n",
      "___________________________________fit_transform_one cache loaded - 0.4s, 0.0min\n",
      "[Memory]0.5s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/4d98c639017c8262d49930e011c29307\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.5s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/8e2d435ce11e45bb4894298b3ea0fd6b\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/0482c4d64fa45188abf2a238a6243aa4\n",
      "___________________________________fit_transform_one cache loaded - 0.4s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/c76bec7cac51604944bdc6c68488c092\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/827b5d2042e1e9dcd857792e74219fe9\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/111d8f1a7a88a782090fbe1ff500e18f\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/3375a5000b5bc9b4a9c9330cf67af690\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/88542b44bf6cbcb678f39d23f49db98e\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/225ba5546c8de6efc85d097dd878e926\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/332b067f1be94b1d6da79319de71b4c1\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/fc1b32984b30b48ffe52927e9dfcdbff\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/0a11989720b3800e8e13c3d35068a0ae\n",
      "___________________________________fit_transform_one cache loaded - 0.4s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/2633f6df6145949646804d8b5609103f\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/130877cbdf15827c51ccc493979819fe\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.1s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/6852a990bd707c236e3887afd39eb25d\n",
      "___________________________________fit_transform_one cache loaded - 0.4s, 0.0min\n",
      "[Memory]0.5s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/2b0094f42b7a9be6d3c26b5d01e16d45\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.5s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/dee4ed6d13279b7c4b04364f07926caf\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/a37a5965428df82e3af5f29912956ad8\n",
      "___________________________________fit_transform_one cache loaded - 0.4s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/0fa844dc035dcc36a51d836ac278cde9\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/76322d282539732f202e148ded5b64b3\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/1cc022731abc3fd426b3debb0fe32152\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/e42954c5be8d6675b299c764a7b14e8f\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/4ff65243e16400fb46891ed6001aec7d\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/6cad3cf637d4b8a8565841c0ebf70090\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/05f572f5554cc2f5dded0862626b4893\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/b3b7ec6e8e751ed0e797a8aaac603359\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/719903506d1e231c9b42b916b113f726\n",
      "___________________________________fit_transform_one cache loaded - 0.4s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/c911afcac8230a4a0b7cc35f9e800d75\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/4f13554041177803c49f2df2b8a7b57d\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/f51f67a12e05f28ee1a2b223c840b657\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/b5eefb4b7f0e1dc6b2f81b17cc568cd6\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/20ce79ea31f39134e5713292fe2fe9e2\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/78e41de6f9c25d7c944d51c4f2d3a6a2\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/be99645267b96e4b57f580fb49530fe9\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/700f667e24867f7ad2bc85ded72febd3\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/6b11bb98e03497289adbf581e02b75dd\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/ccc3cd0e401d9cbe7f94efaba15cc805\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/6a29b9d4be63b1171b4d4ca01aa1206d\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.1s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/c126cb77a66cd1ba0aa0a2dc26cd87e5\n",
      "___________________________________fit_transform_one cache loaded - 0.4s, 0.0min\n",
      "[Memory]0.5s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/ed30e9ad6db96077e3cfe85cbfe63c48\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.5s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/4f83ed2965b5cb6c2e67ed0762d65dbf\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/e13a0cabdde97cff9f382e270eeadbe9\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/1cc3b8b7c6ed48ffc37f02a2d15017d4\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/66b1b5eeef3449b9d0ae728c32f4c778\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.2s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/398b6b94daa65494b1af0c3ec4aa24a1\n",
      "___________________________________fit_transform_one cache loaded - 0.5s, 0.0min\n",
      "[Memory]0.6s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/34bda755e91f0eada5fb2b4513030717\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.7s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/6b34adcfff690cea0faccbb9204e1771\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(CountVectorizer(analyzer=<function stem_rmv_nums at 0x12655c7b8>,\n",
      "        binary=False, decode_error='strict', dtype=<class 'numpy.int64'>,\n",
      "        encoding='utf-8', input='content', lowercase=True, max_df=1.0,\n",
      "        max_features=None, min_df=5, ngram_range=(1, 1), preprocessor=None,\n",
      "        stop_words=None, strip_accents=None,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, vocabulary=None), \n",
      "[ 'From: sac@asdi.saic.com (Steve A. Conroy x6172)\\n'\n",
      "  'Subject: Re: Darrrrrrrrryl\\n'\n",
      "  'Organization: SAIC\\n'\n",
      "  'Lines: 33\\n'\n",
      "  '\\n'\n",
      "  'In article <mssC5KCru.5Ip@netcom.com>, mss@netcom.com (Mark Singer) '\n",
      "  'writes:\\n'\n",
      "  '|> \\n'\n",
      "  '|> \\n'\n",
      "  '|> The media is beating the incident at Dodger Stadium on Wednesday to\\n'\n",
      "  \"|> death, but I haven't seen anything in rsb yet.\\n\"\n",
      "  '|> \\n'\n",
      "  '|> Gerald Perry of the Cardinals pinch hit in the eighth inning with two\\n'\n",
      "  '|> on and his club down by a run.  He stroked a line drive into the\\n'\n",
      "  '|> right field corner.  The ball cleared the three-foot high fence and\\n'\n",
      "  '|> went into the crowd.  Darryl, racing over from right center, got to\\n'\n",
      "  '|> th..., \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "..., \n",
      "None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/pipeline.py:230: UserWarning: Persisting input arguments took 2.25s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______________________________________________fit_transform_one - 74.0s, 1.2min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True), <4732x10422 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 350314 stored elements in Compressed Sparse Row format>, \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "..., \n",
      "None)\n",
      "________________________________________________fit_transform_one - 0.1s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), \n",
      "<4732x10422 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 350314 stored elements in Compressed Sparse Row format>, \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "..., \n",
      "None)\n",
      "________________________________________________fit_transform_one - 0.5s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Do not remove headers and footers\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# used to cache results\n",
    "from tempfile import mkdtemp\n",
    "from shutil import rmtree\n",
    "from sklearn.externals.joblib import Memory\n",
    "# print(__doc__)\n",
    "cachedir = mkdtemp()\n",
    "memory = Memory(location=cachedir, verbose=10)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(min_df=1, stop_words='english')),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('reduce_dim', TruncatedSVD(random_state=42)),\n",
    "    ('clf', GaussianNB()),\n",
    "],\n",
    "memory=memory\n",
    ")\n",
    "\n",
    "param_grid = [\n",
    "    {\n",
    "        'vect': [\n",
    "            CountVectorizer(min_df=3, stop_words='english'),\n",
    "            CountVectorizer(min_df=3, analyzer=stem_rmv_nums),\n",
    "            CountVectorizer(min_df=5, stop_words='english'),\n",
    "            CountVectorizer(min_df=5, analyzer=stem_rmv_nums)\n",
    "        ],\n",
    "        'reduce_dim': [TruncatedSVD(n_components=50, random_state=42),\n",
    "                       NMF(n_components=50, init='random', random_state=42)\n",
    "        ],\n",
    "        'clf': [SVC(kernel='linear', C=10, random_state=42),\n",
    "                LogisticRegression(penalty='l2', C=100, random_state=42),\n",
    "                LogisticRegression(penalty='l1', C=10, random_state=42),\n",
    "                GaussianNB()\n",
    "        ],\n",
    "    }\n",
    "]\n",
    "# reducer_labels = ['LinearSVC', 'NMF', 'KBest(chi2)']\n",
    "\n",
    "grid = GridSearchCV(pipeline, cv=5, n_jobs=1, param_grid=param_grid, scoring='accuracy')\n",
    "grid.fit(train_dataset.data, new_train_label)\n",
    "rmtree(cachedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_clf</th>\n",
       "      <th>param_reduce_dim</th>\n",
       "      <th>param_vect</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.557260</td>\n",
       "      <td>1.081095</td>\n",
       "      <td>0.319253</td>\n",
       "      <td>0.090035</td>\n",
       "      <td>SVC(C=10, cache_size=200, class_weight=None, c...</td>\n",
       "      <td>TruncatedSVD(algorithm='randomized', n_compone...</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>{'clf': SVC(C=10, cache_size=200, class_weight...</td>\n",
       "      <td>0.968321</td>\n",
       "      <td>0.974657</td>\n",
       "      <td>...</td>\n",
       "      <td>0.974007</td>\n",
       "      <td>0.003681</td>\n",
       "      <td>6</td>\n",
       "      <td>0.977015</td>\n",
       "      <td>0.977543</td>\n",
       "      <td>0.974637</td>\n",
       "      <td>0.977813</td>\n",
       "      <td>0.978875</td>\n",
       "      <td>0.977176</td>\n",
       "      <td>0.001407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63.944739</td>\n",
       "      <td>6.623394</td>\n",
       "      <td>14.921423</td>\n",
       "      <td>1.106898</td>\n",
       "      <td>SVC(C=10, cache_size=200, class_weight=None, c...</td>\n",
       "      <td>TruncatedSVD(algorithm='randomized', n_compone...</td>\n",
       "      <td>CountVectorizer(analyzer=&lt;function stem_rmv_nu...</td>\n",
       "      <td>{'clf': SVC(C=10, cache_size=200, class_weight...</td>\n",
       "      <td>0.972545</td>\n",
       "      <td>0.974657</td>\n",
       "      <td>...</td>\n",
       "      <td>0.973373</td>\n",
       "      <td>0.002244</td>\n",
       "      <td>10</td>\n",
       "      <td>0.977543</td>\n",
       "      <td>0.975694</td>\n",
       "      <td>0.975694</td>\n",
       "      <td>0.977021</td>\n",
       "      <td>0.978611</td>\n",
       "      <td>0.976912</td>\n",
       "      <td>0.001119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.943457</td>\n",
       "      <td>0.357226</td>\n",
       "      <td>0.245360</td>\n",
       "      <td>0.008052</td>\n",
       "      <td>SVC(C=10, cache_size=200, class_weight=None, c...</td>\n",
       "      <td>TruncatedSVD(algorithm='randomized', n_compone...</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>{'clf': SVC(C=10, cache_size=200, class_weight...</td>\n",
       "      <td>0.969377</td>\n",
       "      <td>0.972545</td>\n",
       "      <td>...</td>\n",
       "      <td>0.972527</td>\n",
       "      <td>0.003463</td>\n",
       "      <td>12</td>\n",
       "      <td>0.977279</td>\n",
       "      <td>0.977279</td>\n",
       "      <td>0.974901</td>\n",
       "      <td>0.976756</td>\n",
       "      <td>0.977819</td>\n",
       "      <td>0.976807</td>\n",
       "      <td>0.001010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61.596599</td>\n",
       "      <td>1.050247</td>\n",
       "      <td>14.728722</td>\n",
       "      <td>1.212823</td>\n",
       "      <td>SVC(C=10, cache_size=200, class_weight=None, c...</td>\n",
       "      <td>TruncatedSVD(algorithm='randomized', n_compone...</td>\n",
       "      <td>CountVectorizer(analyzer=&lt;function stem_rmv_nu...</td>\n",
       "      <td>{'clf': SVC(C=10, cache_size=200, class_weight...</td>\n",
       "      <td>0.971489</td>\n",
       "      <td>0.973601</td>\n",
       "      <td>...</td>\n",
       "      <td>0.973795</td>\n",
       "      <td>0.001384</td>\n",
       "      <td>8</td>\n",
       "      <td>0.977279</td>\n",
       "      <td>0.975429</td>\n",
       "      <td>0.974108</td>\n",
       "      <td>0.975964</td>\n",
       "      <td>0.977555</td>\n",
       "      <td>0.976067</td>\n",
       "      <td>0.001260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21.160269</td>\n",
       "      <td>5.095933</td>\n",
       "      <td>0.371571</td>\n",
       "      <td>0.024480</td>\n",
       "      <td>SVC(C=10, cache_size=200, class_weight=None, c...</td>\n",
       "      <td>NMF(alpha=0.0, beta_loss='frobenius', init='ra...</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>{'clf': SVC(C=10, cache_size=200, class_weight...</td>\n",
       "      <td>0.963041</td>\n",
       "      <td>0.959873</td>\n",
       "      <td>...</td>\n",
       "      <td>0.961116</td>\n",
       "      <td>0.004496</td>\n",
       "      <td>23</td>\n",
       "      <td>0.963540</td>\n",
       "      <td>0.959049</td>\n",
       "      <td>0.960634</td>\n",
       "      <td>0.955890</td>\n",
       "      <td>0.956166</td>\n",
       "      <td>0.959056</td>\n",
       "      <td>0.002863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>19.179709</td>\n",
       "      <td>2.147933</td>\n",
       "      <td>15.114380</td>\n",
       "      <td>1.406758</td>\n",
       "      <td>SVC(C=10, cache_size=200, class_weight=None, c...</td>\n",
       "      <td>NMF(alpha=0.0, beta_loss='frobenius', init='ra...</td>\n",
       "      <td>CountVectorizer(analyzer=&lt;function stem_rmv_nu...</td>\n",
       "      <td>{'clf': SVC(C=10, cache_size=200, class_weight...</td>\n",
       "      <td>0.970433</td>\n",
       "      <td>0.956705</td>\n",
       "      <td>...</td>\n",
       "      <td>0.961961</td>\n",
       "      <td>0.004722</td>\n",
       "      <td>22</td>\n",
       "      <td>0.964333</td>\n",
       "      <td>0.954557</td>\n",
       "      <td>0.960106</td>\n",
       "      <td>0.956947</td>\n",
       "      <td>0.959599</td>\n",
       "      <td>0.959108</td>\n",
       "      <td>0.003284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>18.506962</td>\n",
       "      <td>3.308128</td>\n",
       "      <td>0.460090</td>\n",
       "      <td>0.139502</td>\n",
       "      <td>SVC(C=10, cache_size=200, class_weight=None, c...</td>\n",
       "      <td>NMF(alpha=0.0, beta_loss='frobenius', init='ra...</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>{'clf': SVC(C=10, cache_size=200, class_weight...</td>\n",
       "      <td>0.971489</td>\n",
       "      <td>0.959873</td>\n",
       "      <td>...</td>\n",
       "      <td>0.961116</td>\n",
       "      <td>0.006919</td>\n",
       "      <td>23</td>\n",
       "      <td>0.965125</td>\n",
       "      <td>0.957199</td>\n",
       "      <td>0.956407</td>\n",
       "      <td>0.956154</td>\n",
       "      <td>0.959863</td>\n",
       "      <td>0.958950</td>\n",
       "      <td>0.003356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>12.778025</td>\n",
       "      <td>4.431236</td>\n",
       "      <td>15.204809</td>\n",
       "      <td>1.012487</td>\n",
       "      <td>SVC(C=10, cache_size=200, class_weight=None, c...</td>\n",
       "      <td>NMF(alpha=0.0, beta_loss='frobenius', init='ra...</td>\n",
       "      <td>CountVectorizer(analyzer=&lt;function stem_rmv_nu...</td>\n",
       "      <td>{'clf': SVC(C=10, cache_size=200, class_weight...</td>\n",
       "      <td>0.964097</td>\n",
       "      <td>0.960929</td>\n",
       "      <td>...</td>\n",
       "      <td>0.963440</td>\n",
       "      <td>0.003733</td>\n",
       "      <td>21</td>\n",
       "      <td>0.965918</td>\n",
       "      <td>0.965125</td>\n",
       "      <td>0.962483</td>\n",
       "      <td>0.966719</td>\n",
       "      <td>0.964352</td>\n",
       "      <td>0.964920</td>\n",
       "      <td>0.001452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.767613</td>\n",
       "      <td>0.226947</td>\n",
       "      <td>0.339406</td>\n",
       "      <td>0.074087</td>\n",
       "      <td>LogisticRegression(C=100, class_weight=None, d...</td>\n",
       "      <td>TruncatedSVD(algorithm='randomized', n_compone...</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>{'clf': LogisticRegression(C=100, class_weight...</td>\n",
       "      <td>0.970433</td>\n",
       "      <td>0.973601</td>\n",
       "      <td>...</td>\n",
       "      <td>0.974218</td>\n",
       "      <td>0.003369</td>\n",
       "      <td>4</td>\n",
       "      <td>0.978336</td>\n",
       "      <td>0.978864</td>\n",
       "      <td>0.976486</td>\n",
       "      <td>0.979134</td>\n",
       "      <td>0.978875</td>\n",
       "      <td>0.978339</td>\n",
       "      <td>0.000962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.519141</td>\n",
       "      <td>0.024996</td>\n",
       "      <td>15.398905</td>\n",
       "      <td>1.630857</td>\n",
       "      <td>LogisticRegression(C=100, class_weight=None, d...</td>\n",
       "      <td>TruncatedSVD(algorithm='randomized', n_compone...</td>\n",
       "      <td>CountVectorizer(analyzer=&lt;function stem_rmv_nu...</td>\n",
       "      <td>{'clf': LogisticRegression(C=100, class_weight...</td>\n",
       "      <td>0.970433</td>\n",
       "      <td>0.971489</td>\n",
       "      <td>...</td>\n",
       "      <td>0.974007</td>\n",
       "      <td>0.002940</td>\n",
       "      <td>6</td>\n",
       "      <td>0.979657</td>\n",
       "      <td>0.976222</td>\n",
       "      <td>0.976486</td>\n",
       "      <td>0.978870</td>\n",
       "      <td>0.979139</td>\n",
       "      <td>0.978075</td>\n",
       "      <td>0.001430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.513977</td>\n",
       "      <td>0.011012</td>\n",
       "      <td>0.221241</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>LogisticRegression(C=100, class_weight=None, d...</td>\n",
       "      <td>TruncatedSVD(algorithm='randomized', n_compone...</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>{'clf': LogisticRegression(C=100, class_weight...</td>\n",
       "      <td>0.970433</td>\n",
       "      <td>0.972545</td>\n",
       "      <td>...</td>\n",
       "      <td>0.972739</td>\n",
       "      <td>0.002932</td>\n",
       "      <td>11</td>\n",
       "      <td>0.978071</td>\n",
       "      <td>0.977807</td>\n",
       "      <td>0.976486</td>\n",
       "      <td>0.978605</td>\n",
       "      <td>0.978347</td>\n",
       "      <td>0.977863</td>\n",
       "      <td>0.000739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.458189</td>\n",
       "      <td>0.029620</td>\n",
       "      <td>17.062690</td>\n",
       "      <td>3.396922</td>\n",
       "      <td>LogisticRegression(C=100, class_weight=None, d...</td>\n",
       "      <td>TruncatedSVD(algorithm='randomized', n_compone...</td>\n",
       "      <td>CountVectorizer(analyzer=&lt;function stem_rmv_nu...</td>\n",
       "      <td>{'clf': LogisticRegression(C=100, class_weight...</td>\n",
       "      <td>0.970433</td>\n",
       "      <td>0.973601</td>\n",
       "      <td>...</td>\n",
       "      <td>0.974218</td>\n",
       "      <td>0.002362</td>\n",
       "      <td>4</td>\n",
       "      <td>0.979128</td>\n",
       "      <td>0.973844</td>\n",
       "      <td>0.975694</td>\n",
       "      <td>0.978870</td>\n",
       "      <td>0.977819</td>\n",
       "      <td>0.977071</td>\n",
       "      <td>0.002017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.545759</td>\n",
       "      <td>0.012454</td>\n",
       "      <td>0.315529</td>\n",
       "      <td>0.013141</td>\n",
       "      <td>LogisticRegression(C=100, class_weight=None, d...</td>\n",
       "      <td>NMF(alpha=0.0, beta_loss='frobenius', init='ra...</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>{'clf': LogisticRegression(C=100, class_weight...</td>\n",
       "      <td>0.968321</td>\n",
       "      <td>0.960929</td>\n",
       "      <td>...</td>\n",
       "      <td>0.965765</td>\n",
       "      <td>0.004639</td>\n",
       "      <td>18</td>\n",
       "      <td>0.969353</td>\n",
       "      <td>0.965125</td>\n",
       "      <td>0.964861</td>\n",
       "      <td>0.963022</td>\n",
       "      <td>0.965672</td>\n",
       "      <td>0.965607</td>\n",
       "      <td>0.002074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.486747</td>\n",
       "      <td>0.027588</td>\n",
       "      <td>14.538339</td>\n",
       "      <td>1.074393</td>\n",
       "      <td>LogisticRegression(C=100, class_weight=None, d...</td>\n",
       "      <td>NMF(alpha=0.0, beta_loss='frobenius', init='ra...</td>\n",
       "      <td>CountVectorizer(analyzer=&lt;function stem_rmv_nu...</td>\n",
       "      <td>{'clf': LogisticRegression(C=100, class_weight...</td>\n",
       "      <td>0.971489</td>\n",
       "      <td>0.964097</td>\n",
       "      <td>...</td>\n",
       "      <td>0.966610</td>\n",
       "      <td>0.004139</td>\n",
       "      <td>16</td>\n",
       "      <td>0.968560</td>\n",
       "      <td>0.961955</td>\n",
       "      <td>0.964069</td>\n",
       "      <td>0.964342</td>\n",
       "      <td>0.964880</td>\n",
       "      <td>0.964761</td>\n",
       "      <td>0.002144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.476165</td>\n",
       "      <td>0.004496</td>\n",
       "      <td>0.279357</td>\n",
       "      <td>0.012001</td>\n",
       "      <td>LogisticRegression(C=100, class_weight=None, d...</td>\n",
       "      <td>NMF(alpha=0.0, beta_loss='frobenius', init='ra...</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>{'clf': LogisticRegression(C=100, class_weight...</td>\n",
       "      <td>0.967265</td>\n",
       "      <td>0.970433</td>\n",
       "      <td>...</td>\n",
       "      <td>0.966610</td>\n",
       "      <td>0.003102</td>\n",
       "      <td>16</td>\n",
       "      <td>0.968032</td>\n",
       "      <td>0.963540</td>\n",
       "      <td>0.963012</td>\n",
       "      <td>0.964606</td>\n",
       "      <td>0.965936</td>\n",
       "      <td>0.965025</td>\n",
       "      <td>0.001806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.448598</td>\n",
       "      <td>0.041978</td>\n",
       "      <td>14.996127</td>\n",
       "      <td>0.847849</td>\n",
       "      <td>LogisticRegression(C=100, class_weight=None, d...</td>\n",
       "      <td>NMF(alpha=0.0, beta_loss='frobenius', init='ra...</td>\n",
       "      <td>CountVectorizer(analyzer=&lt;function stem_rmv_nu...</td>\n",
       "      <td>{'clf': LogisticRegression(C=100, class_weight...</td>\n",
       "      <td>0.966209</td>\n",
       "      <td>0.964097</td>\n",
       "      <td>...</td>\n",
       "      <td>0.965131</td>\n",
       "      <td>0.003385</td>\n",
       "      <td>20</td>\n",
       "      <td>0.966975</td>\n",
       "      <td>0.969353</td>\n",
       "      <td>0.968032</td>\n",
       "      <td>0.969889</td>\n",
       "      <td>0.969633</td>\n",
       "      <td>0.968776</td>\n",
       "      <td>0.001105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.642173</td>\n",
       "      <td>0.042271</td>\n",
       "      <td>0.265106</td>\n",
       "      <td>0.028434</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>TruncatedSVD(algorithm='randomized', n_compone...</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>{'clf': LogisticRegression(C=10, class_weight=...</td>\n",
       "      <td>0.972545</td>\n",
       "      <td>0.971489</td>\n",
       "      <td>...</td>\n",
       "      <td>0.974641</td>\n",
       "      <td>0.003192</td>\n",
       "      <td>3</td>\n",
       "      <td>0.978071</td>\n",
       "      <td>0.978600</td>\n",
       "      <td>0.976486</td>\n",
       "      <td>0.980718</td>\n",
       "      <td>0.977819</td>\n",
       "      <td>0.978339</td>\n",
       "      <td>0.001379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.530679</td>\n",
       "      <td>0.014311</td>\n",
       "      <td>14.533985</td>\n",
       "      <td>0.649265</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>TruncatedSVD(algorithm='randomized', n_compone...</td>\n",
       "      <td>CountVectorizer(analyzer=&lt;function stem_rmv_nu...</td>\n",
       "      <td>{'clf': LogisticRegression(C=10, class_weight=...</td>\n",
       "      <td>0.971489</td>\n",
       "      <td>0.970433</td>\n",
       "      <td>...</td>\n",
       "      <td>0.974852</td>\n",
       "      <td>0.003220</td>\n",
       "      <td>2</td>\n",
       "      <td>0.978600</td>\n",
       "      <td>0.975958</td>\n",
       "      <td>0.977015</td>\n",
       "      <td>0.979662</td>\n",
       "      <td>0.979403</td>\n",
       "      <td>0.978127</td>\n",
       "      <td>0.001425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.565735</td>\n",
       "      <td>0.019394</td>\n",
       "      <td>0.239978</td>\n",
       "      <td>0.006986</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>TruncatedSVD(algorithm='randomized', n_compone...</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>{'clf': LogisticRegression(C=10, class_weight=...</td>\n",
       "      <td>0.971489</td>\n",
       "      <td>0.973601</td>\n",
       "      <td>...</td>\n",
       "      <td>0.973584</td>\n",
       "      <td>0.003592</td>\n",
       "      <td>9</td>\n",
       "      <td>0.978864</td>\n",
       "      <td>0.978600</td>\n",
       "      <td>0.977279</td>\n",
       "      <td>0.979926</td>\n",
       "      <td>0.976234</td>\n",
       "      <td>0.978181</td>\n",
       "      <td>0.001288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.470892</td>\n",
       "      <td>0.023071</td>\n",
       "      <td>14.621430</td>\n",
       "      <td>0.986598</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>TruncatedSVD(algorithm='randomized', n_compone...</td>\n",
       "      <td>CountVectorizer(analyzer=&lt;function stem_rmv_nu...</td>\n",
       "      <td>{'clf': LogisticRegression(C=10, class_weight=...</td>\n",
       "      <td>0.972545</td>\n",
       "      <td>0.973601</td>\n",
       "      <td>...</td>\n",
       "      <td>0.975486</td>\n",
       "      <td>0.002241</td>\n",
       "      <td>1</td>\n",
       "      <td>0.978864</td>\n",
       "      <td>0.974901</td>\n",
       "      <td>0.976750</td>\n",
       "      <td>0.978605</td>\n",
       "      <td>0.978611</td>\n",
       "      <td>0.977546</td>\n",
       "      <td>0.001525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.550019</td>\n",
       "      <td>0.008803</td>\n",
       "      <td>0.302240</td>\n",
       "      <td>0.014709</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>NMF(alpha=0.0, beta_loss='frobenius', init='ra...</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>{'clf': LogisticRegression(C=10, class_weight=...</td>\n",
       "      <td>0.965153</td>\n",
       "      <td>0.965153</td>\n",
       "      <td>...</td>\n",
       "      <td>0.967878</td>\n",
       "      <td>0.003227</td>\n",
       "      <td>14</td>\n",
       "      <td>0.970410</td>\n",
       "      <td>0.968824</td>\n",
       "      <td>0.967768</td>\n",
       "      <td>0.966455</td>\n",
       "      <td>0.967520</td>\n",
       "      <td>0.968195</td>\n",
       "      <td>0.001339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.480112</td>\n",
       "      <td>0.004660</td>\n",
       "      <td>14.274583</td>\n",
       "      <td>0.754601</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>NMF(alpha=0.0, beta_loss='frobenius', init='ra...</td>\n",
       "      <td>CountVectorizer(analyzer=&lt;function stem_rmv_nu...</td>\n",
       "      <td>{'clf': LogisticRegression(C=10, class_weight=...</td>\n",
       "      <td>0.968321</td>\n",
       "      <td>0.969377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.970203</td>\n",
       "      <td>0.002599</td>\n",
       "      <td>13</td>\n",
       "      <td>0.970145</td>\n",
       "      <td>0.968824</td>\n",
       "      <td>0.971995</td>\n",
       "      <td>0.973059</td>\n",
       "      <td>0.969369</td>\n",
       "      <td>0.970678</td>\n",
       "      <td>0.001602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.547234</td>\n",
       "      <td>0.128814</td>\n",
       "      <td>0.279752</td>\n",
       "      <td>0.009650</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>NMF(alpha=0.0, beta_loss='frobenius', init='ra...</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>{'clf': LogisticRegression(C=10, class_weight=...</td>\n",
       "      <td>0.961985</td>\n",
       "      <td>0.968321</td>\n",
       "      <td>...</td>\n",
       "      <td>0.965554</td>\n",
       "      <td>0.003919</td>\n",
       "      <td>19</td>\n",
       "      <td>0.972259</td>\n",
       "      <td>0.968032</td>\n",
       "      <td>0.963804</td>\n",
       "      <td>0.969625</td>\n",
       "      <td>0.971217</td>\n",
       "      <td>0.968987</td>\n",
       "      <td>0.002962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.429231</td>\n",
       "      <td>0.008826</td>\n",
       "      <td>14.198473</td>\n",
       "      <td>0.760005</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>NMF(alpha=0.0, beta_loss='frobenius', init='ra...</td>\n",
       "      <td>CountVectorizer(analyzer=&lt;function stem_rmv_nu...</td>\n",
       "      <td>{'clf': LogisticRegression(C=10, class_weight=...</td>\n",
       "      <td>0.966209</td>\n",
       "      <td>0.968321</td>\n",
       "      <td>...</td>\n",
       "      <td>0.967667</td>\n",
       "      <td>0.003226</td>\n",
       "      <td>15</td>\n",
       "      <td>0.969089</td>\n",
       "      <td>0.969617</td>\n",
       "      <td>0.972259</td>\n",
       "      <td>0.975172</td>\n",
       "      <td>0.969897</td>\n",
       "      <td>0.971207</td>\n",
       "      <td>0.002261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.539780</td>\n",
       "      <td>0.029918</td>\n",
       "      <td>0.230348</td>\n",
       "      <td>0.026177</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "      <td>TruncatedSVD(algorithm='randomized', n_compone...</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>{'clf': GaussianNB(priors=None, var_smoothing=...</td>\n",
       "      <td>0.884900</td>\n",
       "      <td>0.930306</td>\n",
       "      <td>...</td>\n",
       "      <td>0.912933</td>\n",
       "      <td>0.015050</td>\n",
       "      <td>30</td>\n",
       "      <td>0.904888</td>\n",
       "      <td>0.928402</td>\n",
       "      <td>0.913342</td>\n",
       "      <td>0.912044</td>\n",
       "      <td>0.894904</td>\n",
       "      <td>0.910716</td>\n",
       "      <td>0.011004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.480395</td>\n",
       "      <td>0.035184</td>\n",
       "      <td>14.977582</td>\n",
       "      <td>1.453776</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "      <td>TruncatedSVD(algorithm='randomized', n_compone...</td>\n",
       "      <td>CountVectorizer(analyzer=&lt;function stem_rmv_nu...</td>\n",
       "      <td>{'clf': GaussianNB(priors=None, var_smoothing=...</td>\n",
       "      <td>0.935586</td>\n",
       "      <td>0.918691</td>\n",
       "      <td>...</td>\n",
       "      <td>0.907861</td>\n",
       "      <td>0.024198</td>\n",
       "      <td>31</td>\n",
       "      <td>0.922853</td>\n",
       "      <td>0.920476</td>\n",
       "      <td>0.885073</td>\n",
       "      <td>0.884046</td>\n",
       "      <td>0.925271</td>\n",
       "      <td>0.907544</td>\n",
       "      <td>0.018830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.686169</td>\n",
       "      <td>0.128471</td>\n",
       "      <td>0.348328</td>\n",
       "      <td>0.073099</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "      <td>TruncatedSVD(algorithm='randomized', n_compone...</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>{'clf': GaussianNB(priors=None, var_smoothing=...</td>\n",
       "      <td>0.920803</td>\n",
       "      <td>0.923970</td>\n",
       "      <td>...</td>\n",
       "      <td>0.913145</td>\n",
       "      <td>0.014795</td>\n",
       "      <td>29</td>\n",
       "      <td>0.923910</td>\n",
       "      <td>0.919947</td>\n",
       "      <td>0.896697</td>\n",
       "      <td>0.886424</td>\n",
       "      <td>0.918669</td>\n",
       "      <td>0.909130</td>\n",
       "      <td>0.014809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.415506</td>\n",
       "      <td>0.008169</td>\n",
       "      <td>14.983043</td>\n",
       "      <td>0.910319</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "      <td>TruncatedSVD(algorithm='randomized', n_compone...</td>\n",
       "      <td>CountVectorizer(analyzer=&lt;function stem_rmv_nu...</td>\n",
       "      <td>{'clf': GaussianNB(priors=None, var_smoothing=...</td>\n",
       "      <td>0.936642</td>\n",
       "      <td>0.889124</td>\n",
       "      <td>...</td>\n",
       "      <td>0.901310</td>\n",
       "      <td>0.025152</td>\n",
       "      <td>32</td>\n",
       "      <td>0.926024</td>\n",
       "      <td>0.898283</td>\n",
       "      <td>0.882695</td>\n",
       "      <td>0.896989</td>\n",
       "      <td>0.923158</td>\n",
       "      <td>0.905430</td>\n",
       "      <td>0.016599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.539367</td>\n",
       "      <td>0.008175</td>\n",
       "      <td>0.315292</td>\n",
       "      <td>0.012289</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "      <td>NMF(alpha=0.0, beta_loss='frobenius', init='ra...</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>{'clf': GaussianNB(priors=None, var_smoothing=...</td>\n",
       "      <td>0.949314</td>\n",
       "      <td>0.948258</td>\n",
       "      <td>...</td>\n",
       "      <td>0.943576</td>\n",
       "      <td>0.005214</td>\n",
       "      <td>27</td>\n",
       "      <td>0.944782</td>\n",
       "      <td>0.946631</td>\n",
       "      <td>0.942404</td>\n",
       "      <td>0.946117</td>\n",
       "      <td>0.942435</td>\n",
       "      <td>0.944474</td>\n",
       "      <td>0.001783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.486586</td>\n",
       "      <td>0.043844</td>\n",
       "      <td>15.789191</td>\n",
       "      <td>2.874070</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "      <td>NMF(alpha=0.0, beta_loss='frobenius', init='ra...</td>\n",
       "      <td>CountVectorizer(analyzer=&lt;function stem_rmv_nu...</td>\n",
       "      <td>{'clf': GaussianNB(priors=None, var_smoothing=...</td>\n",
       "      <td>0.952482</td>\n",
       "      <td>0.950370</td>\n",
       "      <td>...</td>\n",
       "      <td>0.947168</td>\n",
       "      <td>0.004722</td>\n",
       "      <td>25</td>\n",
       "      <td>0.950330</td>\n",
       "      <td>0.941876</td>\n",
       "      <td>0.940026</td>\n",
       "      <td>0.949815</td>\n",
       "      <td>0.944811</td>\n",
       "      <td>0.945372</td>\n",
       "      <td>0.004134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.463775</td>\n",
       "      <td>0.008045</td>\n",
       "      <td>0.274385</td>\n",
       "      <td>0.010935</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "      <td>NMF(alpha=0.0, beta_loss='frobenius', init='ra...</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>{'clf': GaussianNB(priors=None, var_smoothing=...</td>\n",
       "      <td>0.951426</td>\n",
       "      <td>0.944034</td>\n",
       "      <td>...</td>\n",
       "      <td>0.939772</td>\n",
       "      <td>0.007733</td>\n",
       "      <td>28</td>\n",
       "      <td>0.947952</td>\n",
       "      <td>0.940819</td>\n",
       "      <td>0.933421</td>\n",
       "      <td>0.942684</td>\n",
       "      <td>0.935833</td>\n",
       "      <td>0.940142</td>\n",
       "      <td>0.005131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.486615</td>\n",
       "      <td>0.101159</td>\n",
       "      <td>15.988325</td>\n",
       "      <td>1.507333</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "      <td>NMF(alpha=0.0, beta_loss='frobenius', init='ra...</td>\n",
       "      <td>CountVectorizer(analyzer=&lt;function stem_rmv_nu...</td>\n",
       "      <td>{'clf': GaussianNB(priors=None, var_smoothing=...</td>\n",
       "      <td>0.938754</td>\n",
       "      <td>0.961985</td>\n",
       "      <td>...</td>\n",
       "      <td>0.944421</td>\n",
       "      <td>0.008819</td>\n",
       "      <td>26</td>\n",
       "      <td>0.936063</td>\n",
       "      <td>0.945575</td>\n",
       "      <td>0.945839</td>\n",
       "      <td>0.944532</td>\n",
       "      <td>0.943755</td>\n",
       "      <td>0.943153</td>\n",
       "      <td>0.003622</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        7.557260      1.081095         0.319253        0.090035   \n",
       "1       63.944739      6.623394        14.921423        1.106898   \n",
       "2        4.943457      0.357226         0.245360        0.008052   \n",
       "3       61.596599      1.050247        14.728722        1.212823   \n",
       "4       21.160269      5.095933         0.371571        0.024480   \n",
       "5       19.179709      2.147933        15.114380        1.406758   \n",
       "6       18.506962      3.308128         0.460090        0.139502   \n",
       "7       12.778025      4.431236        15.204809        1.012487   \n",
       "8        0.767613      0.226947         0.339406        0.074087   \n",
       "9        0.519141      0.024996        15.398905        1.630857   \n",
       "10       0.513977      0.011012         0.221241        0.009766   \n",
       "11       0.458189      0.029620        17.062690        3.396922   \n",
       "12       0.545759      0.012454         0.315529        0.013141   \n",
       "13       0.486747      0.027588        14.538339        1.074393   \n",
       "14       0.476165      0.004496         0.279357        0.012001   \n",
       "15       0.448598      0.041978        14.996127        0.847849   \n",
       "16       0.642173      0.042271         0.265106        0.028434   \n",
       "17       0.530679      0.014311        14.533985        0.649265   \n",
       "18       0.565735      0.019394         0.239978        0.006986   \n",
       "19       0.470892      0.023071        14.621430        0.986598   \n",
       "20       0.550019      0.008803         0.302240        0.014709   \n",
       "21       0.480112      0.004660        14.274583        0.754601   \n",
       "22       0.547234      0.128814         0.279752        0.009650   \n",
       "23       0.429231      0.008826        14.198473        0.760005   \n",
       "24       0.539780      0.029918         0.230348        0.026177   \n",
       "25       0.480395      0.035184        14.977582        1.453776   \n",
       "26       0.686169      0.128471         0.348328        0.073099   \n",
       "27       0.415506      0.008169        14.983043        0.910319   \n",
       "28       0.539367      0.008175         0.315292        0.012289   \n",
       "29       0.486586      0.043844        15.789191        2.874070   \n",
       "30       0.463775      0.008045         0.274385        0.010935   \n",
       "31       0.486615      0.101159        15.988325        1.507333   \n",
       "\n",
       "                                            param_clf  \\\n",
       "0   SVC(C=10, cache_size=200, class_weight=None, c...   \n",
       "1   SVC(C=10, cache_size=200, class_weight=None, c...   \n",
       "2   SVC(C=10, cache_size=200, class_weight=None, c...   \n",
       "3   SVC(C=10, cache_size=200, class_weight=None, c...   \n",
       "4   SVC(C=10, cache_size=200, class_weight=None, c...   \n",
       "5   SVC(C=10, cache_size=200, class_weight=None, c...   \n",
       "6   SVC(C=10, cache_size=200, class_weight=None, c...   \n",
       "7   SVC(C=10, cache_size=200, class_weight=None, c...   \n",
       "8   LogisticRegression(C=100, class_weight=None, d...   \n",
       "9   LogisticRegression(C=100, class_weight=None, d...   \n",
       "10  LogisticRegression(C=100, class_weight=None, d...   \n",
       "11  LogisticRegression(C=100, class_weight=None, d...   \n",
       "12  LogisticRegression(C=100, class_weight=None, d...   \n",
       "13  LogisticRegression(C=100, class_weight=None, d...   \n",
       "14  LogisticRegression(C=100, class_weight=None, d...   \n",
       "15  LogisticRegression(C=100, class_weight=None, d...   \n",
       "16  LogisticRegression(C=10, class_weight=None, du...   \n",
       "17  LogisticRegression(C=10, class_weight=None, du...   \n",
       "18  LogisticRegression(C=10, class_weight=None, du...   \n",
       "19  LogisticRegression(C=10, class_weight=None, du...   \n",
       "20  LogisticRegression(C=10, class_weight=None, du...   \n",
       "21  LogisticRegression(C=10, class_weight=None, du...   \n",
       "22  LogisticRegression(C=10, class_weight=None, du...   \n",
       "23  LogisticRegression(C=10, class_weight=None, du...   \n",
       "24       GaussianNB(priors=None, var_smoothing=1e-09)   \n",
       "25       GaussianNB(priors=None, var_smoothing=1e-09)   \n",
       "26       GaussianNB(priors=None, var_smoothing=1e-09)   \n",
       "27       GaussianNB(priors=None, var_smoothing=1e-09)   \n",
       "28       GaussianNB(priors=None, var_smoothing=1e-09)   \n",
       "29       GaussianNB(priors=None, var_smoothing=1e-09)   \n",
       "30       GaussianNB(priors=None, var_smoothing=1e-09)   \n",
       "31       GaussianNB(priors=None, var_smoothing=1e-09)   \n",
       "\n",
       "                                     param_reduce_dim  \\\n",
       "0   TruncatedSVD(algorithm='randomized', n_compone...   \n",
       "1   TruncatedSVD(algorithm='randomized', n_compone...   \n",
       "2   TruncatedSVD(algorithm='randomized', n_compone...   \n",
       "3   TruncatedSVD(algorithm='randomized', n_compone...   \n",
       "4   NMF(alpha=0.0, beta_loss='frobenius', init='ra...   \n",
       "5   NMF(alpha=0.0, beta_loss='frobenius', init='ra...   \n",
       "6   NMF(alpha=0.0, beta_loss='frobenius', init='ra...   \n",
       "7   NMF(alpha=0.0, beta_loss='frobenius', init='ra...   \n",
       "8   TruncatedSVD(algorithm='randomized', n_compone...   \n",
       "9   TruncatedSVD(algorithm='randomized', n_compone...   \n",
       "10  TruncatedSVD(algorithm='randomized', n_compone...   \n",
       "11  TruncatedSVD(algorithm='randomized', n_compone...   \n",
       "12  NMF(alpha=0.0, beta_loss='frobenius', init='ra...   \n",
       "13  NMF(alpha=0.0, beta_loss='frobenius', init='ra...   \n",
       "14  NMF(alpha=0.0, beta_loss='frobenius', init='ra...   \n",
       "15  NMF(alpha=0.0, beta_loss='frobenius', init='ra...   \n",
       "16  TruncatedSVD(algorithm='randomized', n_compone...   \n",
       "17  TruncatedSVD(algorithm='randomized', n_compone...   \n",
       "18  TruncatedSVD(algorithm='randomized', n_compone...   \n",
       "19  TruncatedSVD(algorithm='randomized', n_compone...   \n",
       "20  NMF(alpha=0.0, beta_loss='frobenius', init='ra...   \n",
       "21  NMF(alpha=0.0, beta_loss='frobenius', init='ra...   \n",
       "22  NMF(alpha=0.0, beta_loss='frobenius', init='ra...   \n",
       "23  NMF(alpha=0.0, beta_loss='frobenius', init='ra...   \n",
       "24  TruncatedSVD(algorithm='randomized', n_compone...   \n",
       "25  TruncatedSVD(algorithm='randomized', n_compone...   \n",
       "26  TruncatedSVD(algorithm='randomized', n_compone...   \n",
       "27  TruncatedSVD(algorithm='randomized', n_compone...   \n",
       "28  NMF(alpha=0.0, beta_loss='frobenius', init='ra...   \n",
       "29  NMF(alpha=0.0, beta_loss='frobenius', init='ra...   \n",
       "30  NMF(alpha=0.0, beta_loss='frobenius', init='ra...   \n",
       "31  NMF(alpha=0.0, beta_loss='frobenius', init='ra...   \n",
       "\n",
       "                                           param_vect  \\\n",
       "0   CountVectorizer(analyzer='word', binary=False,...   \n",
       "1   CountVectorizer(analyzer=<function stem_rmv_nu...   \n",
       "2   CountVectorizer(analyzer='word', binary=False,...   \n",
       "3   CountVectorizer(analyzer=<function stem_rmv_nu...   \n",
       "4   CountVectorizer(analyzer='word', binary=False,...   \n",
       "5   CountVectorizer(analyzer=<function stem_rmv_nu...   \n",
       "6   CountVectorizer(analyzer='word', binary=False,...   \n",
       "7   CountVectorizer(analyzer=<function stem_rmv_nu...   \n",
       "8   CountVectorizer(analyzer='word', binary=False,...   \n",
       "9   CountVectorizer(analyzer=<function stem_rmv_nu...   \n",
       "10  CountVectorizer(analyzer='word', binary=False,...   \n",
       "11  CountVectorizer(analyzer=<function stem_rmv_nu...   \n",
       "12  CountVectorizer(analyzer='word', binary=False,...   \n",
       "13  CountVectorizer(analyzer=<function stem_rmv_nu...   \n",
       "14  CountVectorizer(analyzer='word', binary=False,...   \n",
       "15  CountVectorizer(analyzer=<function stem_rmv_nu...   \n",
       "16  CountVectorizer(analyzer='word', binary=False,...   \n",
       "17  CountVectorizer(analyzer=<function stem_rmv_nu...   \n",
       "18  CountVectorizer(analyzer='word', binary=False,...   \n",
       "19  CountVectorizer(analyzer=<function stem_rmv_nu...   \n",
       "20  CountVectorizer(analyzer='word', binary=False,...   \n",
       "21  CountVectorizer(analyzer=<function stem_rmv_nu...   \n",
       "22  CountVectorizer(analyzer='word', binary=False,...   \n",
       "23  CountVectorizer(analyzer=<function stem_rmv_nu...   \n",
       "24  CountVectorizer(analyzer='word', binary=False,...   \n",
       "25  CountVectorizer(analyzer=<function stem_rmv_nu...   \n",
       "26  CountVectorizer(analyzer='word', binary=False,...   \n",
       "27  CountVectorizer(analyzer=<function stem_rmv_nu...   \n",
       "28  CountVectorizer(analyzer='word', binary=False,...   \n",
       "29  CountVectorizer(analyzer=<function stem_rmv_nu...   \n",
       "30  CountVectorizer(analyzer='word', binary=False,...   \n",
       "31  CountVectorizer(analyzer=<function stem_rmv_nu...   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'clf': SVC(C=10, cache_size=200, class_weight...           0.968321   \n",
       "1   {'clf': SVC(C=10, cache_size=200, class_weight...           0.972545   \n",
       "2   {'clf': SVC(C=10, cache_size=200, class_weight...           0.969377   \n",
       "3   {'clf': SVC(C=10, cache_size=200, class_weight...           0.971489   \n",
       "4   {'clf': SVC(C=10, cache_size=200, class_weight...           0.963041   \n",
       "5   {'clf': SVC(C=10, cache_size=200, class_weight...           0.970433   \n",
       "6   {'clf': SVC(C=10, cache_size=200, class_weight...           0.971489   \n",
       "7   {'clf': SVC(C=10, cache_size=200, class_weight...           0.964097   \n",
       "8   {'clf': LogisticRegression(C=100, class_weight...           0.970433   \n",
       "9   {'clf': LogisticRegression(C=100, class_weight...           0.970433   \n",
       "10  {'clf': LogisticRegression(C=100, class_weight...           0.970433   \n",
       "11  {'clf': LogisticRegression(C=100, class_weight...           0.970433   \n",
       "12  {'clf': LogisticRegression(C=100, class_weight...           0.968321   \n",
       "13  {'clf': LogisticRegression(C=100, class_weight...           0.971489   \n",
       "14  {'clf': LogisticRegression(C=100, class_weight...           0.967265   \n",
       "15  {'clf': LogisticRegression(C=100, class_weight...           0.966209   \n",
       "16  {'clf': LogisticRegression(C=10, class_weight=...           0.972545   \n",
       "17  {'clf': LogisticRegression(C=10, class_weight=...           0.971489   \n",
       "18  {'clf': LogisticRegression(C=10, class_weight=...           0.971489   \n",
       "19  {'clf': LogisticRegression(C=10, class_weight=...           0.972545   \n",
       "20  {'clf': LogisticRegression(C=10, class_weight=...           0.965153   \n",
       "21  {'clf': LogisticRegression(C=10, class_weight=...           0.968321   \n",
       "22  {'clf': LogisticRegression(C=10, class_weight=...           0.961985   \n",
       "23  {'clf': LogisticRegression(C=10, class_weight=...           0.966209   \n",
       "24  {'clf': GaussianNB(priors=None, var_smoothing=...           0.884900   \n",
       "25  {'clf': GaussianNB(priors=None, var_smoothing=...           0.935586   \n",
       "26  {'clf': GaussianNB(priors=None, var_smoothing=...           0.920803   \n",
       "27  {'clf': GaussianNB(priors=None, var_smoothing=...           0.936642   \n",
       "28  {'clf': GaussianNB(priors=None, var_smoothing=...           0.949314   \n",
       "29  {'clf': GaussianNB(priors=None, var_smoothing=...           0.952482   \n",
       "30  {'clf': GaussianNB(priors=None, var_smoothing=...           0.951426   \n",
       "31  {'clf': GaussianNB(priors=None, var_smoothing=...           0.938754   \n",
       "\n",
       "    split1_test_score       ...         mean_test_score  std_test_score  \\\n",
       "0            0.974657       ...                0.974007        0.003681   \n",
       "1            0.974657       ...                0.973373        0.002244   \n",
       "2            0.972545       ...                0.972527        0.003463   \n",
       "3            0.973601       ...                0.973795        0.001384   \n",
       "4            0.959873       ...                0.961116        0.004496   \n",
       "5            0.956705       ...                0.961961        0.004722   \n",
       "6            0.959873       ...                0.961116        0.006919   \n",
       "7            0.960929       ...                0.963440        0.003733   \n",
       "8            0.973601       ...                0.974218        0.003369   \n",
       "9            0.971489       ...                0.974007        0.002940   \n",
       "10           0.972545       ...                0.972739        0.002932   \n",
       "11           0.973601       ...                0.974218        0.002362   \n",
       "12           0.960929       ...                0.965765        0.004639   \n",
       "13           0.964097       ...                0.966610        0.004139   \n",
       "14           0.970433       ...                0.966610        0.003102   \n",
       "15           0.964097       ...                0.965131        0.003385   \n",
       "16           0.971489       ...                0.974641        0.003192   \n",
       "17           0.970433       ...                0.974852        0.003220   \n",
       "18           0.973601       ...                0.973584        0.003592   \n",
       "19           0.973601       ...                0.975486        0.002241   \n",
       "20           0.965153       ...                0.967878        0.003227   \n",
       "21           0.969377       ...                0.970203        0.002599   \n",
       "22           0.968321       ...                0.965554        0.003919   \n",
       "23           0.968321       ...                0.967667        0.003226   \n",
       "24           0.930306       ...                0.912933        0.015050   \n",
       "25           0.918691       ...                0.907861        0.024198   \n",
       "26           0.923970       ...                0.913145        0.014795   \n",
       "27           0.889124       ...                0.901310        0.025152   \n",
       "28           0.948258       ...                0.943576        0.005214   \n",
       "29           0.950370       ...                0.947168        0.004722   \n",
       "30           0.944034       ...                0.939772        0.007733   \n",
       "31           0.961985       ...                0.944421        0.008819   \n",
       "\n",
       "    rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0                 6            0.977015            0.977543   \n",
       "1                10            0.977543            0.975694   \n",
       "2                12            0.977279            0.977279   \n",
       "3                 8            0.977279            0.975429   \n",
       "4                23            0.963540            0.959049   \n",
       "5                22            0.964333            0.954557   \n",
       "6                23            0.965125            0.957199   \n",
       "7                21            0.965918            0.965125   \n",
       "8                 4            0.978336            0.978864   \n",
       "9                 6            0.979657            0.976222   \n",
       "10               11            0.978071            0.977807   \n",
       "11                4            0.979128            0.973844   \n",
       "12               18            0.969353            0.965125   \n",
       "13               16            0.968560            0.961955   \n",
       "14               16            0.968032            0.963540   \n",
       "15               20            0.966975            0.969353   \n",
       "16                3            0.978071            0.978600   \n",
       "17                2            0.978600            0.975958   \n",
       "18                9            0.978864            0.978600   \n",
       "19                1            0.978864            0.974901   \n",
       "20               14            0.970410            0.968824   \n",
       "21               13            0.970145            0.968824   \n",
       "22               19            0.972259            0.968032   \n",
       "23               15            0.969089            0.969617   \n",
       "24               30            0.904888            0.928402   \n",
       "25               31            0.922853            0.920476   \n",
       "26               29            0.923910            0.919947   \n",
       "27               32            0.926024            0.898283   \n",
       "28               27            0.944782            0.946631   \n",
       "29               25            0.950330            0.941876   \n",
       "30               28            0.947952            0.940819   \n",
       "31               26            0.936063            0.945575   \n",
       "\n",
       "    split2_train_score  split3_train_score  split4_train_score  \\\n",
       "0             0.974637            0.977813            0.978875   \n",
       "1             0.975694            0.977021            0.978611   \n",
       "2             0.974901            0.976756            0.977819   \n",
       "3             0.974108            0.975964            0.977555   \n",
       "4             0.960634            0.955890            0.956166   \n",
       "5             0.960106            0.956947            0.959599   \n",
       "6             0.956407            0.956154            0.959863   \n",
       "7             0.962483            0.966719            0.964352   \n",
       "8             0.976486            0.979134            0.978875   \n",
       "9             0.976486            0.978870            0.979139   \n",
       "10            0.976486            0.978605            0.978347   \n",
       "11            0.975694            0.978870            0.977819   \n",
       "12            0.964861            0.963022            0.965672   \n",
       "13            0.964069            0.964342            0.964880   \n",
       "14            0.963012            0.964606            0.965936   \n",
       "15            0.968032            0.969889            0.969633   \n",
       "16            0.976486            0.980718            0.977819   \n",
       "17            0.977015            0.979662            0.979403   \n",
       "18            0.977279            0.979926            0.976234   \n",
       "19            0.976750            0.978605            0.978611   \n",
       "20            0.967768            0.966455            0.967520   \n",
       "21            0.971995            0.973059            0.969369   \n",
       "22            0.963804            0.969625            0.971217   \n",
       "23            0.972259            0.975172            0.969897   \n",
       "24            0.913342            0.912044            0.894904   \n",
       "25            0.885073            0.884046            0.925271   \n",
       "26            0.896697            0.886424            0.918669   \n",
       "27            0.882695            0.896989            0.923158   \n",
       "28            0.942404            0.946117            0.942435   \n",
       "29            0.940026            0.949815            0.944811   \n",
       "30            0.933421            0.942684            0.935833   \n",
       "31            0.945839            0.944532            0.943755   \n",
       "\n",
       "    mean_train_score  std_train_score  \n",
       "0           0.977176         0.001407  \n",
       "1           0.976912         0.001119  \n",
       "2           0.976807         0.001010  \n",
       "3           0.976067         0.001260  \n",
       "4           0.959056         0.002863  \n",
       "5           0.959108         0.003284  \n",
       "6           0.958950         0.003356  \n",
       "7           0.964920         0.001452  \n",
       "8           0.978339         0.000962  \n",
       "9           0.978075         0.001430  \n",
       "10          0.977863         0.000739  \n",
       "11          0.977071         0.002017  \n",
       "12          0.965607         0.002074  \n",
       "13          0.964761         0.002144  \n",
       "14          0.965025         0.001806  \n",
       "15          0.968776         0.001105  \n",
       "16          0.978339         0.001379  \n",
       "17          0.978127         0.001425  \n",
       "18          0.978181         0.001288  \n",
       "19          0.977546         0.001525  \n",
       "20          0.968195         0.001339  \n",
       "21          0.970678         0.001602  \n",
       "22          0.968987         0.002962  \n",
       "23          0.971207         0.002261  \n",
       "24          0.910716         0.011004  \n",
       "25          0.907544         0.018830  \n",
       "26          0.909130         0.014809  \n",
       "27          0.905430         0.016599  \n",
       "28          0.944474         0.001783  \n",
       "29          0.945372         0.004134  \n",
       "30          0.940142         0.005131  \n",
       "31          0.943153         0.003622  \n",
       "\n",
       "[32 rows x 23 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "result = pd.DataFrame(grid.cv_results_)\n",
    "pd.DataFrame(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1}\n"
     ]
    }
   ],
   "source": [
    "# remove headers and footers\n",
    "\n",
    "categories = ['comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware',\n",
    "              'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey']\n",
    "\n",
    "train_dataset_rm = fetch_20newsgroups(subset = 'train', categories = categories, shuffle=True,\n",
    "                                      random_state=None, remove=('headers', 'footers'))\n",
    "test_dataset_rm = fetch_20newsgroups(subset = 'test', categories = categories, shuffle=True,\n",
    "                                     random_state=None, remove=('headers', 'footers'))\n",
    "\n",
    "new_train_label_rm = re_label(train_dataset_rm)\n",
    "new_test_label_rm = re_label(test_dataset_rm)\n",
    "\n",
    "print(set(new_train_label_rm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=3,\n",
      "        ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
      "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None), \n",
      "[ 'Looking for a graphics/CAD/or-whatever package on a X-Unix box that will\\n'\n",
      "  'take a file with records like:\\n'\n",
      "  '\\n'\n",
      "  'n  a  b  p\\n'\n",
      "  '\\n'\n",
      "  'where n = a count  - integer \\n'\n",
      "  '      a = entity a - string\\n'\n",
      "  '      b = entity b - string\\n'\n",
      "  '      p = type     - string\\n'\n",
      "  '\\n'\n",
      "  'and produce a networked graph with nodes represented with boxes or circles\\n'\n",
      "  'and the vertices represented by lines and the width of the line determined '\n",
      "  'by\\n'\n",
      "  'n.  There would be a different line type for each type of vertice. The '\n",
      "  'boxes\\n'\n",
      "  \"need to be identified with the entity's name.  The number of entities < \"\n",
      "  '1000\\n'\n",
      "  'and vertices < 100000.  It would be nice if the tool minimi..., \n",
      "[ 0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "..., \n",
      "None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/pipeline.py:230: UserWarning: Persisting input arguments took 3.04s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________fit_transform_one - 2.2s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True), <3785x14282 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 240844 stored elements in Compressed Sparse Row format>, \n",
      "[ 0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "..., \n",
      "None)\n",
      "________________________________________________fit_transform_one - 0.1s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), \n",
      "<3785x14282 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 240844 stored elements in Compressed Sparse Row format>, \n",
      "[ 0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "..., \n",
      "None)\n",
      "________________________________________________fit_transform_one - 0.6s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=3,\n",
      "        ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
      "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None), \n",
      "[ 'On March 21, 1993 Roger Maynard wrote (in reply to an article by Graham\\n'\n",
      "  'Hudson):\\n'\n",
      "  '\\n'\n",
      "  '>> will still have the Jennings Trophy at the end of the year.  Potvin is '\n",
      "  'very\\n'\n",
      "  '>> good, and I do believe that he will be a star, but I want to see him\\n'\n",
      "  '>> perform in the playoffs under pressure.\\n'\n",
      "  '\\n'\n",
      "  '>You don\\'t think he is performing \"under pressure\" now?  The major\\n'\n",
      "  '>differences  between playoff hockey and normal hockey is 1. play-\\n'\n",
      "  '>ing every other night which is physically exhausting and 2.   You\\n'\n",
      "  '>play  the  same  team  in a consecutive string of games.  Is this\\n'\n",
      "  '>what you mean by pressure?  Have you even thought about what  you\\n'\n",
      "  '>mean  ..., \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "..., \n",
      "None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/pipeline.py:230: UserWarning: Persisting input arguments took 3.05s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________fit_transform_one - 2.4s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True), <3785x14827 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 242066 stored elements in Compressed Sparse Row format>, \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "..., \n",
      "None)\n",
      "________________________________________________fit_transform_one - 0.1s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), \n",
      "<3785x14827 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 242066 stored elements in Compressed Sparse Row format>, \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "..., \n",
      "None)\n",
      "________________________________________________fit_transform_one - 0.6s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=3,\n",
      "        ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
      "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None), \n",
      "[ 'On March 21, 1993 Roger Maynard wrote (in reply to an article by Graham\\n'\n",
      "  'Hudson):\\n'\n",
      "  '\\n'\n",
      "  '>> will still have the Jennings Trophy at the end of the year.  Potvin is '\n",
      "  'very\\n'\n",
      "  '>> good, and I do believe that he will be a star, but I want to see him\\n'\n",
      "  '>> perform in the playoffs under pressure.\\n'\n",
      "  '\\n'\n",
      "  '>You don\\'t think he is performing \"under pressure\" now?  The major\\n'\n",
      "  '>differences  between playoff hockey and normal hockey is 1. play-\\n'\n",
      "  '>ing every other night which is physically exhausting and 2.   You\\n'\n",
      "  '>play  the  same  team  in a consecutive string of games.  Is this\\n'\n",
      "  '>what you mean by pressure?  Have you even thought about what  you\\n'\n",
      "  '>mean  ..., \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "..., \n",
      "None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/pipeline.py:230: UserWarning: Persisting input arguments took 2.37s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________fit_transform_one - 2.5s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True), <3785x14775 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 241644 stored elements in Compressed Sparse Row format>, \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "..., \n",
      "None)\n",
      "________________________________________________fit_transform_one - 0.1s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), \n",
      "<3785x14775 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 241644 stored elements in Compressed Sparse Row format>, \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "..., \n",
      "None)\n",
      "________________________________________________fit_transform_one - 0.6s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=3,\n",
      "        ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
      "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None), \n",
      "[ 'On March 21, 1993 Roger Maynard wrote (in reply to an article by Graham\\n'\n",
      "  'Hudson):\\n'\n",
      "  '\\n'\n",
      "  '>> will still have the Jennings Trophy at the end of the year.  Potvin is '\n",
      "  'very\\n'\n",
      "  '>> good, and I do believe that he will be a star, but I want to see him\\n'\n",
      "  '>> perform in the playoffs under pressure.\\n'\n",
      "  '\\n'\n",
      "  '>You don\\'t think he is performing \"under pressure\" now?  The major\\n'\n",
      "  '>differences  between playoff hockey and normal hockey is 1. play-\\n'\n",
      "  '>ing every other night which is physically exhausting and 2.   You\\n'\n",
      "  '>play  the  same  team  in a consecutive string of games.  Is this\\n'\n",
      "  '>what you mean by pressure?  Have you even thought about what  you\\n'\n",
      "  '>mean  ..., \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "..., \n",
      "None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/pipeline.py:230: UserWarning: Persisting input arguments took 2.40s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________fit_transform_one - 2.2s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True), <3786x14741 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 239784 stored elements in Compressed Sparse Row format>, \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "..., \n",
      "None)\n",
      "________________________________________________fit_transform_one - 0.1s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), \n",
      "<3786x14741 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 239784 stored elements in Compressed Sparse Row format>, \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "..., \n",
      "None)\n",
      "________________________________________________fit_transform_one - 0.5s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=3,\n",
      "        ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
      "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None), \n",
      "[ 'On March 21, 1993 Roger Maynard wrote (in reply to an article by Graham\\n'\n",
      "  'Hudson):\\n'\n",
      "  '\\n'\n",
      "  '>> will still have the Jennings Trophy at the end of the year.  Potvin is '\n",
      "  'very\\n'\n",
      "  '>> good, and I do believe that he will be a star, but I want to see him\\n'\n",
      "  '>> perform in the playoffs under pressure.\\n'\n",
      "  '\\n'\n",
      "  '>You don\\'t think he is performing \"under pressure\" now?  The major\\n'\n",
      "  '>differences  between playoff hockey and normal hockey is 1. play-\\n'\n",
      "  '>ing every other night which is physically exhausting and 2.   You\\n'\n",
      "  '>play  the  same  team  in a consecutive string of games.  Is this\\n'\n",
      "  '>what you mean by pressure?  Have you even thought about what  you\\n'\n",
      "  '>mean  ..., \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "..., \n",
      "None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/pipeline.py:230: UserWarning: Persisting input arguments took 2.24s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________fit_transform_one - 2.4s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True), <3787x14503 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 239488 stored elements in Compressed Sparse Row format>, \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "..., \n",
      "None)\n",
      "________________________________________________fit_transform_one - 0.1s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), \n",
      "<3787x14503 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 239488 stored elements in Compressed Sparse Row format>, \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "..., \n",
      "None)\n",
      "________________________________________________fit_transform_one - 0.5s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(CountVectorizer(analyzer=<function stem_rmv_nums at 0x12655c7b8>,\n",
      "        binary=False, decode_error='strict', dtype=<class 'numpy.int64'>,\n",
      "        encoding='utf-8', input='content', lowercase=True, max_df=1.0,\n",
      "        max_features=None, min_df=3, ngram_range=(1, 1), preprocessor=None,\n",
      "        stop_words=None, strip_accents=None,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, vocabulary=None), \n",
      "[ 'Looking for a graphics/CAD/or-whatever package on a X-Unix box that will\\n'\n",
      "  'take a file with records like:\\n'\n",
      "  '\\n'\n",
      "  'n  a  b  p\\n'\n",
      "  '\\n'\n",
      "  'where n = a count  - integer \\n'\n",
      "  '      a = entity a - string\\n'\n",
      "  '      b = entity b - string\\n'\n",
      "  '      p = type     - string\\n'\n",
      "  '\\n'\n",
      "  'and produce a networked graph with nodes represented with boxes or circles\\n'\n",
      "  'and the vertices represented by lines and the width of the line determined '\n",
      "  'by\\n'\n",
      "  'n.  There would be a different line type for each type of vertice. The '\n",
      "  'boxes\\n'\n",
      "  \"need to be identified with the entity's name.  The number of entities < \"\n",
      "  '1000\\n'\n",
      "  'and vertices < 100000.  It would be nice if the tool minimi..., \n",
      "[ 0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "..., \n",
      "None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/pipeline.py:230: UserWarning: Persisting input arguments took 1.65s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______________________________________________fit_transform_one - 47.3s, 0.8min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True), <3785x11239 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 213840 stored elements in Compressed Sparse Row format>, \n",
      "[ 0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "..., \n",
      "None)\n",
      "________________________________________________fit_transform_one - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), \n",
      "<3785x11239 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 213840 stored elements in Compressed Sparse Row format>, \n",
      "[ 0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "..., \n",
      "None)\n",
      "________________________________________________fit_transform_one - 0.4s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(CountVectorizer(analyzer=<function stem_rmv_nums at 0x12655c7b8>,\n",
      "        binary=False, decode_error='strict', dtype=<class 'numpy.int64'>,\n",
      "        encoding='utf-8', input='content', lowercase=True, max_df=1.0,\n",
      "        max_features=None, min_df=3, ngram_range=(1, 1), preprocessor=None,\n",
      "        stop_words=None, strip_accents=None,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, vocabulary=None), \n",
      "[ 'On March 21, 1993 Roger Maynard wrote (in reply to an article by Graham\\n'\n",
      "  'Hudson):\\n'\n",
      "  '\\n'\n",
      "  '>> will still have the Jennings Trophy at the end of the year.  Potvin is '\n",
      "  'very\\n'\n",
      "  '>> good, and I do believe that he will be a star, but I want to see him\\n'\n",
      "  '>> perform in the playoffs under pressure.\\n'\n",
      "  '\\n'\n",
      "  '>You don\\'t think he is performing \"under pressure\" now?  The major\\n'\n",
      "  '>differences  between playoff hockey and normal hockey is 1. play-\\n'\n",
      "  '>ing every other night which is physically exhausting and 2.   You\\n'\n",
      "  '>play  the  same  team  in a consecutive string of games.  Is this\\n'\n",
      "  '>what you mean by pressure?  Have you even thought about what  you\\n'\n",
      "  '>mean  ..., \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "..., \n",
      "None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/pipeline.py:230: UserWarning: Persisting input arguments took 2.27s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______________________________________________fit_transform_one - 49.7s, 0.8min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True), <3785x11867 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 215931 stored elements in Compressed Sparse Row format>, \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "..., \n",
      "None)\n",
      "________________________________________________fit_transform_one - 0.1s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), \n",
      "<3785x11867 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 215931 stored elements in Compressed Sparse Row format>, \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "..., \n",
      "None)\n",
      "________________________________________________fit_transform_one - 0.6s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(CountVectorizer(analyzer=<function stem_rmv_nums at 0x12655c7b8>,\n",
      "        binary=False, decode_error='strict', dtype=<class 'numpy.int64'>,\n",
      "        encoding='utf-8', input='content', lowercase=True, max_df=1.0,\n",
      "        max_features=None, min_df=3, ngram_range=(1, 1), preprocessor=None,\n",
      "        stop_words=None, strip_accents=None,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, vocabulary=None), \n",
      "[ 'On March 21, 1993 Roger Maynard wrote (in reply to an article by Graham\\n'\n",
      "  'Hudson):\\n'\n",
      "  '\\n'\n",
      "  '>> will still have the Jennings Trophy at the end of the year.  Potvin is '\n",
      "  'very\\n'\n",
      "  '>> good, and I do believe that he will be a star, but I want to see him\\n'\n",
      "  '>> perform in the playoffs under pressure.\\n'\n",
      "  '\\n'\n",
      "  '>You don\\'t think he is performing \"under pressure\" now?  The major\\n'\n",
      "  '>differences  between playoff hockey and normal hockey is 1. play-\\n'\n",
      "  '>ing every other night which is physically exhausting and 2.   You\\n'\n",
      "  '>play  the  same  team  in a consecutive string of games.  Is this\\n'\n",
      "  '>what you mean by pressure?  Have you even thought about what  you\\n'\n",
      "  '>mean  ..., \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "..., \n",
      "None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/pipeline.py:230: UserWarning: Persisting input arguments took 2.51s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______________________________________________fit_transform_one - 57.2s, 1.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True), <3785x11796 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 215343 stored elements in Compressed Sparse Row format>, \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "..., \n",
      "None)\n",
      "________________________________________________fit_transform_one - 0.1s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), \n",
      "<3785x11796 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 215343 stored elements in Compressed Sparse Row format>, \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "..., \n",
      "None)\n",
      "________________________________________________fit_transform_one - 0.7s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(CountVectorizer(analyzer=<function stem_rmv_nums at 0x12655c7b8>,\n",
      "        binary=False, decode_error='strict', dtype=<class 'numpy.int64'>,\n",
      "        encoding='utf-8', input='content', lowercase=True, max_df=1.0,\n",
      "        max_features=None, min_df=3, ngram_range=(1, 1), preprocessor=None,\n",
      "        stop_words=None, strip_accents=None,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, vocabulary=None), \n",
      "[ 'On March 21, 1993 Roger Maynard wrote (in reply to an article by Graham\\n'\n",
      "  'Hudson):\\n'\n",
      "  '\\n'\n",
      "  '>> will still have the Jennings Trophy at the end of the year.  Potvin is '\n",
      "  'very\\n'\n",
      "  '>> good, and I do believe that he will be a star, but I want to see him\\n'\n",
      "  '>> perform in the playoffs under pressure.\\n'\n",
      "  '\\n'\n",
      "  '>You don\\'t think he is performing \"under pressure\" now?  The major\\n'\n",
      "  '>differences  between playoff hockey and normal hockey is 1. play-\\n'\n",
      "  '>ing every other night which is physically exhausting and 2.   You\\n'\n",
      "  '>play  the  same  team  in a consecutive string of games.  Is this\\n'\n",
      "  '>what you mean by pressure?  Have you even thought about what  you\\n'\n",
      "  '>mean  ..., \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "..., \n",
      "None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/pipeline.py:230: UserWarning: Persisting input arguments took 2.10s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______________________________________________fit_transform_one - 55.8s, 0.9min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True), <3786x11809 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 214161 stored elements in Compressed Sparse Row format>, \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "..., \n",
      "None)\n",
      "________________________________________________fit_transform_one - 0.1s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), \n",
      "<3786x11809 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 214161 stored elements in Compressed Sparse Row format>, \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "..., \n",
      "None)\n",
      "________________________________________________fit_transform_one - 0.6s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(CountVectorizer(analyzer=<function stem_rmv_nums at 0x12655c7b8>,\n",
      "        binary=False, decode_error='strict', dtype=<class 'numpy.int64'>,\n",
      "        encoding='utf-8', input='content', lowercase=True, max_df=1.0,\n",
      "        max_features=None, min_df=3, ngram_range=(1, 1), preprocessor=None,\n",
      "        stop_words=None, strip_accents=None,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, vocabulary=None), \n",
      "[ 'On March 21, 1993 Roger Maynard wrote (in reply to an article by Graham\\n'\n",
      "  'Hudson):\\n'\n",
      "  '\\n'\n",
      "  '>> will still have the Jennings Trophy at the end of the year.  Potvin is '\n",
      "  'very\\n'\n",
      "  '>> good, and I do believe that he will be a star, but I want to see him\\n'\n",
      "  '>> perform in the playoffs under pressure.\\n'\n",
      "  '\\n'\n",
      "  '>You don\\'t think he is performing \"under pressure\" now?  The major\\n'\n",
      "  '>differences  between playoff hockey and normal hockey is 1. play-\\n'\n",
      "  '>ing every other night which is physically exhausting and 2.   You\\n'\n",
      "  '>play  the  same  team  in a consecutive string of games.  Is this\\n'\n",
      "  '>what you mean by pressure?  Have you even thought about what  you\\n'\n",
      "  '>mean  ..., \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "..., \n",
      "None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/pipeline.py:230: UserWarning: Persisting input arguments took 2.28s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______________________________________________fit_transform_one - 58.4s, 1.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True), <3787x11509 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 213225 stored elements in Compressed Sparse Row format>, \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "..., \n",
      "None)\n",
      "________________________________________________fit_transform_one - 0.1s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), \n",
      "<3787x11509 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 213225 stored elements in Compressed Sparse Row format>, \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "..., \n",
      "None)\n",
      "________________________________________________fit_transform_one - 0.6s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=5,\n",
      "        ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
      "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None), \n",
      "[ 'Looking for a graphics/CAD/or-whatever package on a X-Unix box that will\\n'\n",
      "  'take a file with records like:\\n'\n",
      "  '\\n'\n",
      "  'n  a  b  p\\n'\n",
      "  '\\n'\n",
      "  'where n = a count  - integer \\n'\n",
      "  '      a = entity a - string\\n'\n",
      "  '      b = entity b - string\\n'\n",
      "  '      p = type     - string\\n'\n",
      "  '\\n'\n",
      "  'and produce a networked graph with nodes represented with boxes or circles\\n'\n",
      "  'and the vertices represented by lines and the width of the line determined '\n",
      "  'by\\n'\n",
      "  'n.  There would be a different line type for each type of vertice. The '\n",
      "  'boxes\\n'\n",
      "  \"need to be identified with the entity's name.  The number of entities < \"\n",
      "  '1000\\n'\n",
      "  'and vertices < 100000.  It would be nice if the tool minimi..., \n",
      "[ 0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "..., \n",
      "None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/pipeline.py:230: UserWarning: Persisting input arguments took 1.71s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________fit_transform_one - 2.2s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True), <3785x9055 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 223196 stored elements in Compressed Sparse Row format>, \n",
      "[ 0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "..., \n",
      "None)\n",
      "________________________________________________fit_transform_one - 0.1s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), \n",
      "<3785x9055 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 223196 stored elements in Compressed Sparse Row format>, \n",
      "[ 0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "..., \n",
      "None)\n",
      "________________________________________________fit_transform_one - 0.5s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=5,\n",
      "        ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
      "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None), \n",
      "[ 'On March 21, 1993 Roger Maynard wrote (in reply to an article by Graham\\n'\n",
      "  'Hudson):\\n'\n",
      "  '\\n'\n",
      "  '>> will still have the Jennings Trophy at the end of the year.  Potvin is '\n",
      "  'very\\n'\n",
      "  '>> good, and I do believe that he will be a star, but I want to see him\\n'\n",
      "  '>> perform in the playoffs under pressure.\\n'\n",
      "  '\\n'\n",
      "  '>You don\\'t think he is performing \"under pressure\" now?  The major\\n'\n",
      "  '>differences  between playoff hockey and normal hockey is 1. play-\\n'\n",
      "  '>ing every other night which is physically exhausting and 2.   You\\n'\n",
      "  '>play  the  same  team  in a consecutive string of games.  Is this\\n'\n",
      "  '>what you mean by pressure?  Have you even thought about what  you\\n'\n",
      "  '>mean  ..., \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "..., \n",
      "None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/pipeline.py:230: UserWarning: Persisting input arguments took 1.82s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________fit_transform_one - 2.4s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True), <3785x9191 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 223072 stored elements in Compressed Sparse Row format>, \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "..., \n",
      "None)\n",
      "________________________________________________fit_transform_one - 0.1s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), \n",
      "<3785x9191 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 223072 stored elements in Compressed Sparse Row format>, \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "..., \n",
      "None)\n",
      "________________________________________________fit_transform_one - 0.5s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=5,\n",
      "        ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
      "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None), \n",
      "[ 'On March 21, 1993 Roger Maynard wrote (in reply to an article by Graham\\n'\n",
      "  'Hudson):\\n'\n",
      "  '\\n'\n",
      "  '>> will still have the Jennings Trophy at the end of the year.  Potvin is '\n",
      "  'very\\n'\n",
      "  '>> good, and I do believe that he will be a star, but I want to see him\\n'\n",
      "  '>> perform in the playoffs under pressure.\\n'\n",
      "  '\\n'\n",
      "  '>You don\\'t think he is performing \"under pressure\" now?  The major\\n'\n",
      "  '>differences  between playoff hockey and normal hockey is 1. play-\\n'\n",
      "  '>ing every other night which is physically exhausting and 2.   You\\n'\n",
      "  '>play  the  same  team  in a consecutive string of games.  Is this\\n'\n",
      "  '>what you mean by pressure?  Have you even thought about what  you\\n'\n",
      "  '>mean  ..., \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "..., \n",
      "None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/pipeline.py:230: UserWarning: Persisting input arguments took 1.80s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________fit_transform_one - 2.3s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True), <3785x9030 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 222248 stored elements in Compressed Sparse Row format>, \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "..., \n",
      "None)\n",
      "________________________________________________fit_transform_one - 0.1s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), \n",
      "<3785x9030 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 222248 stored elements in Compressed Sparse Row format>, \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "..., \n",
      "None)\n",
      "________________________________________________fit_transform_one - 0.5s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=5,\n",
      "        ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
      "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None), \n",
      "[ 'On March 21, 1993 Roger Maynard wrote (in reply to an article by Graham\\n'\n",
      "  'Hudson):\\n'\n",
      "  '\\n'\n",
      "  '>> will still have the Jennings Trophy at the end of the year.  Potvin is '\n",
      "  'very\\n'\n",
      "  '>> good, and I do believe that he will be a star, but I want to see him\\n'\n",
      "  '>> perform in the playoffs under pressure.\\n'\n",
      "  '\\n'\n",
      "  '>You don\\'t think he is performing \"under pressure\" now?  The major\\n'\n",
      "  '>differences  between playoff hockey and normal hockey is 1. play-\\n'\n",
      "  '>ing every other night which is physically exhausting and 2.   You\\n'\n",
      "  '>play  the  same  team  in a consecutive string of games.  Is this\\n'\n",
      "  '>what you mean by pressure?  Have you even thought about what  you\\n'\n",
      "  '>mean  ..., \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "..., \n",
      "None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/pipeline.py:230: UserWarning: Persisting input arguments took 1.63s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________fit_transform_one - 2.3s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True), <3786x9120 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 220905 stored elements in Compressed Sparse Row format>, \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "..., \n",
      "None)\n",
      "________________________________________________fit_transform_one - 0.1s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), \n",
      "<3786x9120 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 220905 stored elements in Compressed Sparse Row format>, \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "..., \n",
      "None)\n",
      "________________________________________________fit_transform_one - 0.6s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=5,\n",
      "        ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
      "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None), \n",
      "[ 'On March 21, 1993 Roger Maynard wrote (in reply to an article by Graham\\n'\n",
      "  'Hudson):\\n'\n",
      "  '\\n'\n",
      "  '>> will still have the Jennings Trophy at the end of the year.  Potvin is '\n",
      "  'very\\n'\n",
      "  '>> good, and I do believe that he will be a star, but I want to see him\\n'\n",
      "  '>> perform in the playoffs under pressure.\\n'\n",
      "  '\\n'\n",
      "  '>You don\\'t think he is performing \"under pressure\" now?  The major\\n'\n",
      "  '>differences  between playoff hockey and normal hockey is 1. play-\\n'\n",
      "  '>ing every other night which is physically exhausting and 2.   You\\n'\n",
      "  '>play  the  same  team  in a consecutive string of games.  Is this\\n'\n",
      "  '>what you mean by pressure?  Have you even thought about what  you\\n'\n",
      "  '>mean  ..., \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "..., \n",
      "None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/pipeline.py:230: UserWarning: Persisting input arguments took 1.43s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________fit_transform_one - 1.9s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True), <3787x9142 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 221422 stored elements in Compressed Sparse Row format>, \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "..., \n",
      "None)\n",
      "________________________________________________fit_transform_one - 0.1s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), \n",
      "<3787x9142 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 221422 stored elements in Compressed Sparse Row format>, \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "..., \n",
      "None)\n",
      "________________________________________________fit_transform_one - 0.3s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(CountVectorizer(analyzer=<function stem_rmv_nums at 0x12655c7b8>,\n",
      "        binary=False, decode_error='strict', dtype=<class 'numpy.int64'>,\n",
      "        encoding='utf-8', input='content', lowercase=True, max_df=1.0,\n",
      "        max_features=None, min_df=5, ngram_range=(1, 1), preprocessor=None,\n",
      "        stop_words=None, strip_accents=None,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, vocabulary=None), \n",
      "[ 'Looking for a graphics/CAD/or-whatever package on a X-Unix box that will\\n'\n",
      "  'take a file with records like:\\n'\n",
      "  '\\n'\n",
      "  'n  a  b  p\\n'\n",
      "  '\\n'\n",
      "  'where n = a count  - integer \\n'\n",
      "  '      a = entity a - string\\n'\n",
      "  '      b = entity b - string\\n'\n",
      "  '      p = type     - string\\n'\n",
      "  '\\n'\n",
      "  'and produce a networked graph with nodes represented with boxes or circles\\n'\n",
      "  'and the vertices represented by lines and the width of the line determined '\n",
      "  'by\\n'\n",
      "  'n.  There would be a different line type for each type of vertice. The '\n",
      "  'boxes\\n'\n",
      "  \"need to be identified with the entity's name.  The number of entities < \"\n",
      "  '1000\\n'\n",
      "  'and vertices < 100000.  It would be nice if the tool minimi..., \n",
      "[ 0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "..., \n",
      "None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/pipeline.py:230: UserWarning: Persisting input arguments took 1.17s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______________________________________________fit_transform_one - 45.6s, 0.8min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True), <3785x7213 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 200236 stored elements in Compressed Sparse Row format>, \n",
      "[ 0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "..., \n",
      "None)\n",
      "________________________________________________fit_transform_one - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), \n",
      "<3785x7213 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 200236 stored elements in Compressed Sparse Row format>, \n",
      "[ 0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "..., \n",
      "None)\n",
      "________________________________________________fit_transform_one - 0.3s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(CountVectorizer(analyzer=<function stem_rmv_nums at 0x12655c7b8>,\n",
      "        binary=False, decode_error='strict', dtype=<class 'numpy.int64'>,\n",
      "        encoding='utf-8', input='content', lowercase=True, max_df=1.0,\n",
      "        max_features=None, min_df=5, ngram_range=(1, 1), preprocessor=None,\n",
      "        stop_words=None, strip_accents=None,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, vocabulary=None), \n",
      "[ 'On March 21, 1993 Roger Maynard wrote (in reply to an article by Graham\\n'\n",
      "  'Hudson):\\n'\n",
      "  '\\n'\n",
      "  '>> will still have the Jennings Trophy at the end of the year.  Potvin is '\n",
      "  'very\\n'\n",
      "  '>> good, and I do believe that he will be a star, but I want to see him\\n'\n",
      "  '>> perform in the playoffs under pressure.\\n'\n",
      "  '\\n'\n",
      "  '>You don\\'t think he is performing \"under pressure\" now?  The major\\n'\n",
      "  '>differences  between playoff hockey and normal hockey is 1. play-\\n'\n",
      "  '>ing every other night which is physically exhausting and 2.   You\\n'\n",
      "  '>play  the  same  team  in a consecutive string of games.  Is this\\n'\n",
      "  '>what you mean by pressure?  Have you even thought about what  you\\n'\n",
      "  '>mean  ..., \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "..., \n",
      "None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/pipeline.py:230: UserWarning: Persisting input arguments took 1.23s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______________________________________________fit_transform_one - 47.5s, 0.8min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True), <3785x7347 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 200669 stored elements in Compressed Sparse Row format>, \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "..., \n",
      "None)\n",
      "________________________________________________fit_transform_one - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), \n",
      "<3785x7347 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 200669 stored elements in Compressed Sparse Row format>, \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "..., \n",
      "None)\n",
      "________________________________________________fit_transform_one - 0.3s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(CountVectorizer(analyzer=<function stem_rmv_nums at 0x12655c7b8>,\n",
      "        binary=False, decode_error='strict', dtype=<class 'numpy.int64'>,\n",
      "        encoding='utf-8', input='content', lowercase=True, max_df=1.0,\n",
      "        max_features=None, min_df=5, ngram_range=(1, 1), preprocessor=None,\n",
      "        stop_words=None, strip_accents=None,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, vocabulary=None), \n",
      "[ 'On March 21, 1993 Roger Maynard wrote (in reply to an article by Graham\\n'\n",
      "  'Hudson):\\n'\n",
      "  '\\n'\n",
      "  '>> will still have the Jennings Trophy at the end of the year.  Potvin is '\n",
      "  'very\\n'\n",
      "  '>> good, and I do believe that he will be a star, but I want to see him\\n'\n",
      "  '>> perform in the playoffs under pressure.\\n'\n",
      "  '\\n'\n",
      "  '>You don\\'t think he is performing \"under pressure\" now?  The major\\n'\n",
      "  '>differences  between playoff hockey and normal hockey is 1. play-\\n'\n",
      "  '>ing every other night which is physically exhausting and 2.   You\\n'\n",
      "  '>play  the  same  team  in a consecutive string of games.  Is this\\n'\n",
      "  '>what you mean by pressure?  Have you even thought about what  you\\n'\n",
      "  '>mean  ..., \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "..., \n",
      "None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/pipeline.py:230: UserWarning: Persisting input arguments took 1.08s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______________________________________________fit_transform_one - 46.4s, 0.8min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True), <3785x7156 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 199689 stored elements in Compressed Sparse Row format>, \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "..., \n",
      "None)\n",
      "________________________________________________fit_transform_one - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), \n",
      "<3785x7156 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 199689 stored elements in Compressed Sparse Row format>, \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "..., \n",
      "None)\n",
      "________________________________________________fit_transform_one - 0.3s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(CountVectorizer(analyzer=<function stem_rmv_nums at 0x12655c7b8>,\n",
      "        binary=False, decode_error='strict', dtype=<class 'numpy.int64'>,\n",
      "        encoding='utf-8', input='content', lowercase=True, max_df=1.0,\n",
      "        max_features=None, min_df=5, ngram_range=(1, 1), preprocessor=None,\n",
      "        stop_words=None, strip_accents=None,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, vocabulary=None), \n",
      "[ 'On March 21, 1993 Roger Maynard wrote (in reply to an article by Graham\\n'\n",
      "  'Hudson):\\n'\n",
      "  '\\n'\n",
      "  '>> will still have the Jennings Trophy at the end of the year.  Potvin is '\n",
      "  'very\\n'\n",
      "  '>> good, and I do believe that he will be a star, but I want to see him\\n'\n",
      "  '>> perform in the playoffs under pressure.\\n'\n",
      "  '\\n'\n",
      "  '>You don\\'t think he is performing \"under pressure\" now?  The major\\n'\n",
      "  '>differences  between playoff hockey and normal hockey is 1. play-\\n'\n",
      "  '>ing every other night which is physically exhausting and 2.   You\\n'\n",
      "  '>play  the  same  team  in a consecutive string of games.  Is this\\n'\n",
      "  '>what you mean by pressure?  Have you even thought about what  you\\n'\n",
      "  '>mean  ..., \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "..., \n",
      "None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/pipeline.py:230: UserWarning: Persisting input arguments took 1.22s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______________________________________________fit_transform_one - 45.3s, 0.8min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True), <3786x7253 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 198870 stored elements in Compressed Sparse Row format>, \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "..., \n",
      "None)\n",
      "________________________________________________fit_transform_one - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), \n",
      "<3786x7253 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 198870 stored elements in Compressed Sparse Row format>, \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "..., \n",
      "None)\n",
      "________________________________________________fit_transform_one - 0.3s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(CountVectorizer(analyzer=<function stem_rmv_nums at 0x12655c7b8>,\n",
      "        binary=False, decode_error='strict', dtype=<class 'numpy.int64'>,\n",
      "        encoding='utf-8', input='content', lowercase=True, max_df=1.0,\n",
      "        max_features=None, min_df=5, ngram_range=(1, 1), preprocessor=None,\n",
      "        stop_words=None, strip_accents=None,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, vocabulary=None), \n",
      "[ 'On March 21, 1993 Roger Maynard wrote (in reply to an article by Graham\\n'\n",
      "  'Hudson):\\n'\n",
      "  '\\n'\n",
      "  '>> will still have the Jennings Trophy at the end of the year.  Potvin is '\n",
      "  'very\\n'\n",
      "  '>> good, and I do believe that he will be a star, but I want to see him\\n'\n",
      "  '>> perform in the playoffs under pressure.\\n'\n",
      "  '\\n'\n",
      "  '>You don\\'t think he is performing \"under pressure\" now?  The major\\n'\n",
      "  '>differences  between playoff hockey and normal hockey is 1. play-\\n'\n",
      "  '>ing every other night which is physically exhausting and 2.   You\\n'\n",
      "  '>play  the  same  team  in a consecutive string of games.  Is this\\n'\n",
      "  '>what you mean by pressure?  Have you even thought about what  you\\n'\n",
      "  '>mean  ..., \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "..., \n",
      "None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/pipeline.py:230: UserWarning: Persisting input arguments took 1.10s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______________________________________________fit_transform_one - 46.4s, 0.8min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True), <3787x7317 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 199099 stored elements in Compressed Sparse Row format>, \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "..., \n",
      "None)\n",
      "________________________________________________fit_transform_one - 0.1s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), \n",
      "<3787x7317 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 199099 stored elements in Compressed Sparse Row format>, \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "..., \n",
      "None)\n",
      "________________________________________________fit_transform_one - 0.3s, 0.0min\n",
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/8d8060dd6f811f8ba6cf774ea8e176bf\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/7052942d1955cddd5ee8bd2c39f84a8a\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), \n",
      "<3785x14282 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 240844 stored elements in Compressed Sparse Row format>, \n",
      "[ 0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "..., \n",
      "None)\n",
      "_______________________________________________fit_transform_one - 14.3s, 0.2min\n",
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/be9ae3f663761ee926c31e900ef44af5\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/73ccbb1359a96a80c3d1554d4a84f0cd\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), \n",
      "<3785x14827 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 242066 stored elements in Compressed Sparse Row format>, \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "..., \n",
      "None)\n",
      "_______________________________________________fit_transform_one - 18.2s, 0.3min\n",
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/aaf3f039e240c396fdee2807d32f381c\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/fdfeb5926174b199a55db1d92d384597\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), \n",
      "<3785x14775 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 241644 stored elements in Compressed Sparse Row format>, \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "..., \n",
      "None)\n",
      "_______________________________________________fit_transform_one - 18.2s, 0.3min\n",
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/8894911a5385fd50efce71f25c62071d\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/82592fe93af6420e91156db4fd3f79dd\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), \n",
      "<3786x14741 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 239784 stored elements in Compressed Sparse Row format>, \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "..., \n",
      "None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______________________________________________fit_transform_one - 17.0s, 0.3min\n",
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/4e8b114690be07928ae14e4232f6f2c3\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/ec5d4d13ff384948cc5d576d0c996cbb\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), \n",
      "<3787x14503 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 239488 stored elements in Compressed Sparse Row format>, \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "..., \n",
      "None)\n",
      "_______________________________________________fit_transform_one - 17.5s, 0.3min\n",
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/6956b21c7478809b033a9420c313685b\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/5e673ee7a6d9a7a40733f4da56a18c48\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), \n",
      "<3785x11239 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 213840 stored elements in Compressed Sparse Row format>, \n",
      "[ 0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "..., \n",
      "None)\n",
      "_______________________________________________fit_transform_one - 12.5s, 0.2min\n",
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/2636770a39f355d3274de41a0d4aaec2\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/8ffb6c6288db48ded0d14e64302bc5d9\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), \n",
      "<3785x11867 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 215931 stored elements in Compressed Sparse Row format>, \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "..., \n",
      "None)\n",
      "_______________________________________________fit_transform_one - 14.7s, 0.2min\n",
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/bea2911728a284dce55a5a8caeda0d13\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/27f8f3014dd7afb4df64bedf65128939\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), \n",
      "<3785x11796 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 215343 stored elements in Compressed Sparse Row format>, \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "..., \n",
      "None)\n",
      "_______________________________________________fit_transform_one - 10.3s, 0.2min\n",
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/f6fcd5d1afadec57bc40543b1b9da88a\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/a721b410c18c6d69e473a52b0a3b02d9\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), \n",
      "<3786x11809 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 214161 stored elements in Compressed Sparse Row format>, \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "..., \n",
      "None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______________________________________________fit_transform_one - 14.9s, 0.2min\n",
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/18a2c857789f32059271c992b754c282\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/e31822872da1bc218d646f3a1af448eb\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), \n",
      "<3787x11509 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 213225 stored elements in Compressed Sparse Row format>, \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "..., \n",
      "None)\n",
      "_______________________________________________fit_transform_one - 14.5s, 0.2min\n",
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/c6cf143c4f10e4d8e9ab68dc64037726\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/b5a56ab97a47695014c74ee26969a89f\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), \n",
      "<3785x9055 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 223196 stored elements in Compressed Sparse Row format>, \n",
      "[ 0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "..., \n",
      "None)\n",
      "_______________________________________________fit_transform_one - 12.1s, 0.2min\n",
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/a9b9463b2c6a42dae7cfecbc31c93cb7\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/a87d68f929abab9367d6b79e63731d6b\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), \n",
      "<3785x9191 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 223072 stored elements in Compressed Sparse Row format>, \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "..., \n",
      "None)\n",
      "_______________________________________________fit_transform_one - 12.5s, 0.2min\n",
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/81b2f78bb2c741355302cac968def7ad\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/8fcfe8f9ab759ce04b0217f7bb86f20a\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), \n",
      "<3785x9030 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 222248 stored elements in Compressed Sparse Row format>, \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "..., \n",
      "None)\n",
      "_______________________________________________fit_transform_one - 12.5s, 0.2min\n",
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/8ce9ad20a94b7d1f93d4a4ba17206e4f\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/4bd60c7a997bc2520c6d16f0ce12918d\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), \n",
      "<3786x9120 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 220905 stored elements in Compressed Sparse Row format>, \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "..., \n",
      "None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________fit_transform_one - 9.6s, 0.2min\n",
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/d605e82eedf4ff0ac6d3d7ed21cc3b99\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/cda7790a4e9dc590a58bbfa0e22afbd5\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), \n",
      "<3787x9142 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 221422 stored elements in Compressed Sparse Row format>, \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "..., \n",
      "None)\n",
      "________________________________________________fit_transform_one - 7.4s, 0.1min\n",
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/1d0fed29315c76fcf88061c22106e0a4\n",
      "___________________________________fit_transform_one cache loaded - 0.2s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/53b2a58a0734ce31c3536789ba5e36df\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), \n",
      "<3785x7213 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 200236 stored elements in Compressed Sparse Row format>, \n",
      "[ 0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "..., \n",
      "None)\n",
      "________________________________________________fit_transform_one - 7.5s, 0.1min\n",
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/5043c232fd934c3db8ef3ab012fcc4f9\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/dd19c7c540b821fda080f871de2d2362\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), \n",
      "<3785x7347 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 200669 stored elements in Compressed Sparse Row format>, \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "..., \n",
      "None)\n",
      "________________________________________________fit_transform_one - 9.3s, 0.2min\n",
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/78a4c052091a2ef0a480d1d833719ff5\n",
      "___________________________________fit_transform_one cache loaded - 0.2s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/a157ac4229102a455796446e7d94048c\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), \n",
      "<3785x7156 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 199689 stored elements in Compressed Sparse Row format>, \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "..., \n",
      "None)\n",
      "_______________________________________________fit_transform_one - 10.3s, 0.2min\n",
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/87ebb97aaa690306bf903dd317443e33\n",
      "___________________________________fit_transform_one cache loaded - 0.2s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/a179104ae63c16bdac56452e351ee086\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), \n",
      "<3786x7253 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 198870 stored elements in Compressed Sparse Row format>, \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "..., \n",
      "None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______________________________________________fit_transform_one - 10.1s, 0.2min\n",
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/0a77aa38d7d5b014ccc86be5e5055bc9\n",
      "___________________________________fit_transform_one cache loaded - 0.2s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/03d64e6e15a6862c598e51ff254c426b\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(NMF(alpha=0.0, beta_loss='frobenius', init='random', l1_ratio=0.0,\n",
      "  max_iter=200, n_components=50, random_state=42, shuffle=False,\n",
      "  solver='cd', tol=0.0001, verbose=0), \n",
      "<3787x7317 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 199099 stored elements in Compressed Sparse Row format>, \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "..., \n",
      "None)\n",
      "________________________________________________fit_transform_one - 5.9s, 0.1min\n",
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/8d8060dd6f811f8ba6cf774ea8e176bf\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/7052942d1955cddd5ee8bd2c39f84a8a\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/e078fa2e3f3e81aca65de5426ba0d0c4\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.1s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/be9ae3f663761ee926c31e900ef44af5\n",
      "___________________________________fit_transform_one cache loaded - 0.4s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/73ccbb1359a96a80c3d1554d4a84f0cd\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.5s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/5b0e82172ca073e67cef13571e90b25d\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/aaf3f039e240c396fdee2807d32f381c\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/fdfeb5926174b199a55db1d92d384597\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/9f20fec75b3fa19f7dacbd46c9d114d5\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/8894911a5385fd50efce71f25c62071d\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/82592fe93af6420e91156db4fd3f79dd\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/0fbc95317c18d82dc79a40d6bd7fa83a\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/4e8b114690be07928ae14e4232f6f2c3\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/ec5d4d13ff384948cc5d576d0c996cbb\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/49d843b5193b3d334b931779794ca2b7\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/6956b21c7478809b033a9420c313685b\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/5e673ee7a6d9a7a40733f4da56a18c48\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/a3700d90ebf24b53c0554ebbac454cfc\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/2636770a39f355d3274de41a0d4aaec2\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/8ffb6c6288db48ded0d14e64302bc5d9\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/85e0297911eb4ff4426655821ca8e36e\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/bea2911728a284dce55a5a8caeda0d13\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/27f8f3014dd7afb4df64bedf65128939\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/93d52bc6bcac5b8bd25526370bc1772a\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/f6fcd5d1afadec57bc40543b1b9da88a\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/a721b410c18c6d69e473a52b0a3b02d9\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/af64f688138c5ea18a757e95791964a9\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/18a2c857789f32059271c992b754c282\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/e31822872da1bc218d646f3a1af448eb\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/98c6334e26e78e35f8cd80cd60532e79\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/c6cf143c4f10e4d8e9ab68dc64037726\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/b5a56ab97a47695014c74ee26969a89f\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/e0ffdfcbac605d2b6a3de8db9f080bde\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/a9b9463b2c6a42dae7cfecbc31c93cb7\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/a87d68f929abab9367d6b79e63731d6b\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/ce0c5f9f17d8481e37c14a07ea6b2fb5\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/81b2f78bb2c741355302cac968def7ad\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/8fcfe8f9ab759ce04b0217f7bb86f20a\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/c76f4fa28b62ff210bf274f2ea1325e2\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/8ce9ad20a94b7d1f93d4a4ba17206e4f\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/4bd60c7a997bc2520c6d16f0ce12918d\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/22603004255825987c252c3c30d95879\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/d605e82eedf4ff0ac6d3d7ed21cc3b99\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/cda7790a4e9dc590a58bbfa0e22afbd5\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/c586912ba21ea37110ac102698a03cde\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/1d0fed29315c76fcf88061c22106e0a4\n",
      "___________________________________fit_transform_one cache loaded - 0.2s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/53b2a58a0734ce31c3536789ba5e36df\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/635df543498246e9e86a0ecb1c27de04\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/5043c232fd934c3db8ef3ab012fcc4f9\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/dd19c7c540b821fda080f871de2d2362\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/fcd3d1d445093ace255b2472b98a7041\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/78a4c052091a2ef0a480d1d833719ff5\n",
      "___________________________________fit_transform_one cache loaded - 0.2s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/a157ac4229102a455796446e7d94048c\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/214797fd5eb650ed8051b968b2e20d86\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/87ebb97aaa690306bf903dd317443e33\n",
      "___________________________________fit_transform_one cache loaded - 0.2s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/a179104ae63c16bdac56452e351ee086\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/0ff72f3f75820e4e7e946cdd55670f45\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/0a77aa38d7d5b014ccc86be5e5055bc9\n",
      "___________________________________fit_transform_one cache loaded - 0.2s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/03d64e6e15a6862c598e51ff254c426b\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/615b567f2b1c28f5701ff3ab83be807a\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/8d8060dd6f811f8ba6cf774ea8e176bf\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/7052942d1955cddd5ee8bd2c39f84a8a\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/ec59068b523a48a6d6693ae23ec534db\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/be9ae3f663761ee926c31e900ef44af5\n",
      "___________________________________fit_transform_one cache loaded - 0.4s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/73ccbb1359a96a80c3d1554d4a84f0cd\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/4c3c032dedd7c7e2d74c18dd949ad599\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/aaf3f039e240c396fdee2807d32f381c\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/fdfeb5926174b199a55db1d92d384597\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/78eae253e935a68efc1ea14a9b36ef83\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/8894911a5385fd50efce71f25c62071d\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/82592fe93af6420e91156db4fd3f79dd\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/f4e9d2e8f788e596d3fd1e046fd1ad63\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/4e8b114690be07928ae14e4232f6f2c3\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/ec5d4d13ff384948cc5d576d0c996cbb\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/bdd15f1ed3a993590a8e2e36eb7e6a06\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/6956b21c7478809b033a9420c313685b\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/5e673ee7a6d9a7a40733f4da56a18c48\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/e5e9496951fc434bad86b8765fcaff8c\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/2636770a39f355d3274de41a0d4aaec2\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/8ffb6c6288db48ded0d14e64302bc5d9\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/8918b428ea1febcd3e6c6bfd89421fc7\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/bea2911728a284dce55a5a8caeda0d13\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/27f8f3014dd7afb4df64bedf65128939\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/da8ad56d323605b0a906c61e11db85f7\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/f6fcd5d1afadec57bc40543b1b9da88a\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/a721b410c18c6d69e473a52b0a3b02d9\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/b3c2664864c4628621d0b3b4296974ed\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/18a2c857789f32059271c992b754c282\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/e31822872da1bc218d646f3a1af448eb\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/ee9ef41263e9d4e29e609956aa398af6\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/c6cf143c4f10e4d8e9ab68dc64037726\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/b5a56ab97a47695014c74ee26969a89f\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/2e5871dfe7642d3cbbcb3a5d4f6ebac9\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/a9b9463b2c6a42dae7cfecbc31c93cb7\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/a87d68f929abab9367d6b79e63731d6b\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/4025f8647c6daea074f742d69c804798\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/81b2f78bb2c741355302cac968def7ad\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/8fcfe8f9ab759ce04b0217f7bb86f20a\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/1d602eb2e1c052d9ec51f2df21b6c57f\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/8ce9ad20a94b7d1f93d4a4ba17206e4f\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/4bd60c7a997bc2520c6d16f0ce12918d\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/b8e0060adc926b748cef2b7592e967b6\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/d605e82eedf4ff0ac6d3d7ed21cc3b99\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/cda7790a4e9dc590a58bbfa0e22afbd5\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/264f4bb586097eafa45d983e34988564\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/1d0fed29315c76fcf88061c22106e0a4\n",
      "___________________________________fit_transform_one cache loaded - 0.2s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/53b2a58a0734ce31c3536789ba5e36df\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/8c9aa137bcd9f1be0e57947d4b0669be\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/5043c232fd934c3db8ef3ab012fcc4f9\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/dd19c7c540b821fda080f871de2d2362\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/7ad78c092c5b37053a86a2a2cc9f9925\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/78a4c052091a2ef0a480d1d833719ff5\n",
      "___________________________________fit_transform_one cache loaded - 0.2s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/a157ac4229102a455796446e7d94048c\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/9a57132e26cffa2e2ba78e61cca87b5c\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/87ebb97aaa690306bf903dd317443e33\n",
      "___________________________________fit_transform_one cache loaded - 0.2s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/a179104ae63c16bdac56452e351ee086\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/fa2ff56feed3007009b8eb4117f8cffd\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/0a77aa38d7d5b014ccc86be5e5055bc9\n",
      "___________________________________fit_transform_one cache loaded - 0.2s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/03d64e6e15a6862c598e51ff254c426b\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/51db1ecf1512b3bd9ffd44a08475c5a5\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/8d8060dd6f811f8ba6cf774ea8e176bf\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/7052942d1955cddd5ee8bd2c39f84a8a\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/e078fa2e3f3e81aca65de5426ba0d0c4\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.1s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/be9ae3f663761ee926c31e900ef44af5\n",
      "___________________________________fit_transform_one cache loaded - 0.4s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/73ccbb1359a96a80c3d1554d4a84f0cd\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.5s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/5b0e82172ca073e67cef13571e90b25d\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/aaf3f039e240c396fdee2807d32f381c\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/fdfeb5926174b199a55db1d92d384597\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/9f20fec75b3fa19f7dacbd46c9d114d5\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/8894911a5385fd50efce71f25c62071d\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/82592fe93af6420e91156db4fd3f79dd\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/0fbc95317c18d82dc79a40d6bd7fa83a\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/4e8b114690be07928ae14e4232f6f2c3\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/ec5d4d13ff384948cc5d576d0c996cbb\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/49d843b5193b3d334b931779794ca2b7\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/6956b21c7478809b033a9420c313685b\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/5e673ee7a6d9a7a40733f4da56a18c48\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/a3700d90ebf24b53c0554ebbac454cfc\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/2636770a39f355d3274de41a0d4aaec2\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/8ffb6c6288db48ded0d14e64302bc5d9\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/85e0297911eb4ff4426655821ca8e36e\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/bea2911728a284dce55a5a8caeda0d13\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/27f8f3014dd7afb4df64bedf65128939\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/93d52bc6bcac5b8bd25526370bc1772a\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/f6fcd5d1afadec57bc40543b1b9da88a\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/a721b410c18c6d69e473a52b0a3b02d9\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/af64f688138c5ea18a757e95791964a9\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/18a2c857789f32059271c992b754c282\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/e31822872da1bc218d646f3a1af448eb\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/98c6334e26e78e35f8cd80cd60532e79\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/c6cf143c4f10e4d8e9ab68dc64037726\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/b5a56ab97a47695014c74ee26969a89f\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/e0ffdfcbac605d2b6a3de8db9f080bde\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/a9b9463b2c6a42dae7cfecbc31c93cb7\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/a87d68f929abab9367d6b79e63731d6b\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/ce0c5f9f17d8481e37c14a07ea6b2fb5\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/81b2f78bb2c741355302cac968def7ad\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/8fcfe8f9ab759ce04b0217f7bb86f20a\n",
      "___________________________________fit_transform_one cache loaded - 0.1s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/c76f4fa28b62ff210bf274f2ea1325e2\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/8ce9ad20a94b7d1f93d4a4ba17206e4f\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/4bd60c7a997bc2520c6d16f0ce12918d\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/22603004255825987c252c3c30d95879\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/d605e82eedf4ff0ac6d3d7ed21cc3b99\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/cda7790a4e9dc590a58bbfa0e22afbd5\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/c586912ba21ea37110ac102698a03cde\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/1d0fed29315c76fcf88061c22106e0a4\n",
      "___________________________________fit_transform_one cache loaded - 0.2s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/53b2a58a0734ce31c3536789ba5e36df\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/635df543498246e9e86a0ecb1c27de04\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/5043c232fd934c3db8ef3ab012fcc4f9\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/dd19c7c540b821fda080f871de2d2362\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/fcd3d1d445093ace255b2472b98a7041\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/78a4c052091a2ef0a480d1d833719ff5\n",
      "___________________________________fit_transform_one cache loaded - 0.2s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/a157ac4229102a455796446e7d94048c\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/214797fd5eb650ed8051b968b2e20d86\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/87ebb97aaa690306bf903dd317443e33\n",
      "___________________________________fit_transform_one cache loaded - 0.2s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/a179104ae63c16bdac56452e351ee086\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/0ff72f3f75820e4e7e946cdd55670f45\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/0a77aa38d7d5b014ccc86be5e5055bc9\n",
      "___________________________________fit_transform_one cache loaded - 0.2s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/03d64e6e15a6862c598e51ff254c426b\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/615b567f2b1c28f5701ff3ab83be807a\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/8d8060dd6f811f8ba6cf774ea8e176bf\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/7052942d1955cddd5ee8bd2c39f84a8a\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/ec59068b523a48a6d6693ae23ec534db\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/be9ae3f663761ee926c31e900ef44af5\n",
      "___________________________________fit_transform_one cache loaded - 0.4s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/73ccbb1359a96a80c3d1554d4a84f0cd\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.5s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/4c3c032dedd7c7e2d74c18dd949ad599\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/aaf3f039e240c396fdee2807d32f381c\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/fdfeb5926174b199a55db1d92d384597\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/78eae253e935a68efc1ea14a9b36ef83\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/8894911a5385fd50efce71f25c62071d\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/82592fe93af6420e91156db4fd3f79dd\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/f4e9d2e8f788e596d3fd1e046fd1ad63\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/4e8b114690be07928ae14e4232f6f2c3\n",
      "___________________________________fit_transform_one cache loaded - 0.4s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/ec5d4d13ff384948cc5d576d0c996cbb\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/bdd15f1ed3a993590a8e2e36eb7e6a06\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/6956b21c7478809b033a9420c313685b\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/5e673ee7a6d9a7a40733f4da56a18c48\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/e5e9496951fc434bad86b8765fcaff8c\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/2636770a39f355d3274de41a0d4aaec2\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/8ffb6c6288db48ded0d14e64302bc5d9\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/8918b428ea1febcd3e6c6bfd89421fc7\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/bea2911728a284dce55a5a8caeda0d13\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/27f8f3014dd7afb4df64bedf65128939\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/da8ad56d323605b0a906c61e11db85f7\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/f6fcd5d1afadec57bc40543b1b9da88a\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/a721b410c18c6d69e473a52b0a3b02d9\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/b3c2664864c4628621d0b3b4296974ed\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/18a2c857789f32059271c992b754c282\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/e31822872da1bc218d646f3a1af448eb\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/ee9ef41263e9d4e29e609956aa398af6\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/c6cf143c4f10e4d8e9ab68dc64037726\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/b5a56ab97a47695014c74ee26969a89f\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/2e5871dfe7642d3cbbcb3a5d4f6ebac9\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/a9b9463b2c6a42dae7cfecbc31c93cb7\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/a87d68f929abab9367d6b79e63731d6b\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/4025f8647c6daea074f742d69c804798\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/81b2f78bb2c741355302cac968def7ad\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/8fcfe8f9ab759ce04b0217f7bb86f20a\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/1d602eb2e1c052d9ec51f2df21b6c57f\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/8ce9ad20a94b7d1f93d4a4ba17206e4f\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/4bd60c7a997bc2520c6d16f0ce12918d\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/b8e0060adc926b748cef2b7592e967b6\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/d605e82eedf4ff0ac6d3d7ed21cc3b99\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/cda7790a4e9dc590a58bbfa0e22afbd5\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/264f4bb586097eafa45d983e34988564\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/1d0fed29315c76fcf88061c22106e0a4\n",
      "___________________________________fit_transform_one cache loaded - 0.2s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/53b2a58a0734ce31c3536789ba5e36df\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/8c9aa137bcd9f1be0e57947d4b0669be\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/5043c232fd934c3db8ef3ab012fcc4f9\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/dd19c7c540b821fda080f871de2d2362\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/7ad78c092c5b37053a86a2a2cc9f9925\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/78a4c052091a2ef0a480d1d833719ff5\n",
      "___________________________________fit_transform_one cache loaded - 0.2s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/a157ac4229102a455796446e7d94048c\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/9a57132e26cffa2e2ba78e61cca87b5c\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/87ebb97aaa690306bf903dd317443e33\n",
      "___________________________________fit_transform_one cache loaded - 0.2s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/a179104ae63c16bdac56452e351ee086\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/fa2ff56feed3007009b8eb4117f8cffd\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/0a77aa38d7d5b014ccc86be5e5055bc9\n",
      "___________________________________fit_transform_one cache loaded - 0.2s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/03d64e6e15a6862c598e51ff254c426b\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/51db1ecf1512b3bd9ffd44a08475c5a5\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/8d8060dd6f811f8ba6cf774ea8e176bf\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/7052942d1955cddd5ee8bd2c39f84a8a\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/e078fa2e3f3e81aca65de5426ba0d0c4\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/be9ae3f663761ee926c31e900ef44af5\n",
      "___________________________________fit_transform_one cache loaded - 0.4s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/73ccbb1359a96a80c3d1554d4a84f0cd\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/5b0e82172ca073e67cef13571e90b25d\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/aaf3f039e240c396fdee2807d32f381c\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/fdfeb5926174b199a55db1d92d384597\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/9f20fec75b3fa19f7dacbd46c9d114d5\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/8894911a5385fd50efce71f25c62071d\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/82592fe93af6420e91156db4fd3f79dd\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/0fbc95317c18d82dc79a40d6bd7fa83a\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/4e8b114690be07928ae14e4232f6f2c3\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/ec5d4d13ff384948cc5d576d0c996cbb\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/49d843b5193b3d334b931779794ca2b7\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/6956b21c7478809b033a9420c313685b\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/5e673ee7a6d9a7a40733f4da56a18c48\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/a3700d90ebf24b53c0554ebbac454cfc\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/2636770a39f355d3274de41a0d4aaec2\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/8ffb6c6288db48ded0d14e64302bc5d9\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/85e0297911eb4ff4426655821ca8e36e\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/bea2911728a284dce55a5a8caeda0d13\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/27f8f3014dd7afb4df64bedf65128939\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/93d52bc6bcac5b8bd25526370bc1772a\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/f6fcd5d1afadec57bc40543b1b9da88a\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/a721b410c18c6d69e473a52b0a3b02d9\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/af64f688138c5ea18a757e95791964a9\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/18a2c857789f32059271c992b754c282\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/e31822872da1bc218d646f3a1af448eb\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/98c6334e26e78e35f8cd80cd60532e79\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/c6cf143c4f10e4d8e9ab68dc64037726\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/b5a56ab97a47695014c74ee26969a89f\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/e0ffdfcbac605d2b6a3de8db9f080bde\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/a9b9463b2c6a42dae7cfecbc31c93cb7\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/a87d68f929abab9367d6b79e63731d6b\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/ce0c5f9f17d8481e37c14a07ea6b2fb5\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/81b2f78bb2c741355302cac968def7ad\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/8fcfe8f9ab759ce04b0217f7bb86f20a\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/c76f4fa28b62ff210bf274f2ea1325e2\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/8ce9ad20a94b7d1f93d4a4ba17206e4f\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/4bd60c7a997bc2520c6d16f0ce12918d\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/22603004255825987c252c3c30d95879\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/d605e82eedf4ff0ac6d3d7ed21cc3b99\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/cda7790a4e9dc590a58bbfa0e22afbd5\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/c586912ba21ea37110ac102698a03cde\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/1d0fed29315c76fcf88061c22106e0a4\n",
      "___________________________________fit_transform_one cache loaded - 0.2s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/53b2a58a0734ce31c3536789ba5e36df\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/635df543498246e9e86a0ecb1c27de04\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/5043c232fd934c3db8ef3ab012fcc4f9\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/dd19c7c540b821fda080f871de2d2362\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/fcd3d1d445093ace255b2472b98a7041\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/78a4c052091a2ef0a480d1d833719ff5\n",
      "___________________________________fit_transform_one cache loaded - 0.2s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/a157ac4229102a455796446e7d94048c\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/214797fd5eb650ed8051b968b2e20d86\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/87ebb97aaa690306bf903dd317443e33\n",
      "___________________________________fit_transform_one cache loaded - 0.2s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/a179104ae63c16bdac56452e351ee086\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/0ff72f3f75820e4e7e946cdd55670f45\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/0a77aa38d7d5b014ccc86be5e5055bc9\n",
      "___________________________________fit_transform_one cache loaded - 0.2s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/03d64e6e15a6862c598e51ff254c426b\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/615b567f2b1c28f5701ff3ab83be807a\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/8d8060dd6f811f8ba6cf774ea8e176bf\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/7052942d1955cddd5ee8bd2c39f84a8a\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/ec59068b523a48a6d6693ae23ec534db\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/be9ae3f663761ee926c31e900ef44af5\n",
      "___________________________________fit_transform_one cache loaded - 0.4s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/73ccbb1359a96a80c3d1554d4a84f0cd\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/4c3c032dedd7c7e2d74c18dd949ad599\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/aaf3f039e240c396fdee2807d32f381c\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/fdfeb5926174b199a55db1d92d384597\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/78eae253e935a68efc1ea14a9b36ef83\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/8894911a5385fd50efce71f25c62071d\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/82592fe93af6420e91156db4fd3f79dd\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/f4e9d2e8f788e596d3fd1e046fd1ad63\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/4e8b114690be07928ae14e4232f6f2c3\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/ec5d4d13ff384948cc5d576d0c996cbb\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/bdd15f1ed3a993590a8e2e36eb7e6a06\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/6956b21c7478809b033a9420c313685b\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/5e673ee7a6d9a7a40733f4da56a18c48\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/e5e9496951fc434bad86b8765fcaff8c\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/2636770a39f355d3274de41a0d4aaec2\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/8ffb6c6288db48ded0d14e64302bc5d9\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/8918b428ea1febcd3e6c6bfd89421fc7\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/bea2911728a284dce55a5a8caeda0d13\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/27f8f3014dd7afb4df64bedf65128939\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/da8ad56d323605b0a906c61e11db85f7\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/f6fcd5d1afadec57bc40543b1b9da88a\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/a721b410c18c6d69e473a52b0a3b02d9\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/b3c2664864c4628621d0b3b4296974ed\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/18a2c857789f32059271c992b754c282\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/e31822872da1bc218d646f3a1af448eb\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/ee9ef41263e9d4e29e609956aa398af6\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/c6cf143c4f10e4d8e9ab68dc64037726\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/b5a56ab97a47695014c74ee26969a89f\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/2e5871dfe7642d3cbbcb3a5d4f6ebac9\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/a9b9463b2c6a42dae7cfecbc31c93cb7\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/a87d68f929abab9367d6b79e63731d6b\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/4025f8647c6daea074f742d69c804798\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/81b2f78bb2c741355302cac968def7ad\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/8fcfe8f9ab759ce04b0217f7bb86f20a\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/1d602eb2e1c052d9ec51f2df21b6c57f\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/8ce9ad20a94b7d1f93d4a4ba17206e4f\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/4bd60c7a997bc2520c6d16f0ce12918d\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/b8e0060adc926b748cef2b7592e967b6\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/d605e82eedf4ff0ac6d3d7ed21cc3b99\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/cda7790a4e9dc590a58bbfa0e22afbd5\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.4s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/264f4bb586097eafa45d983e34988564\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/1d0fed29315c76fcf88061c22106e0a4\n",
      "___________________________________fit_transform_one cache loaded - 0.2s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/53b2a58a0734ce31c3536789ba5e36df\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/8c9aa137bcd9f1be0e57947d4b0669be\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/5043c232fd934c3db8ef3ab012fcc4f9\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/dd19c7c540b821fda080f871de2d2362\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/7ad78c092c5b37053a86a2a2cc9f9925\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/78a4c052091a2ef0a480d1d833719ff5\n",
      "___________________________________fit_transform_one cache loaded - 0.2s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/a157ac4229102a455796446e7d94048c\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/9a57132e26cffa2e2ba78e61cca87b5c\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/87ebb97aaa690306bf903dd317443e33\n",
      "___________________________________fit_transform_one cache loaded - 0.3s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/a179104ae63c16bdac56452e351ee086\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/fa2ff56feed3007009b8eb4117f8cffd\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.0s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/0a77aa38d7d5b014ccc86be5e5055bc9\n",
      "___________________________________fit_transform_one cache loaded - 0.2s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/03d64e6e15a6862c598e51ff254c426b\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n",
      "[Memory]0.3s, 0.0min    : Loading _fit_transform_one from /var/folders/71/h_lz7s4921x0t4yrnskbyr_40000gn/T/tmpc5c8cd6t/joblib/sklearn/pipeline/_fit_transform_one/51db1ecf1512b3bd9ffd44a08475c5a5\n",
      "___________________________________fit_transform_one cache loaded - 0.0s, 0.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=3,\n",
      "        ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
      "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None), \n",
      "[ 'On March 21, 1993 Roger Maynard wrote (in reply to an article by Graham\\n'\n",
      "  'Hudson):\\n'\n",
      "  '\\n'\n",
      "  '>> will still have the Jennings Trophy at the end of the year.  Potvin is '\n",
      "  'very\\n'\n",
      "  '>> good, and I do believe that he will be a star, but I want to see him\\n'\n",
      "  '>> perform in the playoffs under pressure.\\n'\n",
      "  '\\n'\n",
      "  '>You don\\'t think he is performing \"under pressure\" now?  The major\\n'\n",
      "  '>differences  between playoff hockey and normal hockey is 1. play-\\n'\n",
      "  '>ing every other night which is physically exhausting and 2.   You\\n'\n",
      "  '>play  the  same  team  in a consecutive string of games.  Is this\\n'\n",
      "  '>what you mean by pressure?  Have you even thought about what  you\\n'\n",
      "  '>mean  ..., \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "..., \n",
      "None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/pipeline.py:230: UserWarning: Persisting input arguments took 2.72s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________fit_transform_one - 2.4s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True), <4732x17131 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 306546 stored elements in Compressed Sparse Row format>, \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "..., \n",
      "None)\n",
      "________________________________________________fit_transform_one - 0.1s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling sklearn.pipeline._fit_transform_one...\n",
      "_fit_transform_one(TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), \n",
      "<4732x17131 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 306546 stored elements in Compressed Sparse Row format>, \n",
      "[ 1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "  1,\n",
      "  0,\n",
      "  1,\n",
      "  0,\n",
      "  0,\n",
      "  1,\n",
      "..., \n",
      "None)\n",
      "________________________________________________fit_transform_one - 0.6s, 0.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "grid_rm = GridSearchCV(pipeline, cv=5, n_jobs=1, param_grid=param_grid, scoring='accuracy')\n",
    "grid_rm.fit(train_dataset_rm.data, new_train_label_rm)\n",
    "rmtree(cachedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/apple/miniconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_clf</th>\n",
       "      <th>param_reduce_dim</th>\n",
       "      <th>param_vect</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.962686</td>\n",
       "      <td>0.419752</td>\n",
       "      <td>0.233989</td>\n",
       "      <td>0.032474</td>\n",
       "      <td>SVC(C=10, cache_size=200, class_weight=None, c...</td>\n",
       "      <td>TruncatedSVD(algorithm='randomized', n_compone...</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>{'clf': SVC(C=10, cache_size=200, class_weight...</td>\n",
       "      <td>0.967265</td>\n",
       "      <td>0.968321</td>\n",
       "      <td>...</td>\n",
       "      <td>0.971048</td>\n",
       "      <td>0.005124</td>\n",
       "      <td>6</td>\n",
       "      <td>0.976222</td>\n",
       "      <td>0.974637</td>\n",
       "      <td>0.971995</td>\n",
       "      <td>0.974643</td>\n",
       "      <td>0.977291</td>\n",
       "      <td>0.974958</td>\n",
       "      <td>0.001790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56.816349</td>\n",
       "      <td>4.698646</td>\n",
       "      <td>13.417887</td>\n",
       "      <td>1.112280</td>\n",
       "      <td>SVC(C=10, cache_size=200, class_weight=None, c...</td>\n",
       "      <td>TruncatedSVD(algorithm='randomized', n_compone...</td>\n",
       "      <td>CountVectorizer(analyzer=&lt;function stem_rmv_nu...</td>\n",
       "      <td>{'clf': SVC(C=10, cache_size=200, class_weight...</td>\n",
       "      <td>0.971489</td>\n",
       "      <td>0.955649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.965131</td>\n",
       "      <td>0.005714</td>\n",
       "      <td>14</td>\n",
       "      <td>0.966711</td>\n",
       "      <td>0.972259</td>\n",
       "      <td>0.968032</td>\n",
       "      <td>0.971210</td>\n",
       "      <td>0.973330</td>\n",
       "      <td>0.970308</td>\n",
       "      <td>0.002525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.770253</td>\n",
       "      <td>0.416479</td>\n",
       "      <td>0.231373</td>\n",
       "      <td>0.025810</td>\n",
       "      <td>SVC(C=10, cache_size=200, class_weight=None, c...</td>\n",
       "      <td>TruncatedSVD(algorithm='randomized', n_compone...</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>{'clf': SVC(C=10, cache_size=200, class_weight...</td>\n",
       "      <td>0.973601</td>\n",
       "      <td>0.970433</td>\n",
       "      <td>...</td>\n",
       "      <td>0.972527</td>\n",
       "      <td>0.003552</td>\n",
       "      <td>4</td>\n",
       "      <td>0.975958</td>\n",
       "      <td>0.975958</td>\n",
       "      <td>0.972523</td>\n",
       "      <td>0.975172</td>\n",
       "      <td>0.974650</td>\n",
       "      <td>0.974852</td>\n",
       "      <td>0.001266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47.986434</td>\n",
       "      <td>0.763277</td>\n",
       "      <td>11.289791</td>\n",
       "      <td>0.773188</td>\n",
       "      <td>SVC(C=10, cache_size=200, class_weight=None, c...</td>\n",
       "      <td>TruncatedSVD(algorithm='randomized', n_compone...</td>\n",
       "      <td>CountVectorizer(analyzer=&lt;function stem_rmv_nu...</td>\n",
       "      <td>{'clf': SVC(C=10, cache_size=200, class_weight...</td>\n",
       "      <td>0.974657</td>\n",
       "      <td>0.956705</td>\n",
       "      <td>...</td>\n",
       "      <td>0.966610</td>\n",
       "      <td>0.006743</td>\n",
       "      <td>12</td>\n",
       "      <td>0.964597</td>\n",
       "      <td>0.970938</td>\n",
       "      <td>0.967768</td>\n",
       "      <td>0.970946</td>\n",
       "      <td>0.973330</td>\n",
       "      <td>0.969516</td>\n",
       "      <td>0.003029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.796941</td>\n",
       "      <td>1.451965</td>\n",
       "      <td>0.284369</td>\n",
       "      <td>0.012491</td>\n",
       "      <td>SVC(C=10, cache_size=200, class_weight=None, c...</td>\n",
       "      <td>NMF(alpha=0.0, beta_loss='frobenius', init='ra...</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>{'clf': SVC(C=10, cache_size=200, class_weight...</td>\n",
       "      <td>0.951426</td>\n",
       "      <td>0.940866</td>\n",
       "      <td>...</td>\n",
       "      <td>0.947168</td>\n",
       "      <td>0.008159</td>\n",
       "      <td>25</td>\n",
       "      <td>0.949538</td>\n",
       "      <td>0.951123</td>\n",
       "      <td>0.940819</td>\n",
       "      <td>0.950608</td>\n",
       "      <td>0.946924</td>\n",
       "      <td>0.947802</td>\n",
       "      <td>0.003780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>14.048102</td>\n",
       "      <td>1.745462</td>\n",
       "      <td>11.333085</td>\n",
       "      <td>0.764753</td>\n",
       "      <td>SVC(C=10, cache_size=200, class_weight=None, c...</td>\n",
       "      <td>NMF(alpha=0.0, beta_loss='frobenius', init='ra...</td>\n",
       "      <td>CountVectorizer(analyzer=&lt;function stem_rmv_nu...</td>\n",
       "      <td>{'clf': SVC(C=10, cache_size=200, class_weight...</td>\n",
       "      <td>0.959873</td>\n",
       "      <td>0.940866</td>\n",
       "      <td>...</td>\n",
       "      <td>0.949704</td>\n",
       "      <td>0.007295</td>\n",
       "      <td>23</td>\n",
       "      <td>0.956407</td>\n",
       "      <td>0.958785</td>\n",
       "      <td>0.952180</td>\n",
       "      <td>0.953777</td>\n",
       "      <td>0.950885</td>\n",
       "      <td>0.954407</td>\n",
       "      <td>0.002861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11.459811</td>\n",
       "      <td>2.020819</td>\n",
       "      <td>0.254887</td>\n",
       "      <td>0.004646</td>\n",
       "      <td>SVC(C=10, cache_size=200, class_weight=None, c...</td>\n",
       "      <td>NMF(alpha=0.0, beta_loss='frobenius', init='ra...</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>{'clf': SVC(C=10, cache_size=200, class_weight...</td>\n",
       "      <td>0.949314</td>\n",
       "      <td>0.941922</td>\n",
       "      <td>...</td>\n",
       "      <td>0.951395</td>\n",
       "      <td>0.008535</td>\n",
       "      <td>22</td>\n",
       "      <td>0.951387</td>\n",
       "      <td>0.951915</td>\n",
       "      <td>0.952972</td>\n",
       "      <td>0.955098</td>\n",
       "      <td>0.955638</td>\n",
       "      <td>0.953402</td>\n",
       "      <td>0.001693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9.160476</td>\n",
       "      <td>1.693347</td>\n",
       "      <td>11.322142</td>\n",
       "      <td>0.814039</td>\n",
       "      <td>SVC(C=10, cache_size=200, class_weight=None, c...</td>\n",
       "      <td>NMF(alpha=0.0, beta_loss='frobenius', init='ra...</td>\n",
       "      <td>CountVectorizer(analyzer=&lt;function stem_rmv_nu...</td>\n",
       "      <td>{'clf': SVC(C=10, cache_size=200, class_weight...</td>\n",
       "      <td>0.960929</td>\n",
       "      <td>0.942978</td>\n",
       "      <td>...</td>\n",
       "      <td>0.954987</td>\n",
       "      <td>0.008793</td>\n",
       "      <td>21</td>\n",
       "      <td>0.954822</td>\n",
       "      <td>0.956143</td>\n",
       "      <td>0.954822</td>\n",
       "      <td>0.959324</td>\n",
       "      <td>0.958014</td>\n",
       "      <td>0.956625</td>\n",
       "      <td>0.001786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.492910</td>\n",
       "      <td>0.018127</td>\n",
       "      <td>0.174017</td>\n",
       "      <td>0.010081</td>\n",
       "      <td>LogisticRegression(C=100, class_weight=None, d...</td>\n",
       "      <td>TruncatedSVD(algorithm='randomized', n_compone...</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>{'clf': LogisticRegression(C=100, class_weight...</td>\n",
       "      <td>0.973601</td>\n",
       "      <td>0.971489</td>\n",
       "      <td>...</td>\n",
       "      <td>0.973373</td>\n",
       "      <td>0.005123</td>\n",
       "      <td>1</td>\n",
       "      <td>0.978071</td>\n",
       "      <td>0.976750</td>\n",
       "      <td>0.974373</td>\n",
       "      <td>0.976228</td>\n",
       "      <td>0.978347</td>\n",
       "      <td>0.976754</td>\n",
       "      <td>0.001430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.432590</td>\n",
       "      <td>0.012666</td>\n",
       "      <td>11.248836</td>\n",
       "      <td>0.758335</td>\n",
       "      <td>LogisticRegression(C=100, class_weight=None, d...</td>\n",
       "      <td>TruncatedSVD(algorithm='randomized', n_compone...</td>\n",
       "      <td>CountVectorizer(analyzer=&lt;function stem_rmv_nu...</td>\n",
       "      <td>{'clf': LogisticRegression(C=100, class_weight...</td>\n",
       "      <td>0.974657</td>\n",
       "      <td>0.959873</td>\n",
       "      <td>...</td>\n",
       "      <td>0.969569</td>\n",
       "      <td>0.005102</td>\n",
       "      <td>8</td>\n",
       "      <td>0.970674</td>\n",
       "      <td>0.972259</td>\n",
       "      <td>0.972787</td>\n",
       "      <td>0.973851</td>\n",
       "      <td>0.974650</td>\n",
       "      <td>0.972844</td>\n",
       "      <td>0.001366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.432969</td>\n",
       "      <td>0.010925</td>\n",
       "      <td>0.166997</td>\n",
       "      <td>0.009102</td>\n",
       "      <td>LogisticRegression(C=100, class_weight=None, d...</td>\n",
       "      <td>TruncatedSVD(algorithm='randomized', n_compone...</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>{'clf': LogisticRegression(C=100, class_weight...</td>\n",
       "      <td>0.974657</td>\n",
       "      <td>0.969377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.972950</td>\n",
       "      <td>0.006307</td>\n",
       "      <td>2</td>\n",
       "      <td>0.977807</td>\n",
       "      <td>0.977807</td>\n",
       "      <td>0.973580</td>\n",
       "      <td>0.977285</td>\n",
       "      <td>0.977819</td>\n",
       "      <td>0.976860</td>\n",
       "      <td>0.001652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.386701</td>\n",
       "      <td>0.008652</td>\n",
       "      <td>11.248504</td>\n",
       "      <td>0.764086</td>\n",
       "      <td>LogisticRegression(C=100, class_weight=None, d...</td>\n",
       "      <td>TruncatedSVD(algorithm='randomized', n_compone...</td>\n",
       "      <td>CountVectorizer(analyzer=&lt;function stem_rmv_nu...</td>\n",
       "      <td>{'clf': LogisticRegression(C=100, class_weight...</td>\n",
       "      <td>0.975713</td>\n",
       "      <td>0.960929</td>\n",
       "      <td>...</td>\n",
       "      <td>0.968935</td>\n",
       "      <td>0.005117</td>\n",
       "      <td>10</td>\n",
       "      <td>0.971731</td>\n",
       "      <td>0.973844</td>\n",
       "      <td>0.971995</td>\n",
       "      <td>0.974643</td>\n",
       "      <td>0.975178</td>\n",
       "      <td>0.973478</td>\n",
       "      <td>0.001388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.462682</td>\n",
       "      <td>0.010759</td>\n",
       "      <td>0.232716</td>\n",
       "      <td>0.007757</td>\n",
       "      <td>LogisticRegression(C=100, class_weight=None, d...</td>\n",
       "      <td>NMF(alpha=0.0, beta_loss='frobenius', init='ra...</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>{'clf': LogisticRegression(C=100, class_weight...</td>\n",
       "      <td>0.964097</td>\n",
       "      <td>0.960929</td>\n",
       "      <td>...</td>\n",
       "      <td>0.959637</td>\n",
       "      <td>0.007895</td>\n",
       "      <td>18</td>\n",
       "      <td>0.960634</td>\n",
       "      <td>0.960370</td>\n",
       "      <td>0.956935</td>\n",
       "      <td>0.961965</td>\n",
       "      <td>0.960391</td>\n",
       "      <td>0.960059</td>\n",
       "      <td>0.001669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.410356</td>\n",
       "      <td>0.012042</td>\n",
       "      <td>11.301614</td>\n",
       "      <td>0.817440</td>\n",
       "      <td>LogisticRegression(C=100, class_weight=None, d...</td>\n",
       "      <td>NMF(alpha=0.0, beta_loss='frobenius', init='ra...</td>\n",
       "      <td>CountVectorizer(analyzer=&lt;function stem_rmv_nu...</td>\n",
       "      <td>{'clf': LogisticRegression(C=100, class_weight...</td>\n",
       "      <td>0.964097</td>\n",
       "      <td>0.951426</td>\n",
       "      <td>...</td>\n",
       "      <td>0.958157</td>\n",
       "      <td>0.006724</td>\n",
       "      <td>20</td>\n",
       "      <td>0.960634</td>\n",
       "      <td>0.964861</td>\n",
       "      <td>0.959049</td>\n",
       "      <td>0.963022</td>\n",
       "      <td>0.960391</td>\n",
       "      <td>0.961591</td>\n",
       "      <td>0.002077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.417232</td>\n",
       "      <td>0.014760</td>\n",
       "      <td>0.215037</td>\n",
       "      <td>0.010752</td>\n",
       "      <td>LogisticRegression(C=100, class_weight=None, d...</td>\n",
       "      <td>NMF(alpha=0.0, beta_loss='frobenius', init='ra...</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>{'clf': LogisticRegression(C=100, class_weight...</td>\n",
       "      <td>0.959873</td>\n",
       "      <td>0.956705</td>\n",
       "      <td>...</td>\n",
       "      <td>0.962384</td>\n",
       "      <td>0.007465</td>\n",
       "      <td>15</td>\n",
       "      <td>0.963804</td>\n",
       "      <td>0.964597</td>\n",
       "      <td>0.963540</td>\n",
       "      <td>0.966191</td>\n",
       "      <td>0.967256</td>\n",
       "      <td>0.965078</td>\n",
       "      <td>0.001428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.364368</td>\n",
       "      <td>0.006498</td>\n",
       "      <td>11.262656</td>\n",
       "      <td>0.780384</td>\n",
       "      <td>LogisticRegression(C=100, class_weight=None, d...</td>\n",
       "      <td>NMF(alpha=0.0, beta_loss='frobenius', init='ra...</td>\n",
       "      <td>CountVectorizer(analyzer=&lt;function stem_rmv_nu...</td>\n",
       "      <td>{'clf': LogisticRegression(C=100, class_weight...</td>\n",
       "      <td>0.964097</td>\n",
       "      <td>0.950370</td>\n",
       "      <td>...</td>\n",
       "      <td>0.959637</td>\n",
       "      <td>0.006741</td>\n",
       "      <td>18</td>\n",
       "      <td>0.962483</td>\n",
       "      <td>0.964333</td>\n",
       "      <td>0.964069</td>\n",
       "      <td>0.965663</td>\n",
       "      <td>0.964088</td>\n",
       "      <td>0.964127</td>\n",
       "      <td>0.001011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.495884</td>\n",
       "      <td>0.022546</td>\n",
       "      <td>0.178400</td>\n",
       "      <td>0.012487</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>TruncatedSVD(algorithm='randomized', n_compone...</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>{'clf': LogisticRegression(C=10, class_weight=...</td>\n",
       "      <td>0.971489</td>\n",
       "      <td>0.972545</td>\n",
       "      <td>...</td>\n",
       "      <td>0.971682</td>\n",
       "      <td>0.003580</td>\n",
       "      <td>5</td>\n",
       "      <td>0.978600</td>\n",
       "      <td>0.976750</td>\n",
       "      <td>0.977015</td>\n",
       "      <td>0.978341</td>\n",
       "      <td>0.979139</td>\n",
       "      <td>0.977969</td>\n",
       "      <td>0.000928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.434211</td>\n",
       "      <td>0.010711</td>\n",
       "      <td>11.260686</td>\n",
       "      <td>0.785300</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>TruncatedSVD(algorithm='randomized', n_compone...</td>\n",
       "      <td>CountVectorizer(analyzer=&lt;function stem_rmv_nu...</td>\n",
       "      <td>{'clf': LogisticRegression(C=10, class_weight=...</td>\n",
       "      <td>0.975713</td>\n",
       "      <td>0.964097</td>\n",
       "      <td>...</td>\n",
       "      <td>0.970626</td>\n",
       "      <td>0.004893</td>\n",
       "      <td>7</td>\n",
       "      <td>0.973052</td>\n",
       "      <td>0.974901</td>\n",
       "      <td>0.970938</td>\n",
       "      <td>0.975172</td>\n",
       "      <td>0.975706</td>\n",
       "      <td>0.973954</td>\n",
       "      <td>0.001753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.455256</td>\n",
       "      <td>0.018835</td>\n",
       "      <td>0.169329</td>\n",
       "      <td>0.011409</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>TruncatedSVD(algorithm='randomized', n_compone...</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>{'clf': LogisticRegression(C=10, class_weight=...</td>\n",
       "      <td>0.972545</td>\n",
       "      <td>0.971489</td>\n",
       "      <td>...</td>\n",
       "      <td>0.972950</td>\n",
       "      <td>0.003831</td>\n",
       "      <td>2</td>\n",
       "      <td>0.977807</td>\n",
       "      <td>0.977543</td>\n",
       "      <td>0.978336</td>\n",
       "      <td>0.978870</td>\n",
       "      <td>0.979931</td>\n",
       "      <td>0.978497</td>\n",
       "      <td>0.000850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.389966</td>\n",
       "      <td>0.012903</td>\n",
       "      <td>11.316099</td>\n",
       "      <td>0.789237</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>TruncatedSVD(algorithm='randomized', n_compone...</td>\n",
       "      <td>CountVectorizer(analyzer=&lt;function stem_rmv_nu...</td>\n",
       "      <td>{'clf': LogisticRegression(C=10, class_weight=...</td>\n",
       "      <td>0.976769</td>\n",
       "      <td>0.959873</td>\n",
       "      <td>...</td>\n",
       "      <td>0.969358</td>\n",
       "      <td>0.006238</td>\n",
       "      <td>9</td>\n",
       "      <td>0.973052</td>\n",
       "      <td>0.973316</td>\n",
       "      <td>0.972259</td>\n",
       "      <td>0.974908</td>\n",
       "      <td>0.975178</td>\n",
       "      <td>0.973742</td>\n",
       "      <td>0.001121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.472331</td>\n",
       "      <td>0.013957</td>\n",
       "      <td>0.229366</td>\n",
       "      <td>0.011777</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>NMF(alpha=0.0, beta_loss='frobenius', init='ra...</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>{'clf': LogisticRegression(C=10, class_weight=...</td>\n",
       "      <td>0.969377</td>\n",
       "      <td>0.969377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.966610</td>\n",
       "      <td>0.005440</td>\n",
       "      <td>12</td>\n",
       "      <td>0.970674</td>\n",
       "      <td>0.969089</td>\n",
       "      <td>0.968296</td>\n",
       "      <td>0.968568</td>\n",
       "      <td>0.971745</td>\n",
       "      <td>0.969674</td>\n",
       "      <td>0.001323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.411661</td>\n",
       "      <td>0.011797</td>\n",
       "      <td>11.334696</td>\n",
       "      <td>0.766469</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>NMF(alpha=0.0, beta_loss='frobenius', init='ra...</td>\n",
       "      <td>CountVectorizer(analyzer=&lt;function stem_rmv_nu...</td>\n",
       "      <td>{'clf': LogisticRegression(C=10, class_weight=...</td>\n",
       "      <td>0.969377</td>\n",
       "      <td>0.955649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.960270</td>\n",
       "      <td>0.007242</td>\n",
       "      <td>17</td>\n",
       "      <td>0.964597</td>\n",
       "      <td>0.969881</td>\n",
       "      <td>0.965918</td>\n",
       "      <td>0.965927</td>\n",
       "      <td>0.968577</td>\n",
       "      <td>0.966980</td>\n",
       "      <td>0.001943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.414414</td>\n",
       "      <td>0.013312</td>\n",
       "      <td>0.212723</td>\n",
       "      <td>0.008732</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>NMF(alpha=0.0, beta_loss='frobenius', init='ra...</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>{'clf': LogisticRegression(C=10, class_weight=...</td>\n",
       "      <td>0.965153</td>\n",
       "      <td>0.961985</td>\n",
       "      <td>...</td>\n",
       "      <td>0.967033</td>\n",
       "      <td>0.005329</td>\n",
       "      <td>11</td>\n",
       "      <td>0.974637</td>\n",
       "      <td>0.969881</td>\n",
       "      <td>0.969617</td>\n",
       "      <td>0.971474</td>\n",
       "      <td>0.972802</td>\n",
       "      <td>0.971682</td>\n",
       "      <td>0.001873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.359011</td>\n",
       "      <td>0.008247</td>\n",
       "      <td>11.390168</td>\n",
       "      <td>0.899670</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>NMF(alpha=0.0, beta_loss='frobenius', init='ra...</td>\n",
       "      <td>CountVectorizer(analyzer=&lt;function stem_rmv_nu...</td>\n",
       "      <td>{'clf': LogisticRegression(C=10, class_weight=...</td>\n",
       "      <td>0.967265</td>\n",
       "      <td>0.952482</td>\n",
       "      <td>...</td>\n",
       "      <td>0.961116</td>\n",
       "      <td>0.005369</td>\n",
       "      <td>16</td>\n",
       "      <td>0.965654</td>\n",
       "      <td>0.968824</td>\n",
       "      <td>0.966446</td>\n",
       "      <td>0.966191</td>\n",
       "      <td>0.967256</td>\n",
       "      <td>0.966874</td>\n",
       "      <td>0.001103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.451542</td>\n",
       "      <td>0.011422</td>\n",
       "      <td>0.171724</td>\n",
       "      <td>0.006352</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "      <td>TruncatedSVD(algorithm='randomized', n_compone...</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>{'clf': GaussianNB(priors=None, var_smoothing=...</td>\n",
       "      <td>0.875396</td>\n",
       "      <td>0.862724</td>\n",
       "      <td>...</td>\n",
       "      <td>0.855875</td>\n",
       "      <td>0.015462</td>\n",
       "      <td>29</td>\n",
       "      <td>0.871334</td>\n",
       "      <td>0.881110</td>\n",
       "      <td>0.853897</td>\n",
       "      <td>0.875066</td>\n",
       "      <td>0.880644</td>\n",
       "      <td>0.872410</td>\n",
       "      <td>0.009944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.398242</td>\n",
       "      <td>0.010043</td>\n",
       "      <td>11.299838</td>\n",
       "      <td>0.756189</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "      <td>TruncatedSVD(algorithm='randomized', n_compone...</td>\n",
       "      <td>CountVectorizer(analyzer=&lt;function stem_rmv_nu...</td>\n",
       "      <td>{'clf': GaussianNB(priors=None, var_smoothing=...</td>\n",
       "      <td>0.843717</td>\n",
       "      <td>0.847941</td>\n",
       "      <td>...</td>\n",
       "      <td>0.835376</td>\n",
       "      <td>0.015850</td>\n",
       "      <td>32</td>\n",
       "      <td>0.856275</td>\n",
       "      <td>0.869221</td>\n",
       "      <td>0.842008</td>\n",
       "      <td>0.858954</td>\n",
       "      <td>0.858463</td>\n",
       "      <td>0.856984</td>\n",
       "      <td>0.008725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.397914</td>\n",
       "      <td>0.009832</td>\n",
       "      <td>0.167133</td>\n",
       "      <td>0.008241</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "      <td>TruncatedSVD(algorithm='randomized', n_compone...</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>{'clf': GaussianNB(priors=None, var_smoothing=...</td>\n",
       "      <td>0.873284</td>\n",
       "      <td>0.859556</td>\n",
       "      <td>...</td>\n",
       "      <td>0.855241</td>\n",
       "      <td>0.014060</td>\n",
       "      <td>30</td>\n",
       "      <td>0.871863</td>\n",
       "      <td>0.878732</td>\n",
       "      <td>0.868428</td>\n",
       "      <td>0.889329</td>\n",
       "      <td>0.876683</td>\n",
       "      <td>0.877007</td>\n",
       "      <td>0.007141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.347283</td>\n",
       "      <td>0.009366</td>\n",
       "      <td>11.237877</td>\n",
       "      <td>0.766603</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "      <td>TruncatedSVD(algorithm='randomized', n_compone...</td>\n",
       "      <td>CountVectorizer(analyzer=&lt;function stem_rmv_nu...</td>\n",
       "      <td>{'clf': GaussianNB(priors=None, var_smoothing=...</td>\n",
       "      <td>0.851109</td>\n",
       "      <td>0.847941</td>\n",
       "      <td>...</td>\n",
       "      <td>0.840871</td>\n",
       "      <td>0.015232</td>\n",
       "      <td>31</td>\n",
       "      <td>0.853633</td>\n",
       "      <td>0.859445</td>\n",
       "      <td>0.845443</td>\n",
       "      <td>0.854464</td>\n",
       "      <td>0.861632</td>\n",
       "      <td>0.854923</td>\n",
       "      <td>0.005607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.456939</td>\n",
       "      <td>0.007510</td>\n",
       "      <td>0.234228</td>\n",
       "      <td>0.009009</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "      <td>NMF(alpha=0.0, beta_loss='frobenius', init='ra...</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>{'clf': GaussianNB(priors=None, var_smoothing=...</td>\n",
       "      <td>0.959873</td>\n",
       "      <td>0.932418</td>\n",
       "      <td>...</td>\n",
       "      <td>0.948014</td>\n",
       "      <td>0.011306</td>\n",
       "      <td>24</td>\n",
       "      <td>0.951651</td>\n",
       "      <td>0.950330</td>\n",
       "      <td>0.949009</td>\n",
       "      <td>0.950079</td>\n",
       "      <td>0.955374</td>\n",
       "      <td>0.951289</td>\n",
       "      <td>0.002209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.397768</td>\n",
       "      <td>0.011909</td>\n",
       "      <td>11.342703</td>\n",
       "      <td>0.826228</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "      <td>NMF(alpha=0.0, beta_loss='frobenius', init='ra...</td>\n",
       "      <td>CountVectorizer(analyzer=&lt;function stem_rmv_nu...</td>\n",
       "      <td>{'clf': GaussianNB(priors=None, var_smoothing=...</td>\n",
       "      <td>0.950370</td>\n",
       "      <td>0.938754</td>\n",
       "      <td>...</td>\n",
       "      <td>0.941462</td>\n",
       "      <td>0.007067</td>\n",
       "      <td>27</td>\n",
       "      <td>0.942933</td>\n",
       "      <td>0.947424</td>\n",
       "      <td>0.939498</td>\n",
       "      <td>0.946117</td>\n",
       "      <td>0.947716</td>\n",
       "      <td>0.944738</td>\n",
       "      <td>0.003121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.398259</td>\n",
       "      <td>0.011138</td>\n",
       "      <td>0.215014</td>\n",
       "      <td>0.005030</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "      <td>NMF(alpha=0.0, beta_loss='frobenius', init='ra...</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>{'clf': GaussianNB(priors=None, var_smoothing=...</td>\n",
       "      <td>0.950370</td>\n",
       "      <td>0.936642</td>\n",
       "      <td>...</td>\n",
       "      <td>0.945689</td>\n",
       "      <td>0.007745</td>\n",
       "      <td>26</td>\n",
       "      <td>0.947424</td>\n",
       "      <td>0.949273</td>\n",
       "      <td>0.949802</td>\n",
       "      <td>0.954041</td>\n",
       "      <td>0.957486</td>\n",
       "      <td>0.951605</td>\n",
       "      <td>0.003652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.348461</td>\n",
       "      <td>0.006624</td>\n",
       "      <td>11.283633</td>\n",
       "      <td>0.746878</td>\n",
       "      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n",
       "      <td>NMF(alpha=0.0, beta_loss='frobenius', init='ra...</td>\n",
       "      <td>CountVectorizer(analyzer=&lt;function stem_rmv_nu...</td>\n",
       "      <td>{'clf': GaussianNB(priors=None, var_smoothing=...</td>\n",
       "      <td>0.948258</td>\n",
       "      <td>0.928194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.940828</td>\n",
       "      <td>0.010737</td>\n",
       "      <td>28</td>\n",
       "      <td>0.942668</td>\n",
       "      <td>0.941347</td>\n",
       "      <td>0.944254</td>\n",
       "      <td>0.952721</td>\n",
       "      <td>0.943491</td>\n",
       "      <td>0.944896</td>\n",
       "      <td>0.004029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        5.962686      0.419752         0.233989        0.032474   \n",
       "1       56.816349      4.698646        13.417887        1.112280   \n",
       "2        4.770253      0.416479         0.231373        0.025810   \n",
       "3       47.986434      0.763277        11.289791        0.773188   \n",
       "4       17.796941      1.451965         0.284369        0.012491   \n",
       "5       14.048102      1.745462        11.333085        0.764753   \n",
       "6       11.459811      2.020819         0.254887        0.004646   \n",
       "7        9.160476      1.693347        11.322142        0.814039   \n",
       "8        0.492910      0.018127         0.174017        0.010081   \n",
       "9        0.432590      0.012666        11.248836        0.758335   \n",
       "10       0.432969      0.010925         0.166997        0.009102   \n",
       "11       0.386701      0.008652        11.248504        0.764086   \n",
       "12       0.462682      0.010759         0.232716        0.007757   \n",
       "13       0.410356      0.012042        11.301614        0.817440   \n",
       "14       0.417232      0.014760         0.215037        0.010752   \n",
       "15       0.364368      0.006498        11.262656        0.780384   \n",
       "16       0.495884      0.022546         0.178400        0.012487   \n",
       "17       0.434211      0.010711        11.260686        0.785300   \n",
       "18       0.455256      0.018835         0.169329        0.011409   \n",
       "19       0.389966      0.012903        11.316099        0.789237   \n",
       "20       0.472331      0.013957         0.229366        0.011777   \n",
       "21       0.411661      0.011797        11.334696        0.766469   \n",
       "22       0.414414      0.013312         0.212723        0.008732   \n",
       "23       0.359011      0.008247        11.390168        0.899670   \n",
       "24       0.451542      0.011422         0.171724        0.006352   \n",
       "25       0.398242      0.010043        11.299838        0.756189   \n",
       "26       0.397914      0.009832         0.167133        0.008241   \n",
       "27       0.347283      0.009366        11.237877        0.766603   \n",
       "28       0.456939      0.007510         0.234228        0.009009   \n",
       "29       0.397768      0.011909        11.342703        0.826228   \n",
       "30       0.398259      0.011138         0.215014        0.005030   \n",
       "31       0.348461      0.006624        11.283633        0.746878   \n",
       "\n",
       "                                            param_clf  \\\n",
       "0   SVC(C=10, cache_size=200, class_weight=None, c...   \n",
       "1   SVC(C=10, cache_size=200, class_weight=None, c...   \n",
       "2   SVC(C=10, cache_size=200, class_weight=None, c...   \n",
       "3   SVC(C=10, cache_size=200, class_weight=None, c...   \n",
       "4   SVC(C=10, cache_size=200, class_weight=None, c...   \n",
       "5   SVC(C=10, cache_size=200, class_weight=None, c...   \n",
       "6   SVC(C=10, cache_size=200, class_weight=None, c...   \n",
       "7   SVC(C=10, cache_size=200, class_weight=None, c...   \n",
       "8   LogisticRegression(C=100, class_weight=None, d...   \n",
       "9   LogisticRegression(C=100, class_weight=None, d...   \n",
       "10  LogisticRegression(C=100, class_weight=None, d...   \n",
       "11  LogisticRegression(C=100, class_weight=None, d...   \n",
       "12  LogisticRegression(C=100, class_weight=None, d...   \n",
       "13  LogisticRegression(C=100, class_weight=None, d...   \n",
       "14  LogisticRegression(C=100, class_weight=None, d...   \n",
       "15  LogisticRegression(C=100, class_weight=None, d...   \n",
       "16  LogisticRegression(C=10, class_weight=None, du...   \n",
       "17  LogisticRegression(C=10, class_weight=None, du...   \n",
       "18  LogisticRegression(C=10, class_weight=None, du...   \n",
       "19  LogisticRegression(C=10, class_weight=None, du...   \n",
       "20  LogisticRegression(C=10, class_weight=None, du...   \n",
       "21  LogisticRegression(C=10, class_weight=None, du...   \n",
       "22  LogisticRegression(C=10, class_weight=None, du...   \n",
       "23  LogisticRegression(C=10, class_weight=None, du...   \n",
       "24       GaussianNB(priors=None, var_smoothing=1e-09)   \n",
       "25       GaussianNB(priors=None, var_smoothing=1e-09)   \n",
       "26       GaussianNB(priors=None, var_smoothing=1e-09)   \n",
       "27       GaussianNB(priors=None, var_smoothing=1e-09)   \n",
       "28       GaussianNB(priors=None, var_smoothing=1e-09)   \n",
       "29       GaussianNB(priors=None, var_smoothing=1e-09)   \n",
       "30       GaussianNB(priors=None, var_smoothing=1e-09)   \n",
       "31       GaussianNB(priors=None, var_smoothing=1e-09)   \n",
       "\n",
       "                                     param_reduce_dim  \\\n",
       "0   TruncatedSVD(algorithm='randomized', n_compone...   \n",
       "1   TruncatedSVD(algorithm='randomized', n_compone...   \n",
       "2   TruncatedSVD(algorithm='randomized', n_compone...   \n",
       "3   TruncatedSVD(algorithm='randomized', n_compone...   \n",
       "4   NMF(alpha=0.0, beta_loss='frobenius', init='ra...   \n",
       "5   NMF(alpha=0.0, beta_loss='frobenius', init='ra...   \n",
       "6   NMF(alpha=0.0, beta_loss='frobenius', init='ra...   \n",
       "7   NMF(alpha=0.0, beta_loss='frobenius', init='ra...   \n",
       "8   TruncatedSVD(algorithm='randomized', n_compone...   \n",
       "9   TruncatedSVD(algorithm='randomized', n_compone...   \n",
       "10  TruncatedSVD(algorithm='randomized', n_compone...   \n",
       "11  TruncatedSVD(algorithm='randomized', n_compone...   \n",
       "12  NMF(alpha=0.0, beta_loss='frobenius', init='ra...   \n",
       "13  NMF(alpha=0.0, beta_loss='frobenius', init='ra...   \n",
       "14  NMF(alpha=0.0, beta_loss='frobenius', init='ra...   \n",
       "15  NMF(alpha=0.0, beta_loss='frobenius', init='ra...   \n",
       "16  TruncatedSVD(algorithm='randomized', n_compone...   \n",
       "17  TruncatedSVD(algorithm='randomized', n_compone...   \n",
       "18  TruncatedSVD(algorithm='randomized', n_compone...   \n",
       "19  TruncatedSVD(algorithm='randomized', n_compone...   \n",
       "20  NMF(alpha=0.0, beta_loss='frobenius', init='ra...   \n",
       "21  NMF(alpha=0.0, beta_loss='frobenius', init='ra...   \n",
       "22  NMF(alpha=0.0, beta_loss='frobenius', init='ra...   \n",
       "23  NMF(alpha=0.0, beta_loss='frobenius', init='ra...   \n",
       "24  TruncatedSVD(algorithm='randomized', n_compone...   \n",
       "25  TruncatedSVD(algorithm='randomized', n_compone...   \n",
       "26  TruncatedSVD(algorithm='randomized', n_compone...   \n",
       "27  TruncatedSVD(algorithm='randomized', n_compone...   \n",
       "28  NMF(alpha=0.0, beta_loss='frobenius', init='ra...   \n",
       "29  NMF(alpha=0.0, beta_loss='frobenius', init='ra...   \n",
       "30  NMF(alpha=0.0, beta_loss='frobenius', init='ra...   \n",
       "31  NMF(alpha=0.0, beta_loss='frobenius', init='ra...   \n",
       "\n",
       "                                           param_vect  \\\n",
       "0   CountVectorizer(analyzer='word', binary=False,...   \n",
       "1   CountVectorizer(analyzer=<function stem_rmv_nu...   \n",
       "2   CountVectorizer(analyzer='word', binary=False,...   \n",
       "3   CountVectorizer(analyzer=<function stem_rmv_nu...   \n",
       "4   CountVectorizer(analyzer='word', binary=False,...   \n",
       "5   CountVectorizer(analyzer=<function stem_rmv_nu...   \n",
       "6   CountVectorizer(analyzer='word', binary=False,...   \n",
       "7   CountVectorizer(analyzer=<function stem_rmv_nu...   \n",
       "8   CountVectorizer(analyzer='word', binary=False,...   \n",
       "9   CountVectorizer(analyzer=<function stem_rmv_nu...   \n",
       "10  CountVectorizer(analyzer='word', binary=False,...   \n",
       "11  CountVectorizer(analyzer=<function stem_rmv_nu...   \n",
       "12  CountVectorizer(analyzer='word', binary=False,...   \n",
       "13  CountVectorizer(analyzer=<function stem_rmv_nu...   \n",
       "14  CountVectorizer(analyzer='word', binary=False,...   \n",
       "15  CountVectorizer(analyzer=<function stem_rmv_nu...   \n",
       "16  CountVectorizer(analyzer='word', binary=False,...   \n",
       "17  CountVectorizer(analyzer=<function stem_rmv_nu...   \n",
       "18  CountVectorizer(analyzer='word', binary=False,...   \n",
       "19  CountVectorizer(analyzer=<function stem_rmv_nu...   \n",
       "20  CountVectorizer(analyzer='word', binary=False,...   \n",
       "21  CountVectorizer(analyzer=<function stem_rmv_nu...   \n",
       "22  CountVectorizer(analyzer='word', binary=False,...   \n",
       "23  CountVectorizer(analyzer=<function stem_rmv_nu...   \n",
       "24  CountVectorizer(analyzer='word', binary=False,...   \n",
       "25  CountVectorizer(analyzer=<function stem_rmv_nu...   \n",
       "26  CountVectorizer(analyzer='word', binary=False,...   \n",
       "27  CountVectorizer(analyzer=<function stem_rmv_nu...   \n",
       "28  CountVectorizer(analyzer='word', binary=False,...   \n",
       "29  CountVectorizer(analyzer=<function stem_rmv_nu...   \n",
       "30  CountVectorizer(analyzer='word', binary=False,...   \n",
       "31  CountVectorizer(analyzer=<function stem_rmv_nu...   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'clf': SVC(C=10, cache_size=200, class_weight...           0.967265   \n",
       "1   {'clf': SVC(C=10, cache_size=200, class_weight...           0.971489   \n",
       "2   {'clf': SVC(C=10, cache_size=200, class_weight...           0.973601   \n",
       "3   {'clf': SVC(C=10, cache_size=200, class_weight...           0.974657   \n",
       "4   {'clf': SVC(C=10, cache_size=200, class_weight...           0.951426   \n",
       "5   {'clf': SVC(C=10, cache_size=200, class_weight...           0.959873   \n",
       "6   {'clf': SVC(C=10, cache_size=200, class_weight...           0.949314   \n",
       "7   {'clf': SVC(C=10, cache_size=200, class_weight...           0.960929   \n",
       "8   {'clf': LogisticRegression(C=100, class_weight...           0.973601   \n",
       "9   {'clf': LogisticRegression(C=100, class_weight...           0.974657   \n",
       "10  {'clf': LogisticRegression(C=100, class_weight...           0.974657   \n",
       "11  {'clf': LogisticRegression(C=100, class_weight...           0.975713   \n",
       "12  {'clf': LogisticRegression(C=100, class_weight...           0.964097   \n",
       "13  {'clf': LogisticRegression(C=100, class_weight...           0.964097   \n",
       "14  {'clf': LogisticRegression(C=100, class_weight...           0.959873   \n",
       "15  {'clf': LogisticRegression(C=100, class_weight...           0.964097   \n",
       "16  {'clf': LogisticRegression(C=10, class_weight=...           0.971489   \n",
       "17  {'clf': LogisticRegression(C=10, class_weight=...           0.975713   \n",
       "18  {'clf': LogisticRegression(C=10, class_weight=...           0.972545   \n",
       "19  {'clf': LogisticRegression(C=10, class_weight=...           0.976769   \n",
       "20  {'clf': LogisticRegression(C=10, class_weight=...           0.969377   \n",
       "21  {'clf': LogisticRegression(C=10, class_weight=...           0.969377   \n",
       "22  {'clf': LogisticRegression(C=10, class_weight=...           0.965153   \n",
       "23  {'clf': LogisticRegression(C=10, class_weight=...           0.967265   \n",
       "24  {'clf': GaussianNB(priors=None, var_smoothing=...           0.875396   \n",
       "25  {'clf': GaussianNB(priors=None, var_smoothing=...           0.843717   \n",
       "26  {'clf': GaussianNB(priors=None, var_smoothing=...           0.873284   \n",
       "27  {'clf': GaussianNB(priors=None, var_smoothing=...           0.851109   \n",
       "28  {'clf': GaussianNB(priors=None, var_smoothing=...           0.959873   \n",
       "29  {'clf': GaussianNB(priors=None, var_smoothing=...           0.950370   \n",
       "30  {'clf': GaussianNB(priors=None, var_smoothing=...           0.950370   \n",
       "31  {'clf': GaussianNB(priors=None, var_smoothing=...           0.948258   \n",
       "\n",
       "    split1_test_score       ...         mean_test_score  std_test_score  \\\n",
       "0            0.968321       ...                0.971048        0.005124   \n",
       "1            0.955649       ...                0.965131        0.005714   \n",
       "2            0.970433       ...                0.972527        0.003552   \n",
       "3            0.956705       ...                0.966610        0.006743   \n",
       "4            0.940866       ...                0.947168        0.008159   \n",
       "5            0.940866       ...                0.949704        0.007295   \n",
       "6            0.941922       ...                0.951395        0.008535   \n",
       "7            0.942978       ...                0.954987        0.008793   \n",
       "8            0.971489       ...                0.973373        0.005123   \n",
       "9            0.959873       ...                0.969569        0.005102   \n",
       "10           0.969377       ...                0.972950        0.006307   \n",
       "11           0.960929       ...                0.968935        0.005117   \n",
       "12           0.960929       ...                0.959637        0.007895   \n",
       "13           0.951426       ...                0.958157        0.006724   \n",
       "14           0.956705       ...                0.962384        0.007465   \n",
       "15           0.950370       ...                0.959637        0.006741   \n",
       "16           0.972545       ...                0.971682        0.003580   \n",
       "17           0.964097       ...                0.970626        0.004893   \n",
       "18           0.971489       ...                0.972950        0.003831   \n",
       "19           0.959873       ...                0.969358        0.006238   \n",
       "20           0.969377       ...                0.966610        0.005440   \n",
       "21           0.955649       ...                0.960270        0.007242   \n",
       "22           0.961985       ...                0.967033        0.005329   \n",
       "23           0.952482       ...                0.961116        0.005369   \n",
       "24           0.862724       ...                0.855875        0.015462   \n",
       "25           0.847941       ...                0.835376        0.015850   \n",
       "26           0.859556       ...                0.855241        0.014060   \n",
       "27           0.847941       ...                0.840871        0.015232   \n",
       "28           0.932418       ...                0.948014        0.011306   \n",
       "29           0.938754       ...                0.941462        0.007067   \n",
       "30           0.936642       ...                0.945689        0.007745   \n",
       "31           0.928194       ...                0.940828        0.010737   \n",
       "\n",
       "    rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0                 6            0.976222            0.974637   \n",
       "1                14            0.966711            0.972259   \n",
       "2                 4            0.975958            0.975958   \n",
       "3                12            0.964597            0.970938   \n",
       "4                25            0.949538            0.951123   \n",
       "5                23            0.956407            0.958785   \n",
       "6                22            0.951387            0.951915   \n",
       "7                21            0.954822            0.956143   \n",
       "8                 1            0.978071            0.976750   \n",
       "9                 8            0.970674            0.972259   \n",
       "10                2            0.977807            0.977807   \n",
       "11               10            0.971731            0.973844   \n",
       "12               18            0.960634            0.960370   \n",
       "13               20            0.960634            0.964861   \n",
       "14               15            0.963804            0.964597   \n",
       "15               18            0.962483            0.964333   \n",
       "16                5            0.978600            0.976750   \n",
       "17                7            0.973052            0.974901   \n",
       "18                2            0.977807            0.977543   \n",
       "19                9            0.973052            0.973316   \n",
       "20               12            0.970674            0.969089   \n",
       "21               17            0.964597            0.969881   \n",
       "22               11            0.974637            0.969881   \n",
       "23               16            0.965654            0.968824   \n",
       "24               29            0.871334            0.881110   \n",
       "25               32            0.856275            0.869221   \n",
       "26               30            0.871863            0.878732   \n",
       "27               31            0.853633            0.859445   \n",
       "28               24            0.951651            0.950330   \n",
       "29               27            0.942933            0.947424   \n",
       "30               26            0.947424            0.949273   \n",
       "31               28            0.942668            0.941347   \n",
       "\n",
       "    split2_train_score  split3_train_score  split4_train_score  \\\n",
       "0             0.971995            0.974643            0.977291   \n",
       "1             0.968032            0.971210            0.973330   \n",
       "2             0.972523            0.975172            0.974650   \n",
       "3             0.967768            0.970946            0.973330   \n",
       "4             0.940819            0.950608            0.946924   \n",
       "5             0.952180            0.953777            0.950885   \n",
       "6             0.952972            0.955098            0.955638   \n",
       "7             0.954822            0.959324            0.958014   \n",
       "8             0.974373            0.976228            0.978347   \n",
       "9             0.972787            0.973851            0.974650   \n",
       "10            0.973580            0.977285            0.977819   \n",
       "11            0.971995            0.974643            0.975178   \n",
       "12            0.956935            0.961965            0.960391   \n",
       "13            0.959049            0.963022            0.960391   \n",
       "14            0.963540            0.966191            0.967256   \n",
       "15            0.964069            0.965663            0.964088   \n",
       "16            0.977015            0.978341            0.979139   \n",
       "17            0.970938            0.975172            0.975706   \n",
       "18            0.978336            0.978870            0.979931   \n",
       "19            0.972259            0.974908            0.975178   \n",
       "20            0.968296            0.968568            0.971745   \n",
       "21            0.965918            0.965927            0.968577   \n",
       "22            0.969617            0.971474            0.972802   \n",
       "23            0.966446            0.966191            0.967256   \n",
       "24            0.853897            0.875066            0.880644   \n",
       "25            0.842008            0.858954            0.858463   \n",
       "26            0.868428            0.889329            0.876683   \n",
       "27            0.845443            0.854464            0.861632   \n",
       "28            0.949009            0.950079            0.955374   \n",
       "29            0.939498            0.946117            0.947716   \n",
       "30            0.949802            0.954041            0.957486   \n",
       "31            0.944254            0.952721            0.943491   \n",
       "\n",
       "    mean_train_score  std_train_score  \n",
       "0           0.974958         0.001790  \n",
       "1           0.970308         0.002525  \n",
       "2           0.974852         0.001266  \n",
       "3           0.969516         0.003029  \n",
       "4           0.947802         0.003780  \n",
       "5           0.954407         0.002861  \n",
       "6           0.953402         0.001693  \n",
       "7           0.956625         0.001786  \n",
       "8           0.976754         0.001430  \n",
       "9           0.972844         0.001366  \n",
       "10          0.976860         0.001652  \n",
       "11          0.973478         0.001388  \n",
       "12          0.960059         0.001669  \n",
       "13          0.961591         0.002077  \n",
       "14          0.965078         0.001428  \n",
       "15          0.964127         0.001011  \n",
       "16          0.977969         0.000928  \n",
       "17          0.973954         0.001753  \n",
       "18          0.978497         0.000850  \n",
       "19          0.973742         0.001121  \n",
       "20          0.969674         0.001323  \n",
       "21          0.966980         0.001943  \n",
       "22          0.971682         0.001873  \n",
       "23          0.966874         0.001103  \n",
       "24          0.872410         0.009944  \n",
       "25          0.856984         0.008725  \n",
       "26          0.877007         0.007141  \n",
       "27          0.854923         0.005607  \n",
       "28          0.951289         0.002209  \n",
       "29          0.944738         0.003121  \n",
       "30          0.951605         0.003652  \n",
       "31          0.944896         0.004029  \n",
       "\n",
       "[32 rows x 23 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_rm = pd.DataFrame(grid_rm.cv_results_)\n",
    "pd.DataFrame(grid_rm.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clf': LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
      "          n_jobs=None, penalty='l1', random_state=42, solver='warn',\n",
      "          tol=0.0001, verbose=0, warm_start=False), 'reduce_dim': TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
      "       random_state=42, tol=0.0), 'vect': CountVectorizer(analyzer=<function stem_rmv_nums at 0x12655c7b8>,\n",
      "        binary=False, decode_error='strict', dtype=<class 'numpy.int64'>,\n",
      "        encoding='utf-8', input='content', lowercase=True, max_df=1.0,\n",
      "        max_features=None, min_df=5, ngram_range=(1, 1), preprocessor=None,\n",
      "        stop_words=None, strip_accents=None,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, vocabulary=None)}\n"
     ]
    }
   ],
   "source": [
    "# print out the best result found\n",
    "\n",
    "print(result['params'][19])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 8:\n",
    "In this part, we aim to learn classifiers on the documents belonging to the classes:\n",
    "\n",
    "<font color=LightCoral>[comp.sys.ibm.pc.hardware, comp.sys.mac.hardware,\n",
    "misc.forsale, soc.religion.christian]</font>\n",
    "\n",
    "Perform Naive Baayes classification and multiclass SVM classification (with both One VS One and One VS the rest methods described above) and report the **confusion matrix** and calculate the **accuracy, recall, precision** and **F-1 score** of your classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2352\n",
      "1565\n",
      "-------------------- After preprocess --------------------\n",
      "(2352, 50)\n",
      "(1565, 50)\n"
     ]
    }
   ],
   "source": [
    "# prepare data\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "categories8 = ['comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware',\n",
    "'misc.forsale', 'soc.religion.christian']\n",
    "\n",
    "train_ds = fetch_20newsgroups(subset = 'train', \n",
    "                                      categories = categories8, \n",
    "                                      shuffle = True, \n",
    "                                      random_state = None)\n",
    "test_ds = fetch_20newsgroups(subset = 'test', \n",
    "                                      categories = categories8, \n",
    "                                      shuffle = True, \n",
    "                                      random_state = None)\n",
    "\n",
    "# preprocess data\n",
    "\n",
    "# vect\n",
    "vec8 = CountVectorizer(min_df=3, analyzer=stem_rmv_nums)\n",
    "train_vect = vec8.fit_transform(train_ds.data)\n",
    "test_vect = vec8.transform(test_ds.data)\n",
    "\n",
    "# tfidf\n",
    "tfidf8 = TfidfTransformer()\n",
    "train_tfidf = tfidf8.fit_transform(train_vect)\n",
    "test_tfidf = tfidf8.transform(test_vect)\n",
    "\n",
    "# lsi\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "svd8 = TruncatedSVD(n_components = 50, random_state = 42)\n",
    "X_train8 = svd8.fit_transform(train_tfidf)\n",
    "X_test8 = svd8.transform(test_tfidf)\n",
    "\n",
    "# check\n",
    "print(len(train_ds.data))\n",
    "print(len(test_ds.data))\n",
    "print('-'*20,'After preprocess','-'*20)\n",
    "print(X_train8.shape)\n",
    "print(X_test8.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3]\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(train_ds.target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Confusion Matrix of GaussianNB --------------------\n",
      "[[232  38 120   2]\n",
      " [107 159 118   1]\n",
      " [ 48  45 295   2]\n",
      " [  0   1  15 382]]\n",
      "-------------------- Other Evaluation of GaussianNB --------------------\n",
      "Accuracy: 0.6824281150159744\n",
      "Recall: 0.6802582497665053\n",
      "Precision: 0.6948013657577683\n",
      "F-1 Score: 0.6760627830593133\n"
     ]
    }
   ],
   "source": [
    "bayes8 = GaussianNB().fit(X_train8, train_ds.target)\n",
    "\n",
    "# evaluate\n",
    "evaluate(bayes8, 'GaussianNB', X_test8, test_ds.target, 'macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM(ovr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Confusion Matrix of SVC (ovr) --------------------\n",
      "[[305  61  26   0]\n",
      " [ 44 317  24   0]\n",
      " [ 24  20 343   3]\n",
      " [  3   0   2 393]]\n",
      "-------------------- Other Evaluation of SVC (ovr) --------------------\n",
      "Accuracy: 0.8677316293929712\n",
      "Recall: 0.8670905533208118\n",
      "Precision: 0.8671078244075621\n",
      "F-1 Score: 0.8669467187208237\n"
     ]
    }
   ],
   "source": [
    "svm_ovr = SVC(kernel='linear', C=100).fit(X_train8, train_ds.target)\n",
    "\n",
    "# evaluate\n",
    "evaluate(svm_ovr, 'SVC (ovr)', X_test8, test_ds.target, 'macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM(ovo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Confusion Matrix of SVC (ovo) --------------------\n",
      "[[305  61  26   0]\n",
      " [ 44 317  24   0]\n",
      " [ 24  20 343   3]\n",
      " [  3   0   2 393]]\n",
      "-------------------- Other Evaluation of SVC (ovo) --------------------\n",
      "Accuracy: 0.8677316293929712\n",
      "Recall: 0.8670905533208118\n",
      "Precision: 0.8671078244075621\n",
      "F-1 Score: 0.8669467187208237\n"
     ]
    }
   ],
   "source": [
    "svm_ovo = SVC(kernel='linear', C=100, decision_function_shape = 'ovo').fit(X_train8, train_ds.target)\n",
    "\n",
    "# evaluate\n",
    "evaluate(svm_ovo, 'SVC (ovo)', X_test8, test_ds.target, 'macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
